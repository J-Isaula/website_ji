[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Juan Isaula",
    "section": "",
    "text": "Hola!\nSoy Juan, un matemático orientado al área estadística, especialista en ciencia de datos, análisis actuarial y riesgo crediticio, tengo gran expertis en lenguajes de progamación como Python, R, KNIME y SQL. Me fascina el campo del Machine Learning y Deep Learning, la mayor parte de mis trabajos están orientados al desarrollo de modelos estadísticos aplicados a diferentes áreas (economía, medicina, finanzas, actuaría, riesgo crediticio).\nEn la actualidad soy candidato a MSc. Economía Matemática en Universidad Nacional Autónoma de San Luis Potosi (UASLP), México.\nEn este sitio mantengo información sobre cursos en los cuales soy colaborador, algunos papers que llaman mucho mi atención, mi blog personal donde podra encontrar post que le puden despertar su interes en el modelado estadístico con el uso de herramientas de aprendizaje automático (Machine Learning) y Aprendizaje Profundo (Deep Learning)"
  },
  {
    "objectID": "posts/estructuras_mercado/index.html",
    "href": "posts/estructuras_mercado/index.html",
    "title": "Estructuras de Mercado con Python",
    "section": "",
    "text": "Este post tiene como objetivo dar a conocer la importancia del software de Python en el ambito microeconomico, particularmente en este caso hablamos de las diferentes estructuras de mercado; competencia perfecta, monopolio y oligopolio."
  },
  {
    "objectID": "posts/estructuras_mercado/index.html#condiciones-necesaria-para-la-competencia-perfecta",
    "href": "posts/estructuras_mercado/index.html#condiciones-necesaria-para-la-competencia-perfecta",
    "title": "Estructuras de Mercado con Python",
    "section": "Condiciones necesaria para la competencia perfecta",
    "text": "Condiciones necesaria para la competencia perfecta\n\nMuchos productores, ninguno de los cuales tiene una gran cuota de mercado.\nUna industria puede ser perfectamente competitiva sólo si los consumidores consideran como equivalentes a los productos de todos los productores (producto homogéneo)"
  },
  {
    "objectID": "posts/estructuras_mercado/index.html#libre-entrada-y-salida",
    "href": "posts/estructuras_mercado/index.html#libre-entrada-y-salida",
    "title": "Estructuras de Mercado con Python",
    "section": "Libre entrada y salida",
    "text": "Libre entrada y salida\nExiste libre entrada y salida en una industria cuando nuevos productores pueden entrar facilmente en esa industria a los que ya estan en ella pueden abondonarla sin coste alguno.\n\nRegla de Producción Optima\nLa regla de producción optima dice que el beneficio se maximiza cuando se produce la cantidad de output para la cual el ingreso marginal de la última unidad de output producida es igual a su coste marginal.\n\\[\nIMg = CMg\n\\]\n\n\nFunción de Benenficios\nLa función de beneficios \\((\\pi)\\) representa las diferencias entre los costos totales, \\(C(Q)\\) e ingresos totales,\\(R(Q)\\) , de las empresas\n\\[\n\\pi = R(Q) - C(Q)\n\\]\n\n\nTomador de Precios\nPrecio igual al costo marginal\n\\[\n\\begin{eqnarray*}\nCMg = IMg = P\n\\end{eqnarray*}\n\\]\nPor tanto, se dice que el beneficio de una empresa precio-aceptante se maximiza produciendo la cantidad de output para la cual el costo marginal de la última unidad producida es igual al precio de mercado, tal como se aprecia en el siguiente gráfico\n\n\n\nCantidad de producto que maximiza el beneficio de una empresa precio-aceptante"
  },
  {
    "objectID": "posts/estructuras_mercado/index.html#costes-y-producción-en-el-corto-plazo",
    "href": "posts/estructuras_mercado/index.html#costes-y-producción-en-el-corto-plazo",
    "title": "Estructuras de Mercado con Python",
    "section": "Costes y Producción en el Corto Plazo",
    "text": "Costes y Producción en el Corto Plazo\nEn el corto plazo tenemos las siguientes condiciones de producción de empresas competitivas\n\n\n\n\n\n\n\nCondiciones\nResultados\n\n\n\n\nP > CVMe mínimo\nLa empresa produce en el corto plazo. Si P < CTMe mínimo, la empresa cubre sus costos variables y parte de sus costes fijos pero no todos. Si P > CTMe mínimo, la empresa cubre todos sus costes variables y sus costes fijos.\n\n\nP = CVMe mínimo\nLa empresa es indiferente entre producir en el corto plazo o no producir. Cubre exactamente sus costes variables.\n\n\nP < CVMe mínimo\nLa empresa cierra en el corto plazo. No cubre sus costes variables."
  },
  {
    "objectID": "posts/estructuras_mercado/index.html#ejemplo-1--corto-plazo",
    "href": "posts/estructuras_mercado/index.html#ejemplo-1--corto-plazo",
    "title": "Estructuras de Mercado con Python",
    "section": "Ejemplo # 1- Corto Plazo",
    "text": "Ejemplo # 1- Corto Plazo\nPrimero resolveremos el siguiente ejercicio de manera manual y posteriormente lo resolveremos en Python.\nSuponga que la empresa tiene una curva de costos de corto plazo dada por\n\\[\nC(Q) = 100 + 20Q + Q^2\n\\]\n\n¿Cuál es la ecuación para el costo variable Medio?\n¿Cuál es el valor mínimo para el costo variable promedio?\n¿Cuál es la curva de oferta de corto plazo?\n\nSolución\n\nDada la función de costo \\(C(Q) = 100 + 20Q + Q^2\\) es claro que el costo variable, CV, esta dado por \\[CV = 20Q + Q^2\\] por tanto su costo variable promedio es \\[CVMe = \\frac{CV}{Q} = 20 + Q\\]\nAhora bien, su costo marginal sabemos que unicamente requiere aplicar la regla de diferenciación, ya que \\[CMg = \\frac{\\partial C(Q)}{\\partial Q} = 20 + 2Q\\]\nSi queremos encontrar el costo variable promedio mínimo, \\[CVMe_{\\min}\\], se obtiene como \\[CMg = CVMe \\longrightarrow Q = \\fbox{0}\\]\nEntonces la función de oferta es: \\[\\begin{eqnarray*}CMg &=& p\\\\[0.2cm] 20 + 2Q &=& P\\\\[0.2cm] Q(P) &=& \\frac{P}{2} - 10 \\end{eqnarray*}\\]\n\nPor tanto, también podemos obtener el precio de equilibrio, ya que \\[0 = \\frac{P}{2} - 10 \\longrightarrow P = \\fbox{20}\\]\nAhora, encontremos estos resultados en Python:\n\n# Paquete previo \nfrom sympy import *\nQ = symbols(\"Q\")\n\n\n# función de costo de corto plazo \nCT = 100 + 20*Q + Q**2\n# costo variale promedio \nCV = 20 + Q \n# Encontrar el costo variable minimo \n# Primero: costo marginal\n\nCM = diff(CT,Q)\n\n\n# igualar costo marginal y costo variable promedio \nsolve(Eq(CM,CV))\n\n[0]\n\n\n\ncantidad = solve(Eq(CM,CV))\ncantidad[0]\n\n\\(\\displaystyle 0\\)\n\n\n\nP = CV.subs({Q:cantidad[0]})\nP\n\n\\(\\displaystyle 20\\)\n\n\n\nplot(CT, CT/Q, CV, CM, (Q,0,100), xlim = (0, 100), ylim = (0,100), xlabel = \"Q\", ylabel = \"P\")\n\n\n\n\n<sympy.plotting.plot.Plot at 0x1997ad7ef40>\n\n\nPuedes notar lo rápido y fácil que resulta realizar estos procedimientos con Python y la utilidad que puede brindarte en caso de que trabajes con volumnes de datos.\n\nEjemplo # 2 - Corto Plazo\nAhora suponga que la empresa tiene una curva costos en el corto plazo de la siguiente forma:\n\\[\nC(Q) = 1 + 10Q + Q^2\n\\]\nSi la empresa opera en un mercado perfectamente competitivo, donde \\(P = 12\\), ¿Cuál será los beneficios de la empresa en el corto plazo?\nSolución\nSabemos que la función de beneficios esta dada por\n\\[\n\\pi = R - C\n\\]\nentonces,\n\\[\n\\frac{\\partial \\pi}{\\partial Q} = IMg - CMg = 0\n\\]\nasí pues,\n\\[\nCMg = 10 + 2Q \\hspace{1cm}y\\hspace{1cm} IMg = P\n\\]\npor tanto,\n\\[\n\\begin{eqnarray*}\nCMg &=& IMg\\\\[0.2cm]\n10 + 2Q &=& P\\\\[0.2cm]\nQ &=& \\frac{P}{2} - 5\\\\[0.2cm]\nQ &=& \\frac{12}{2} - 5, \\hspace{2cm}\\mbox{ya que P = 12}\\\\[0.2cm]\nQ &=& \\fbox{1}\n\\end{eqnarray*}\n\\]\nentonces,\n\\[\n\\pi = 12 - (1 + 10 +1) = \\fbox{0}\n\\]\nAhora veamos esta solución en Python:\n\n# Función de costos a corto plazo \nQ = symbols(\"Q\")\nCT = Q**2 + 10*Q + 1\nP = 12\nR = P*Q\n# costo marginal\nCM = diff(CT,Q)\nCM\nIM = diff(R,Q)\nIM\ncantidad = solve(Eq(IM,CM))\nprint(\"El valor de la producción que garantiza un equilibrio será:\", cantidad[0])\n\nEl valor de la producción que garantiza un equilibrio será: 1\n\n\nEste resultado lo que nos dice es que la empresa oferta una unidad de producción \\(Q = 1\\).\n\n# Beneficio = IT - CT\ncosto = CT.subs({Q:cantidad[0]})\ncosto\n\n\\(\\displaystyle 12\\)\n\n\n\ningreso = R.subs({Q:cantidad[0]})\ningreso \n\n\\(\\displaystyle 12\\)\n\n\n\nBeneficios = R - CT\npi = Beneficios.subs({Q:cantidad[0]})\npi\n\n\\(\\displaystyle 0\\)\n\n\n\nplot(CT,CM,CT/Q,(Q,0,60), xlim=(0,5), ylim=(0,30), xlabel='Q', ylabel='CT,CM')\n\n\n\n\n<sympy.plotting.plot.Plot at 0x1997b621bb0>\n\n\nRecuerde que todo este análisis se realizo para un mercado en competencia perfecta a corto plazo.\nPronto actualizare para el mercado en competencia perfecta a largo plazo, monopolio, e introducirnos un poco a la teoria de juegos."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Juan Isaula",
    "section": "",
    "text": "Recurda que puedes dejar tus comentarios sobre alguno de los post que se presentan en esta sección de mi website, yendo al final de este sitio.\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nTipos de Arquitecturas de Redes Neuronales\n\n\n\n\n\n\n\nRNN\n\n\nGRU\n\n\nLSTM\n\n\nPyTorch\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2024\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nPredicción de primas de seguros médicos con Machine Learning\n\n\nUtilizando Python\n\n\n\n\nPython\n\n\nSeguros\n\n\nRandom Forest Regressor\n\n\n\n\n\n\n\n\n\n\n\nNov 19, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nCredit Scoring and Segmentation using Python\n\n\nMachine Learning\n\n\n\n\nFICO\n\n\nCredit Scores\n\n\nPython\n\n\nsklearn\n\n\n\n\n\n\n\n\n\n\n\nSep 13, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nTime Series Forecasting with XGBoost\n\n\nUtilizando Machine Learning Forecast\n\n\n\n\nXGBoost\n\n\nMLForecast\n\n\nPython\n\n\nsklearn\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nRedes Neuronales Recurrentes (LSTM)\n\n\nPronósticos de índice AAPL\n\n\n\n\nRNN\n\n\nLSTM\n\n\nTensorflow\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nEstructuras de Mercado con Python\n\n\nCompetencia Perfecta, Monopolio y Oligopolio\n\n\n\n\nCMg\n\n\nCVP\n\n\nCTP\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nApr 13, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nPortfolio management\n\n\nGeneralidades\n\n\n\n\nDiversificación\n\n\nPortafolio\n\n\nVolatilidad\n\n\nFrontera eficiente\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nMachine Learning en Tidyverse\n\n\nMúltiples Modulos con broom\n\n\n\n\nMachine Learning\n\n\nForecasting\n\n\nR\n\n\nRStudio\n\n\nbroom\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nMicroeconomía Intermedia con R\n\n\nUtilidad y sus Curvas de Indiferencia\n\n\n\n\nEconomía\n\n\nMicroeconomía\n\n\nR\n\n\nRStudio\n\n\n\n\n\n\n\n\n\n\n\nJan 9, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nModelo Prophet de Facebook\n\n\nPronóstico aplicado al tipo de cambio USD/HNL\n\n\n\n\nProphet\n\n\nForecasting\n\n\nR\n\n\nRStudio\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2022\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nIntroducción a R\n\n\nGeneralidades\n\n\n\n\nR\n\n\nRStudio\n\n\n\n\n\n\n\n\n\n\n\nJan 20, 2022\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nSeries de Tiempo\n\n\n\n\n\n\n\nTime Series\n\n\nRStudio\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2021\n\n\nJuan Isaula\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/port_mg/index.html",
    "href": "posts/port_mg/index.html",
    "title": "Portfolio management",
    "section": "",
    "text": "La teoría de la fijación de precios de derivados es una teoría de rendimientos deterministas: cubrimos nuestros derivados con el subyacente para eliminar el riesgo, y nuestra cartera libre de riesgo resultante gana la tasa de interés libre de riesgo. Los bancos ganan dinero con este proceso de cobertura; venden algo por un poco más de lo que vale y cubrir el riesgo para obtener una ganancia garantizada. Los gestores de fondos compran y venden activos (incluidos los derivados) con el objetivo de superar la tasa de rendimiento del banco. Al hacerlo, se arriesgan. En este artículo explico algunas de la teorías detrás del riesgo y la recompensa de la inversión y, como optimizar una cartera para obtener el mejor valor por dinero."
  },
  {
    "objectID": "posts/port_mg/index.html#diversificación",
    "href": "posts/port_mg/index.html#diversificación",
    "title": "Portfolio management",
    "section": "Diversificación",
    "text": "Diversificación\nIntroduciremos algo de notación y muestro el efecto de la diversificación sobre la rentabilidad de la cartera. Supongamos que tenemos una cartera de \\(N\\) activos. El valor hoy del i-ésimo activo es \\(S_i\\) y su rendimiento aleatorio es \\(R_i\\) sobre nuestro horizonte de tiempo \\(T\\). Las \\(R_i \\sim N(\\mu_iT, \\sigma_i\\sqrt{T})\\). La correlación entre los rendimientos de la i-ésima y j-ésimo activo es \\(\\rho_{ij}\\) (con \\(\\rho_{ii} = 1\\)).\nLos parámetros \\(\\mu, \\sigma\\) y \\(\\rho\\) corresponden a la media, volatilidad y correlación a la que estamos acostumbrados. Tenga en cuenta la escala con el horizonte de tiempo.\nSi tenemos \\(w_i\\) del i-ésimo activo, entonces nuestra cartera tiene valor\n\\[\n\\Pi = \\sum_{i=1}^{N} w_iS_i\n\\]\nAl final de nuestro horizonte temporal, el valor es\n\\[\\Pi + \\delta\\Pi = \\sum_{i=1}^{N} w_iS_i(1+R_i)\\]\nPodemos escribir el cambio relativo en el valor de la cartera como\n\\[\n\\frac{\\delta\\Pi}{\\Pi} = \\sum_{i=1}^N W_iR_i\\hspace{1.5cm} (1)\n\\]\ndonde\n\\[\nW_i = \\frac{w_iS_i}{\\sum_{i=1}^N w_iS_i}\n\\]\nLos pesos \\(W_i\\) suman uno.\nA partir de (1) es sencillo calcular el rendimiento esperado de la cartera\n\\[\n\\mu_{\\Pi} = \\frac{1}{T}E\\left[\\begin{array}{c}\\frac{\\delta\\Pi}{\\Pi}\\end{array}\\right] = \\sum_{i=1}^{N}W_i \\mu_i\\hspace{6cm} (2)\n\\]\nY la desviación estándar de los retornos son\n\\[\n\\sigma_{\\Pi} = \\frac{1}{\\sqrt{T}}\\sqrt{var\\left[\\begin{array}{0} \\frac{\\delta \\Pi}{\\Pi}\\end{array}\\right]} = \\sqrt{\\sum_{i=1}^{N}\\sum_{j=1}^N W_iW_j \\rho_{ij}\\sigma_i\\sigma_j}\\hspace{1.5cm} (3)\n\\]\nEn ellos hemos relacionado los parámetros de los activos individuales con la rentabilidad esperada y la desviación estándar de toda la cartera.\nSupongamos que tenemos activos en nuestra cartera que no están correlacionados, es decir, \\(\\rho_{ij} = 0\\), \\(i = j\\). Para simplificar las cosas, suponga que tienen el mismo peso, de modo que \\(W_i = \\frac{1}{N}\\). El rendimiento esperado de la cartera está representado por\n\\[\n\\mu_{\\Pi} = \\frac{1}{N}\\sum_{i=1}^N \\mu_i\n\\]\nEl promedio de los rendimientos esperados de todos los activos, y la volatilidad se convierte en\n\\[\n\\sigma_{\\Pi} = \\sqrt{\\frac{1}{N^2}\\sum_{i=1}^N \\sigma_i^2}\n\\]\nEsta volatilidad es \\(O(N^{-1/2})\\) ya que hay \\(N\\) términos en la suma. A medida que aumentamos el número de activos en cartera, la desviación estándar de los rendimientos tiende a cero.\nSupongamos que todos los activos no están correlacionados, pero veremos algo similar cuando describa el Modelo de fijación de precios de activos de capital; la diversificación reduce la volatilidad sin perjudicar las expectativas de rendimientos.\nAhora me voy a referir a la volatilidad o desviación estándar como riesgo, algo malo que debe evitarse (dentro de lo razonable), y el rendimiento esperado como recompensa, algo bueno que queremos tanto como sea posible."
  },
  {
    "objectID": "posts/port_mg/index.html#teoría-moderna-del-portafolio",
    "href": "posts/port_mg/index.html#teoría-moderna-del-portafolio",
    "title": "Portfolio management",
    "section": "Teoría Moderna del Portafolio",
    "text": "Teoría Moderna del Portafolio\nPödemos usar el marco anterior para discutir la “mejor” cartera. La definición de “mejor” fue abordada con mucho éxito por el Premio Nobel Harry Markowitz. Su modelo proporciona una manera de definir carteras que sean eficientes.\nUna cartera eficiente es aquella que tiene la recompensa más alta para un nivel de riesgo, o el riesgo más bajo para una recompensa dada. Para ver cómo funciona esto imagina que hay cuatro activos en el mundo \\(A, B, C\\) y \\(D\\) con recompensa y riesgo como se muestra en la figura 1 (ignore E por el momento). Si pudieras comprar alguno de estos (pero de momentos no te permiten más de uno), ¿cuál comprarías? eliges D? No, porque tiene el mismo riesgo que B pero menos recompensa, tiene la misma recompensa que como C pero pun mayor riesgo. Entonces, podemos descartar \\(D\\). ¿Qué pasa con B o C? Ambos son atractivos cuando se comparan con D, pero entre si no estan claro, B tiene un mayor riesgo, pero obtiene una mayor recompensa. Sin embargo, comparándolos a ambos con A vemos que no hay competencia, ya que A es la elección preferida. Si introducimos el activo E con el mismo riesgo que B y una recompensa mayor que A, entonces no podemos decir objetivamente cuál de A y E es mejor; esta es una elección subjetiva y depende de las preferencias de riesgo de un inversor.\n\n\n\nFigura 1: Riesgo y recompensa de cinco activos\n\n\nAhora suponga que tengo los dos activos A y E de la figura 2, y puedo combinar en mi cartera, ¿qué efecto tiene esto en mi riesgo/recompensa?\n\n\n\nFigura 2: Dos activos y cualquier combinación\n\n\nDe (2) y (3) tenemos\n\\[\\mu_{\\Pi} = W\\mu_{A} + (1-W)\\mu_{E}\\]\ny\n\\[\n\\sigma_{\\Pi}^2 = W^2\\sigma_{A}^2 + 2W(1-W)\\rho\\sigma_{A}\\sigma_{E} + (1-W)^2\\sigma_{E}^2\n\\]\nAquí \\(w\\) es el peso del activo A y, recordando que los pesos deben sumar uno, el peso del activo E es \\(1 - E\\).\nA medida que variamos W, también cambian el riesgo y la recompensa. La linea en el espacio de riesgo/recompensa que es parametrizada por W es una hipérbola, como se muestra en la figura 2. La parte de esta curva en negrita es eficiente, y es preferible al resto de la curva. Una ves más, las preferencias de riesgo de un individuo dirá dónde quiere estar en la curva audaz. Cuando una de las volatilidades es cero la línea se vuelvve recta. en cualquier lugar de la curva entre los dos puntos se requiere una posición larga en cada activo. Fuera de esta región, uno de los activos se vende al descubierto para financiar la compra del otro. Todo lo que sigue asume que podemos vender al descubierto tanto activo como queramos. Los resultados cambian ligeramente cuando hay restricciones.\nSi tenemos muchos activos en nuestra cartera, ya no tenemos una simple hipérbola para nuestros posibles perfiles de riesgo/recompensa; en cambio obtenemos algo como lo que se muestra en la Figura 3.\n\n\n\nFigura 3: Posibilidades de cartera y la frontera eficiente\n\n\nEsta figura ahora usa todo A, B, C, D y E, no solo A y E. Aunque B, C y D no son individualmente atractivos, bien pueden ser útiles en un portafolio, dependiendo de como se correlacionen, o no, con otras inversiones. En esta figura podemos ver la frontera eficiente marcada en negrita. Dado cualquier elección de cartera elegiríamos tener una que se encuentre en esta frontera eficiente."
  },
  {
    "objectID": "posts/port_mg/index.html#incluir-una-inversión-sin-riesgo",
    "href": "posts/port_mg/index.html#incluir-una-inversión-sin-riesgo",
    "title": "Portfolio management",
    "section": "Incluir una inversión sin riesgo",
    "text": "Incluir una inversión sin riesgo\nUna inversión sin riesgo que gana una tasa de rendimiento garantizada \\(r\\) sería el punto F en la Figura 3. Si se nos permite mantener este activo en nuestra cartera, dado que la volatilidad de este activo es cero, obtenemos la nueva frontera eficiente que es la línea recta en la Figura 3. El portafolio para el que la línea recta toca la frontera eficiente original se denomina cartera de mercado. La linea recta en sí misma se llama la línea del mercado de capitales.\n\nDonde quiero estar en la frontera eficiente?\nHabiendo encontrado la frontera eficiente, queremos aber dónde debemos estar. Esta es una elección personal, la frontera eficiente es objetiva, dados los datos, pero la “mejor” posición en ella es subjetiva.\nLa siguiente es una forma de interpretar el diagrama de riesgo/recompensa que puede ser útil en la elección de la mejor cartera.\nEl rendimiento de la cartera se distribuye normalmente porque está compuesto por activos que se distribuyen normalmente. Tiene media \\(\\mu\\) y desviación estándar \\(\\sigma\\) (he ignorado la dependencia del horizonte T). La pendiente de la línea que une la cartera con el activo libre de riesgo es\n\\[\ns = \\frac{\\mu_{\\Pi} - r}{\\sigma_{\\Pi}}\n\\]\nEsta es una cantidad importante; es una medida de la probabilidad de tenter un rendimiento que exceda r. Si \\(C(.)\\) es la función acumulada para la distribución normal estandarizada, entonces \\(C(s)\\) es la probabilidad de que el rendimiento en \\(\\Pi\\) sea al menos q \\(r\\). Mas generalmente\n\\[\nC\\left(\\begin{array}{0}\\frac{\\mu_{\\Pi} - r^*}{\\sigma_{\\Pi}}\\end{array}\\right)\n\\]\nes la probabilidad de que el rendimiento exceda \\(r^*\\). Esto sugiere que si queremos minimizar la posibilidad de una rentabilidad inferior a \\(r^*\\) debemos elegir la cartera del conjunto de fronteras eficientes, \\(\\Pi_{eff}\\) con el mayor valor de la pendiente\n\\[\n\\frac{\\mu_{\\Pi_{eff}} - r^*}{\\sigma_{\\Pi_{eff}}}\n\\]\nPor el contrario, si mantenemos la pendiente de esta línea fija en \\(s\\), entonces podemos decir que con una confianza de \\(C(s)\\) no perderemos más que\n\\[\n\\mu_{\\Pi_{eff}} - s\\sigma_{\\Pi_{eff}}\n\\]\nNuestra elección de cartera podría determinarse maximizando esta cantidad. Estas dos estrategías se muestran esquemáticamente en la Figura 5.\n\n\n\nFigura 5: Dos sencillas formas de elegir la mejor cartera eficiente\n\n\nNinguno de estos métodos da resultados satisfactorios cuando existe inversión libre de riesgo entre los activos y hay ventas cortas sin restricciones, ya que dan como resultado un endeudamiento infinito.\nOtra forma de elegir la cartera óptima es con la ayuda de una función de utilidad. Este enfoque es popular entre los economistas. En la Figura 6 muestro las curvas de indiferencia y la frontera eficiente.\n\n\n\nFigura 6: Frontera eficiente y las curvas de indiferencia\n\n\nLas curvas reciben este nombre porque representan lineas a las cual el inversionista es indiferente al trade-off riesgo/recompensa. Un inversionista quiere un alto rendimiento y riesgo bajo. Frente a las carteras A y B en la Figura, ve a A con bajo rendimiento y bajo riesgo, pero B tiene una mejor recompensa a costa de un mayor riesgo. El inversor es indiferente entre estos dos. Sin embargo, C es mejor que ambos, estando en una curva preferida."
  },
  {
    "objectID": "posts/port_mg/index.html#markowitz-en-la-práctica",
    "href": "posts/port_mg/index.html#markowitz-en-la-práctica",
    "title": "Portfolio management",
    "section": "Markowitz en la Práctica",
    "text": "Markowitz en la Práctica\nLas entradas al modelo de Markowitz son rendimientos esperados, volatilidades y correlaciones. Con \\(N\\) activos esto significa \\(N + N + N(N-1)/2\\) parámetros. La mayoría de estos no se pueden conocer con precisión (¿existen siquiera?); sólo las volatilidades son en absoluto confiable. Habiendo ingresado estos parámetros, debemos optimizar sobre todos los pesos de los activvos en la cartera: Elija un riesgo de cartera y encuentre los pesos que haqcen que el rendimiento de la cartera sea máximo sujeto a esta volatilidad. Este es un proceso que consume mucho tiempo computacionalmente a menos que uno solo tenga una pequeña cantidad de activos.\nEl problema con la implementación práctica de este modelo lo realizaré enm otro post que publicare posterioremente, usando Python. Por los momentos es importante comprender la lógica del modelo."
  },
  {
    "objectID": "posts/port_mg/index.html#modelo-de-precios-de-activos-de-capital-capital-asset-pricing-model",
    "href": "posts/port_mg/index.html#modelo-de-precios-de-activos-de-capital-capital-asset-pricing-model",
    "title": "Portfolio management",
    "section": "Modelo de Precios de Activos de Capital (Capital Asset Pricing Model)",
    "text": "Modelo de Precios de Activos de Capital (Capital Asset Pricing Model)\nAntes de discutir el modelo de fijación de precios de activos de capital o CAPM debemos introducir la idea del valor \\(\\beta\\). El parámetro \\(\\beta_i\\), de un activo en relación con una cartera \\(M\\) es la relación de la covarianza entre el rendimiento del valor y el rendimiento de la cartera a la varianza de la cartera. Del siguiente modo\n\\[\n\\beta_i = \\frac{Cov[R_iR_M]}{Var[R_M]}\n\\]\n\nEl Modelo de Indice Unico\nAhora construire un modelo de índices único y describiré las extenciones más adelante. Voy a relacionar el rendimiento de todos los activos al rendimiento de un índice representativo, \\(M\\). Este índice suele ser tomado como un índice bursátil de amplio rango en el modelo de índice único. Nosotros escribimos el rendimiento del i-ésimo activo como\n\\[\nR_i = \\alpha_i + \\beta_iR_M + \\epsilon_i\n\\]\nUsando esta representación podemos ver que el rendimiento de un activo se puede descomponer en tres partes:\n\nUna media constante\nUna parte aleatoria común con el índice \\(M\\) y,\nuna parte aleatoria no correlacionada con el índice, \\(\\epsilon_i\\).\n\nLa parte aleatoria \\(\\epsilon_i\\) es única para el i-ésimo activo, y tiene media cero. Observe cómo todos los activos están relacionados con el índice \\(M\\) pero son de contrario completamente sin correlación.\nEn la Figura 7 se muestra un gráfico de rendimiento de las acciones de Walt Disney frente a los rendimientos del S&P 500; \\(\\alpha\\) y \\(\\beta\\) se pueden determinar a partir de un análisis de regresión lineal. Los datos utilizados en este gráfico abarcaron desde enero de 1985 hasta casi finales de 1997.\n\n\n\nFigura 7: Rentabilidad de las acciones de Walt Disney frente a la rentabilidad del S&P 500.\n\n\nEl rendimiento esperado del índice se denotará por \\(\\mu_M\\) y su desviación estándar por \\(\\sigma_M\\). El rendimiento esperado del i-ésimo activo es entonces:\n\\[\n\\mu_i = \\alpha_i + \\beta_i\\mu_M\n\\]\ny la desviación estandar\n\\[\n\\sigma_i = \\sqrt{\\beta_i^2\\sigma_M^2 + e_i^2}\n\\]\ndonde \\(e_i\\) es la desviación estándar de \\(\\epsilon_i\\).\nSi tenemos una cartera de dichos activos, el rendimiento viene dado por\n\\[\n\\begin{eqnarray}\n\\frac{\\delta \\Pi}{\\Pi} = \\sum_{i=1}^N W_iR_i = \\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\alpha_i\\end{array}\\right) + R_M\\left(\\begin{array}{0} \\sum_{i=1}^N W_i\\beta_i\\end{array}\\right) + \\sum_{i=1}^N W_i\\epsilon_i\n\\end{eqnarray}\n\\]\nDe esto se sigue que\n\\[\n\\mu_\\Pi = \\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\alpha_i\\end{array}\\right) + E[R_M]\\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\beta_i\\end{array}\\right)\n\\]\nPodemos escribir\n\\[\n\\alpha_\\Pi = \\sum_{i=1}^NW_i\\alpha_i \\hspace{1cm}y \\hspace{1cm} \\beta_\\Pi = \\sum_{i=1}^NW_i\\beta_i\n\\]\nEntonces,\n\\[\n\\mu_\\Pi = \\alpha_\\Pi + \\beta_\\Pi\nE[R_M] = \\alpha_\\Pi + \\beta_\\Pi \\mu_M\\]\nDe manera similar, el riesgo se mide por\n\\[\n\\sigma_\\Pi = \\sqrt{\\sum_{i=1}^N\\sum_{j=1}^N W_iW_j\\beta_i\\beta_j\\sigma_M^2 + \\sum_{i=1}^N W_i^2 e_i^2}\n\\]\nSi los pesos son casi iguales, \\(N^{-1}\\), entonces los términos finales dentro de la raíz cuadrada también son \\(O(N^{-1})\\). Por lo tanto, esta expresión es, al orden principal como \\(N \\longrightarrow \\infty\\),\n\\[\n\\sigma_\\Pi = \\left|\\begin{array}{0}\\sum_{i=1}^N W_i\\beta_i\\end{array}\\right|\\sigma_M = \\left|\\begin{array}{0}\\beta_\\Pi\\end{array}\\right|\\sigma_M\n\\]\nObserve que la contribución de los no correlacionados a la cartera se desvanece a medida que aumentamos le número de activos en la cartera: El riesgo asociado con el \\(\\epsilon_s\\) se llama riesgo diversificable. El riesgo restante, que esta correlacionado con el índice, se denomina riesgo sistematico.\n\n\nElegir la Cartera Optima\nEl principal es el mismo que el modelo de Markowitz para la elección óptima de cartera. La diferencia es que hay muchos menos parámetros para ingresar, y el cálculo es mucho más rapido.\nEl procedimiento es el siguiente. Elija un valor para el rendimiento de la cartera \\(\\mu_\\Pi\\). Sujeto a esta restricción, minimizar \\(\\sigma_\\Pi\\). Repita esta minimización para diferentes rendimientos de carteera para obtener la frontera eficiente. La posición es esta curva es entonces una elección subjetiva."
  },
  {
    "objectID": "posts/port_mg/index.html#medición-del-desempeño",
    "href": "posts/port_mg/index.html#medición-del-desempeño",
    "title": "Portfolio management",
    "section": "Medición del Desempeño",
    "text": "Medición del Desempeño\nSi uno ha seguido una de las estratetias de asignación de activos, o simplemente ha negociado en instinto, ¿puede uno decir qué tan bien lo ha hecho? ¿Fueron los resultados sobresalientes deido a un extraño instinto natural, o los horribles resultados fueron simplemente mala suerte?\nEl rendimiento ideal sería uno en el que los rendimientos superaran la tasa libre de riesgo, pero en una moda consistente. No solo es importante obtener un alto rendimiento de la gestión de la cartera, pero uno debe lograr esto con la menor aleatoriedad posible.\nLas dos medidas más comunes de rendimiento por unidad de riesgo son\n\nRelación de Sharpe de recompensa a variabilidad y el\níndice de Treynor de recompensa a la volatilidad.\n\nEstos se definen como\n\\[\n\\begin{eqnarray}\nratio Sharpe &=& \\frac{\\mu_\\Pi - r}{\\sigma_\\Pi}\\\\[0.2cm]\nratio Treynor &=& \\frac{\\mu_\\Pi - r}{\\beta_\\Pi}\n\\end{eqnarray}\n\\]\nEn estos \\(\\mu\\) y \\(\\sigma\\) son el rendimiento realizado y la desviación estándar de la cartera durante el período. El \\(\\beta\\) es una medida de la volatilidad de la cartera. El ratio de Sharpe generalmente se usa cuando la cartera es la totalidad de la inversión de uno y el ratio de Treynor cuando se examina el rendimiento de un componente de la cartera de toda la empresa, digamos.\nCuando la cartera baja las dos medidas son las mismas (hasta un factor del mercado Desviación Estándar)\n\n\n\nFigura 8: un buen y un gerente (manager); mismos rendimientos, distintas volatilidades\n\n\nLa Figura 8 muestra el valor de la cartera frente al tiempo para un buen administrador y un mal administrador."
  },
  {
    "objectID": "posts/port_mg/index.html#resumen",
    "href": "posts/port_mg/index.html#resumen",
    "title": "Portfolio management",
    "section": "Resumen",
    "text": "Resumen\n\nLa gestión de carteras y la asignación de activos consisten en asumir riesgos a cambio de una recompensa.\nLas preguntas son, ¿como decidir cuánto riesgo tomar? ¿cómo obtener el mejor rendimiento? Pero la teoría de los derivados se basa en no correr ningún riesgo en absoluto, por lo que he dedicado tiempo a gestión de cartera en este post.\nExiste tanta incertidumbre en el tema de las finanzas que la eliminación del riesgo es casi imposible y las ideas detrás de la gestión de carteras deben ser apreciadas por cualquier persona involucrada en derivados."
  },
  {
    "objectID": "posts/port_mg/index.html#definición",
    "href": "posts/port_mg/index.html#definición",
    "title": "Portfolio management",
    "section": "Definición",
    "text": "Definición\nEl valor en riesgo es una estimación, con un cierto grado de confianza, de cuánto se puede perder de la cartera, en un horizonte de tiempo dado.\n\nEl grado de confianza normalmente se establece en 95%, 87.5%, 99%, etc. El horizonte temporal de interés puede ser de un día, por ejemplo, para actividades comerciales o de meses para gestión de cartera.\nComo ejemplo de VaR, podemos calcular (mediane los métodos que e describirán aquí) que durante la próxima semana hay un 95% de probabilidad de que no perdamos más de $10 millones. Podemos escribir esto como\n\\[\nProb\\{\\delta V \\leq -\\$10 m\\} = 0.05\n\\]\ndonde \\(\\delta V\\) es el cambio en el valor de la cartera. (uso \\(\\delta\\) para “el cambio en” para enfatizar que estamos considerando cambios en un tiempo finito.) En símbolos, esto es\n\\[\nProb\\{\\delta V \\leq -VaR\\}= 1- c\n\\]\ndonde el grado de confianza es \\(c\\).\nEl VaR se calcula asumiendo circustancias de mercado normales, lo que significa que el mercado extremo no se consideran condiciones como choques, o se examinan por separado. Así, efectivamente, el VaR mide lo que se puede esperar que suceda durante la operación diaria de una institución.\nPara el computo del VaR requerimos disponer al menos de los siguientes datos:\n\nLos precios vigentes de todos los activos en cartera y,\nsus volatilidadesa y correlaciones entre ellos\n\nSi los bienes son negociados podemos tomar los precios del mercado (marking to market).\nPor lo general, se supone que el movimiento de los componentes de la cartera son aleatorias y extraídas de distribuciones normales."
  },
  {
    "objectID": "posts/port_mg/index.html#var-para-un-único-activo",
    "href": "posts/port_mg/index.html#var-para-un-único-activo",
    "title": "Portfolio management",
    "section": "VaR para un único activo",
    "text": "VaR para un único activo\nEmpecemos por estimar el VaR de una cartera compuesta por un único activo.\nSupongamos que tenemos una cantidad de una acción con precio \\(S\\) y volatilidad \\(\\sigma\\). Queremos saber con el 99% de confianza cuál es el máximo que podemos perder durante la próxima semana, estoy usando notación deliberadamente similar al del mundo de los derivados\n\\[\n\\sigma S\\left(\\begin{array}{0}\\frac{1}{52}\\end{array}\\right)^{1/2}\n\\]\nya que el paso de tiempo es \\(1/52\\) de un año. Finalmente, debemos calcular la posición de la cola extrema izquierda de esta distribución correspondiente a\n\\[\n1\\% = 100 - 99\\%\n\\]\nSolo necesitamos hacer esto para la distribución normal estandarizada, porque podemos llegar a cualquier otra distribución escalando. En la siguiente tabla, vemos que el intervalo de confianza del 99% corresponde a 2.33 desviaciones estándar de la media.\n\nGrado de confianza y la relación con la desviación de la media.\n\n\nGrado de Confianza (%)\nNúmero de desviaciones estándar de la media\n\n\n\n\n99\n2.326342\n\n\n98\n2.053748\n\n\n97\n1.88079\n\n\n96\n1.750686\n\n\n95\n1.644853\n\n\n90\n1.281551\n\n\n\n\n\n\n\nDado que tenemos una cantidad de acciones, el VaR es dado por\n\\[\n2.33\\sigma\\triangle S(1/52)^{1/2}\n\\]\nDe manera general, si el horizonte de tiempo es \\(\\delta t\\) y el grado de confianza es \\(c\\), tenemos\n\\[\nVaR = -\\sigma \\triangle S(\\delta t)^{1/2}\\alpha(1-c)\n\\]\ndonde \\(\\alpha(.)\\) es la función de distribución acumulativa inverdsa para la distribución Normal estandarizada, que se muestra en la Figura 9,\n\n\n\nFigura 9: Función de distribución acumulativa inversa para la distribución Normal Estandarizada.\n\n\nEn la Figura 10 hemos supuesto que el rendimiento del activo se distribuye normalmente con una media cero. La suposición de media cero es válida para horizontes temporales cortos: La desviación estándar del rendimiento escala con la raíz cuadrada del tiempo pero la media escala con el tiempo mismo.\n\n\n\nFigura 10: La distribución de los rendimientos futuros de las acciones.\n\n\nPara horizontes a más largo plazo, el rendimiento se desplaza hacia la derecha (es de esperar) en una cantidad proporcional al horizonte de tiempo. Por lo tanto, para escalas de tiempo más largas, la ecuación anterior debe modificarse para tener en cuenta el derivado del valor del activo. Si la tasa de este derivado es \\(\\mu\\) entonces la ecuación anterior se convierte en\n\\[\nVaR = \\triangle S(\\mu \\delta t - \\sigma \\delta t^{1/2} \\alpha(1-c))\n\\]"
  },
  {
    "objectID": "posts/port_mg/index.html#var-para-un-portafolio-o-cartera",
    "href": "posts/port_mg/index.html#var-para-un-portafolio-o-cartera",
    "title": "Portfolio management",
    "section": "VaR para un Portafolio o Cartera",
    "text": "VaR para un Portafolio o Cartera\nSi conocemos las volatilidades de todos los activos de nuestra cartera y las correlaciones entre ellos entonces podemos calcular el VaR para toda la cartera.\nSi la volatilidad del i-ésimo activo es \\(\\sigma_i\\) y la correlación entre el i-ésimo y el j-ésimo activo es \\(\\rho_{ij}\\) (con \\(\\rho_{ii} = 1\\)), entonces el VaR para la cartera compuesta por M activos con una participación de i del i-ésimo activo es\n\\[\n-\\alpha(1-c)\\delta t^{1/2}\\sqrt{\\sum_{j=1}^M\\sum_{i=1}^M \\triangle_i\\triangle_j\\sigma_i\\sigma_j\\rho_{ij}S_iS_j}\n\\]"
  },
  {
    "objectID": "posts/port_mg/index.html#uso-del-var-como-medida-de-rendimiento",
    "href": "posts/port_mg/index.html#uso-del-var-como-medida-de-rendimiento",
    "title": "Portfolio management",
    "section": "Uso del VaR como medida de rendimiento",
    "text": "Uso del VaR como medida de rendimiento\nUno de los usos del VaR en la medición del desempeño de bancos, mesas o comerciantes. En el pasado, el “talento comercial” se ha medido únicamente en términos de ganancias; la bonificación de un comerciante esta relacionado con esa ganancia. Esto anima a los comerciante a asumir riesgos; piensa en lanzar una moneda al aire y recibes un porcentaje de la ganancia pero sin la desventaja (que se lleva el banco), ¿cuánto apostarías? Una mejor medida del talento comercial podría tener en cuenta el riesgo en tal apuesta, y premiar una buena relación rendimiento-roesgo. El ratio\n\\[\n\\frac{\\mbox{Retorno superior al libre de riesgo}}{volatilidad} = \\frac{\\mu - r}{\\sigma}\n\\]\nLa relación de Sharpe, es una medida de este tipo. Alternativamente, use VaR como la medida de riesgo y ganancia/pérdida como medida de rendimiento.\n\\[\n\\frac{\\mbox{Perdidads y ganancias diarias}}{\\mbox{VaR diaria}}\n\\]"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Microeconomía Intermedia con R",
    "section": "",
    "text": "Una forma de iniciar el análisis de los individuos es plantear un conjunto básico de postulados, o axiomas, que describen el comportamiento racional del mismo. Supondremos que dadas tres canastas de consumo cualesquiera \\((x_1,x_2)\\), \\((y_1,y_2)\\) y \\((z_1,z_2)\\). El consumidor puede ordenarlas según su atractivo. Es decir, puede decidir que una de ellas es estrictamente mejor que la otra o bien que le son indiferentes.\nUtilizaremos la notación:\n\n\\(\\succ\\) Para indicar que una canasta se prefiere estrictamente a otra, es decir, \\((x_1,x_2) \\succ (y_1,y_2)\\).\n\\(\\sim\\) Para indicar que al consumidor le resulta indiferente elegir una u otra de las dos canastas de bienes y lo representamos matemáticamente como \\((x_1,x_2)\\sim (y_1,y_2)\\).\n\\(\\succeq\\) Para indicar si el individuo prefiere una de las dos canastas o es indiferente entre ellas, decimos que prefiere debilmente la canasta \\((x_1,x_2)\\) a la \\((y_1,y_2)\\) y escribimos \\((x_1,x_2)\\succeq (y_1,y_2)\\).\n\n\n\nCon base en lo anterior, ya estamos preparados para conocer los tres axiomas de la teoría del consumidor. Decimos que las preferencias son:\n\nCompletas: suponemos que es posible comprar dos canastas cualesquiera, es decir, dada cualquier canasta \\(\\textbf{X}\\) y cualquier canasrta \\(\\textbf{Y}\\), suponemos que \\((x_1,x_2)\\succeq (y_1,y_2)\\) o \\((y_1,y_2) \\succeq (x_1,x_2)\\) o las dos cosas, en cuyo caso el consumidor es indiferente entre las dos canastas.\nReflexivas: suponemos que cualquier canasta es al menos tan buena como ella misma: \\((x_1,x_2)\\succeq (y_1,y_2)\\).\nTransitiva: si \\((x_1,x_2)\\succeq (y_1,y_2)\\) y \\((y_1,y_2)\\succeq (z_1,z_2) \\Longrightarrow (x_1,x_2)\\succeq (z_1,z_2)\\). Es decir, si el consumidor piensa que la canasta \\(\\textbf{X}\\) es al menos tan buena como la \\(\\textbf{Y}\\) y que la \\(\\textbf{Y}\\) es al menos tan buena como la \\(\\textbf{Z}\\), piensa que la \\(\\textbf{X}\\) es al menos tan buena como la \\(\\textbf{Z}\\).\n\nConsidere que cuando nos referimos a las canastas \\(\\textbf{X}, \\textbf{Y}\\) o \\(\\textbf{Z}\\) estamos haciendo referencia a:\n\n\\(\\textbf{X} = (x_1,x_2)\\)\n\\(\\textbf{Y} = (y_1.y_2)\\)\n\\(\\textbf{Z} = (z_1,z_2)\\)\n\nSi las preferencias no fueran transitivas, podría muy bien haber un conjunto de canastas tal que ninguna de las elecciones fuera la mejor. Sin embargo, en el curso de microeconomía II estamos trabajando bajo el modelo tradicional, donde asumimos que el individuo es razonal, tomando en cuenta que siempre va a preferir mas que menos.\n\n\n\nEl primer axioma, la completitud, es dificilmente criticable, al menos en el caso de los tipos de elecciones que suelen analizar los economistas. Decir que pueden compararse dos canastas cualesquiera es decir simplemente que el consumidor es capaz de elegir entre dos canasas cualesquiera.\nEl segundo axioma, la reflexividad, plantea más problemas. Una canasta cualquiera es ciertamente tan buena como una canasta idéntica.\nEl tercer axioma, la transitividad, plantea más problemas. No esta claro que las preferencias deban tener necesariamente esta propiedad. El supuesto de que son transitivas no parece evidente desde un punto de vista puramente lógico, y, de hecho, no lo es. La transitividad es una hipótesis sobre la conducta de los individuos en sus elecciones y no una afirmación lógica. Sin embargo, no importa que sea o no un hecho lógico básico; lo que importa es que sea o no una descripción razonablemente exacta del comportamiento de los individuos.\n¿Qué pensarías de una persona que dijera que prefiere la canasta \\(\\textbf{X}\\) a la \\(\\textbf{Y}\\) y la \\(\\textbf{Y}\\) a la \\(\\textbf{Z}\\), pero que también dijera que prefiere la \\(\\textbf{Z}\\) a la \\(\\textbf{X}\\)? Desde luego, lo consideraríamos como prueba de una conducta particular. Y lo que es más importante, ¿Cómo se comportaría este consumidor si tuviera que elegir entre las tres canastas \\(\\textbf{X}, \\textbf{Y}\\) y \\(\\textbf{Z}\\)?"
  },
  {
    "objectID": "posts/post-with-code/index.html#curvas-de-indiferencia",
    "href": "posts/post-with-code/index.html#curvas-de-indiferencia",
    "title": "Microeconomía Intermedia con R",
    "section": "Curvas de Indiferencia",
    "text": "Curvas de Indiferencia\nCon base en la definición previa de utilidad, podemos concluir, una función de utilidad es la que explica la cantidad de utilidad que posee un consumidor dado su consumo de dos bienes diferentes. \\(x, y\\). Una curva de indiferencia es solo una rebanada infenitesimal de esa función que describe todas las diferentes combinaciones entre dos bienes que producen la misma cantidad de utilidad (es decir, a la que una persona sería indiferente).\nSupongamos que una persona clasifica las hamburguesas \\((y)\\) y las bebidas \\((x)\\) de acuerdo con la función de utilidad\n\\[\nU(x,y) = \\sqrt{xy}\n\\]\nEn el caso de esta función, obtenemos la curva de indiferencia identificando un conjunto de combinaciones de \\(x,y\\) en el cual la utilidad tiene el mismo valor. Suponga que arbitrariamente decimos que la utilidad tiene un valor de 10. Entonces, la ecuación de esta curva sera:\n\\[\nU(x,y) = 10 = \\sqrt{xy}\n\\]Note que si elevamos esta función al cuadrado se mantiene el mismo orden, por lo cual también podemos representar esta curva de indiferencia como\n\\[\n100 = xy\n\\]\nEs importante siempre despejar este tipo de ecuaciones para \\(y\\) la importancia esta en que será mucho más facil posteriormente encontrar su tasa marginal de sustitución ( en otra sección de esta publicación estudiaremos a detalle esto), entonces, al despejar obtenemos:\n\\[\ny = \\frac{100}{x}\n\\]\nPara trazar su curva de indiferencia, lo haremos en R , a continuación les muestro como hacerlo. Puedes realizar este ejercicio en tu PC tu mismo.\n\n# 1. Primero cargamos las librerias que utilizaremos, en caso que nos las tengas \n#    instaladas sugiero lo hagas usando install.package(\"libreria\") en su consola\n#    de Rstudio.\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(tidyverse)\nlibrary(plotly)\n\n# 2. Creamos la función de utilidad del ejemplo \nutilidad <- function(x,y){\n  sqrt(x*y) \n}\n\n# 3. Creamos una matriz para hacer un bucle en la función de utilidad\nvalores_matriz <- matrix(0,nrow = 200, ncol = 200)\n\n# 3.1 Llenamos la matriz con usando la función de utilidad \nfor(fila in 1:nrow(valores_matriz)){\n  for(columna in 1:ncol(valores_matriz)){\n    valores_matriz[fila,columna] <- utilidad(fila,columna)\n  }\n}\n\n# 4. Función que nos permitira graficar las curvas de indiferencia \n\nC_indiferencia <- function(entrada_utilidad){\n  y <- c()\n  \n  for(i in 1:50){\n    y_coord <- entrada_utilidad^2/i\n    y       <- c(y,y_coord)\n  }\n  \n  data <- data.frame(\n    x = 1:50,\n    y = y,\n    z = rep(entrada_utilidad,50)\n  )\n  \n  return(data)\n}\n\n\n# 4.1 Resultado de utilidades obtenidas \nlista_utilidades <- lapply(10, C_indiferencia)\n\nfull_df <- do.call(rbind, lista_utilidades)\n\nAhora si ya estamos preparados para graficar nuestras curvas de indiferencia para \\(10 = \\sqrt{xy}\\)\n\n# 5. Gráfico\n\nggplot() + \n  geom_point(data = full_df, aes(x = x, y = y, color = z)) + \n  geom_path(data = full_df, aes(x = x, y = y, color = z)) +\n  theme_minimal()+\n  ylim(0,100) + \n  labs(x = \"Bebidad\", y = \"Hamburguesas\") + \n  scale_color_continuous(name = \"Utilidad\")\n\n\n\n\nNote que la curva previa representa una utilidad = 10.\nA continuación te muestro un grafico animado de la curva de indiferencia previa. Para generar el gráfico presiona el boton PLAY.\n\n\n\n\n\n\nVeamos que sucede cuando tenemos diferentes niveles de utilidad, en base al resultado usted puede deducir su propio análisis.\n\nutilidad <- function(x,y){\n  sqrt(x*y) \n}\n\nvalores_matriz <- matrix(0,nrow = 200, ncol = 200)\n\nfor(fila in 1:nrow(valores_matriz)){\n  for(columna in 1:ncol(valores_matriz)){\n    valores_matriz[fila,columna] <- utilidad(fila,columna)\n  }\n}\n\nC_indiferencia <- function(entrada_utilidad){\n  y <- c()\n  \n  for(i in 1:100){\n    y_coord <- entrada_utilidad^2/i\n    y       <- c(y,y_coord)\n  }\n  \n  data <- data.frame(\n    x = 1:100,\n    y = y,\n    z = rep(entrada_utilidad,100)\n  )\n  \n  return(data)\n}\n\nlista_utilidades <- lapply(seq(from =10, to = 60, by = 10), C_indiferencia)\n\nfull_df <- do.call(rbind, lista_utilidades)\n\n\nggplot() +\n  geom_point(data = full_df, aes(x = x, y = y, color = z)) +\n  geom_path(data = full_df, aes(x = x, y = y, color = z)) +\n  theme_minimal() +\n  ylim(0,200) +\n  labs(x = \"Bebidas\", y = \"Hamburguesas\") +\n  scale_color_continuous(name = \"Utilidad\")\n\n\n\n\nAquí podemos señalar lo siguiente:\n\nA medida que aumenta la utilidad, las curvas se desplazan hacia la derecha y hacia la izquierda a medida que disminuye la utilidad.\nObserve que las curvas se inclinan hacia abajo, esto debe ser necesariamente el caso; a medida que uno aumenta su consumo de bebidas renuncia al otro bien que les era indiferente, hamburguesa.\nTodo lo que está debajo de la curva representa paquetes con menos utilidad. La teoría de la utilidad asume que un consumidor siempre buscará maximizar la utilidad.\nComprende que la pendiente no es lineal. En genera, cuanto más se tiene de algo, menos utilidad se obtendrá de otra unidad y, por el contrario, más se renunciaría a adquirir el otro bien. Esta pendiente tiene un nombre oficial: Tasa Marginal de Sustitución o TMS hablaremos de esto en una sección posterior.\n\nPero esas son solo algunas rebanadas que ya he señalado como infinitesimalmente pequeñas.\nPara concluir esta sección te dejo un gráfico animado de los diferentes niveles de utilidad, por favor presiona el boton PLAY para que logres verlo."
  },
  {
    "objectID": "posts/post-with-code/index.html#tasa-marginal-de-sustitución-tms",
    "href": "posts/post-with-code/index.html#tasa-marginal-de-sustitución-tms",
    "title": "Microeconomía Intermedia con R",
    "section": "Tasa Marginal de Sustitución (TMS)",
    "text": "Tasa Marginal de Sustitución (TMS)\nOtro concepto importante en la teoría del consumidor es la Tasa Marginal de Sustitución (TMS). Matemáticamente esto es la pendiente de la curva de indiferencia, sin embargo, en términos microecnómicos esta pendiente se refiere a la relación de cambio entre un bien \\(x\\) y el bien \\(y\\), es decir, cuanto del bien x se tiene que sacrificar (aumentar) para aumentar (disminuir) el consumo del bien y para aumentarse en el mismo nivel de utilidad.\nEn términos matemáticos la TMS se define como:\n\\[\nTMS = -\\left.\\begin{array}{c}\\frac{dy}{dx} \\end{array}\\right|_{U = U_1}\n\\]\ndonde la notación indica que la pendiente se debe calcular a lo largo de la cuva de indiferencia \\(U_1\\).\nUn ejercicio interesante para el lector, seria intentar probar la identidad de \\(TMS\\) que acabamos de definir.\n\nMúltiples Curvas de Indiferencia\nHay una curva de indiferencia que pasa por cada punto del plano \\(xy\\). Cada una de estas curvas muestra combinaciones de \\(x\\) y \\(y\\) que proporcionan al individuo determinado nivel de satisfación como se vio en graficos anteriores. Los movimientos en dirección noreste representan movimientos hacia niveles más altos de satisfación.\n\n\n\nEl cambio de la pendiente a lo largo de U1 muestra que la canasta de consumo disponible afecta los intercambios que esta persona realizará libremente\n\n\nDado que ya conocemos en que consiste la TMS, y a este punto asumo que el lector ya tiene idea de como realizar el computo manual de la TMS para una función de utilidad dada. Entonces, procederemos a realizar el computo de la TMS en R, para el computo se procederá a crear una función que resuelva el problema más rapidamente, ya que como usted se ha podido dar cuenta se necesita y usar calculo diferencial (derivadas).\nLa función que crearemos para realizar el computo de la TMS la llamaremos TMS, veamos como hacerlo en R.\n\nTMS <- function(fun.utilidad, bien_x) {\n  U  <- parse(text = fun.utilidad)\n  v1 <- D(U, \"x\")                       # D() función que realiza la derivada de U\n  print(paste(\"TMS = \", \n              eval(v1, envir = list(x = bien_x)), \"considerando\", \n              bien_x, \"unidades del bien x\"))\n}\n\nDel bloque de código previo:\n\nTMS: función que calcula la tasa marginal de sustitución.\nfun.utilidad: función de la curva de indiferencia (y en función de x). Tiene que especificarse en caracteres.\nbien_x: unidades del bien x en donde se evaluara la TMS.\n\n\n\nEjemplo\nconsideremos la siguiente función de utilidad con su respectivo nivel de utilidad\n\\[\nU(x,y) = 10 = \\sqrt{xy}\n\\]\nSi calculamos la TMS de esta curva de indiferencia de manera manual tendremos:\n\\[\nTMS = -\\frac{\\frac{\\partial U}{\\partial x}}{\\frac{\\partial U}{\\partial y}} = -\\frac{100}{x^2}\n\\]\nComo se puede dar cuenta la TMS depende de “x”, lo que indica que tenemos que variar “x” positiva o negativamente , con el fin de obtener menos o más de “y” y mantenernos en la misma utilidad de 10.\nSi evaluamos la TMS cuando el bien “x” es igual a 5, entonces, la TMS sera de\n\\[\nTMS = -\\frac{100}{5^2} = -4\n\\]\nEsto implica, que si aumentamos el consumo del bien “x” en 1 tendremos que disminuir el consumo del bien y en 4. Veamos este ejemplo en R.\n\n# bien_x = 5\n# Utilizamos la función TMS que creamos previamente \n\nTMS(fun.utilidad = \"100/x\", 5)\n\n[1] \"TMS =  -4 considerando 5 unidades del bien x\"\n\n\nNote que el resultado es el deseado. Pero si queremos ver como varía la TMS para distintas cantidades del bien “x”, podemos hacer pequeñas variaciones a la función (TMS) que definimos en el primer bloque de código de esta sección.\n\nVar_TMS <- function(fun.utilidad, bien_x){\n  U  <- parse(text = fun.utilidad)\n  v1 <- D(U, \"x\")\n  eval(v1, envir = list(x = bien_x))\n}\n\n\n# Veamos el comportamiento de la TMS cuando variamos el bien x\n\nw <- c()\nfor (i in seq(60, 10, -10)){\n  t <- Var_TMS(fun.utilidad = \"100/x\",i)\n  w <- c(w,t)\n}\n\nw\n\n[1] -0.02777778 -0.04000000 -0.06250000 -0.11111111 -0.25000000 -1.00000000\n\n\nVeamos que a medida que el bien x pasa de ser abundante a ser un bien escazo cada vez le resulta al consumidor más relevante y si desea obtener una unidad adicional del bien x tendrá que renunciar a más cantidad del bien y. Es así que si el consumidor tiene solo un bien, cambiará este bien siempre y cuando reciba cien unidades del bien y.\nEn la siguiente sección de este post verá el tema de maximización de la utilidad dado una restricción presupuestaria. Es decir, desarrollamaremos el cálculo óptimo de los bienes, que maximizan la función de utilidad."
  },
  {
    "objectID": "posts/r/index.html",
    "href": "posts/r/index.html",
    "title": "Introducción a R",
    "section": "",
    "text": "R es un lenguaje y un ambiente para el manejo de datos, cálculos, y gráficos en código libre. Dada estas características los desarrollos que se han realizado en R son abiertos y están disponibles gratuitamente, por lo cual su uso se ha difundido ampliamente. R es difundido libremente por una gran diversidad de sitios espejo del CRAN (The comprehensive R Archive Network: red de servidores en todo el mundo que almacenan versiones id’enticas y actualizadas de código y documentación para R). Además, de ser gratuitos, los desarrollos en R se actualizan más rápido que cualquier otro de los costosos softwares comerciales que se encuentran en el mercado. Esto es así debido a que los usuarios hacen desarrollos, los documentan y los difunden en su red especializada de manera cotidiana (Quintana y Mendoza, 2016,p.23).\nAntes de comenzar a programar es bueno conocer los aspectos básicos del software que se esta utilizando como son: el ambiente, el funcionamiento de las herramientas de ayuda y la sintaxis básica, necesaria para el desarrollo de cualquier proyecto. En la práctica, la programación en R no es dificil solo hace falta acostumbrarse al ambiente y familiarizarse a la sintaxis, la cual trataremos en este material.\n\n\n\nEs software libre y por tanto su costo es nulo. \nEs multiplataforma: existen versiones para LinuX, Mac y Windows. Los procedimientos y análisis desarrollados en una plataforma son perfectamente desarrollables en otra. \nImplementa una enorme cantidad de métodos estadísticos, desde los más clasicos a los más modernos. Los métodos se organizan en librerías cuyo número se encuentra en constante crecimiento.\n\nCapacidad para acceder a datos en múltiples formatos. Dispone de librerías para leer datos desdes SPSS,SAS,Access, MySQL,Excel, etc. A si mismo permite también la generació de informes de resultados en diversos formatos.\n\nEnorme capacidad para manipular y modificar datos y funciones.\n\nGeneración de gráficos de alta calidad.\n\nExistencia de una comunidad de usuarios muy activa, en la que participan estadísticos de renombre.\n\nAmplia disponibilidad de documentación, tanto en internet como en libros publicados por editoriales de prestigio. \nFacilidad de integración con actividad de formación en técnicas y métodos estadísticos en todos los ámbitos del conocimiento.\n\nExistencia de extensiones específicas para nuevas áreas como modelos gráficos o análisis de mercados financieros.\n\nTodos los algoritmos implementados en R pueden ser vistos e interpretados por cualquier usuario, por lo que este puede saber exactamente que es lo que hace el ordenador cuando ejecuta un comando.\n\n\n\n\n\nHay empresas que por políticas no pueden instalar software libre en sus maquinas cada una tiene su politica, sus software de preferencia, sus necesidades, etc.\n\nAlgunas de las instituciones del sector público y privado tienen un dilema. por parte necesitan ahorrar recursos y por otra parte tienen que contar con soporte técnico por el que pagan fortunas. La idea del soporte es tener el apoyo y mantenimiento por si algo sale mal tanto en la aplicación del software como en la administración de los sistemas. Por eso pagan licencias costosas por SAS, STATA y otros paquetes.\n\nUna de las principales desventajas es que hasta hace poco el uso de R estaba limitado a entornos universitarios y de usuarios con gran conocimiento de la estadística y la programación. Junto a esto, su primera impresión entre los usuarios principiantes, es de dureza y poca amigabilidad, aunque esto queda superado con el uso.\n\nNo hay nadie a quien reclamar si algo falla, ni hay un departamento de atención al cliente que nos diga qué podemos hacer si algo va mal, si alguién procedimiento nos da un error, o simplemente si no sabemos qué sintaxis utilizar. Pero a cambio existe una comunidad de usuarios organizada en foros y dispuesta a colaborar desinteresadamente en la resolución de problemas.\n\nA todos los puntos anteriores podemos añadir el siguiente, que será considerado por unos una ventaja y por otros un inconveniente: Para hacer un buen uso de R hay que tener un buen conocimiento de los métodos estadísticos. En realidad esta afirmación es cierta no sólo para R, sino para cualquier paquete estadístico.\n\n\n\n\nPara realizar la instalación de R y RStudio en Windows,Mac, Ubuntu o Linux se debe ingresar a los siguientes sitios web:\n\nInstalación de R\nInstalación de RStudio\n\n\n\n\nRPermite obtener ayuda para conocer toda la información (qué hace, cuál es la sintaxis correcta, qué parámetros tiene, algunos ejemplos de uso, etcétera) sobre una función, objeto o librería.\nExisten cinco funciones para obtener ayuda las cuales son:\n\nhelt.start()\n\n\nUtilizando esta función se encuentra un menú de recursos, entre los cuales existen manuales, referencias y demás material para comenzar a aprender R.\n\nescribe en tu consola de RStudio help.start()\n\nhelp(¨nombre del objeto¨)\n\n\nEsta función facilita obtener información acerca de las funciones de los paquetes ya instalados en R. Si se desea obtener información acerca de una función, por ejemplo de la función plot(), se debe escribir help(“plot”) o ?plot en la línea de comandos.\n\nexample(\"nombre de la función\")\n\n\nPara obtener ejemplos del uso de funciones, se utiliza la función example (). Porejemplo, escribeexample(“array”).\n\nexample(\"array\")\n\n\narray> dim(as.array(letters))\n[1] 26\n\narray> array(1:3, c(2,4)) # recycle 1:3 \"2 2/3 times\"\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    2    1\n[2,]    2    1    3    2\n\narray> #     [,1] [,2] [,3] [,4]\narray> #[1,]    1    3    2    1\narray> #[2,]    2    1    3    2\narray> \narray> \narray> \n\n\n\nlibrary(help = \"nombre\")\n\n\nOtra manera de obtener información de ayuda sobre un paquete es usar la opción help para el comando library(), con lo cual tendrás información más completa. Un ejemplo es library(help=“stats”).\n\nlibrary(help=\"stats\")\n\n\nvignette(“nombre de la librer ́ıa”)\n\n\nAlgunos paquetes ya instalados en R incluyen viñetas dentro del ordenador. Una viñeta es un documento corto que describe como se usa un paquete. Se puede ver una viñeta usando la función vignette(). Escribe vignette(“Sweave”) en la línea de comandos.\n\nvignette(\"Sweave\")\n\n\n\n\nLa forma correcta de almacenar valores, es a través de una asignación la cual se realiza especificando el símbolo <-. Del lado izquierdo del símbolo se especifica el nombre de la variable y del lado derecho se introduce el valor u operación.\n\nSe puede trabajar con una gran cantidad de operadores matemáticos que utiliza R y que permite realizar cálculos matemáticos, por mencionar algunos, se pueden observar en el siguiente cuadro\n\n\n\nOperador Matemático\nFunción en R\n\n\n\n\n\\(\\sqrt{x}\\)\nsqrt()\n\n\n\\(e^x\\)\nexp(x)\n\n\n\\(x!\\)\nfactorial(x)\n\n\n\\(logaritmo(x)\\)\nlog(x)\n\n\n\\(\\pi\\)\nPi\n\n\n\\(|x|\\)\nabs(x)\n\n\n\\(seno(x)\\)\nsin(x)\n\n\n\\(coseno(x)\\)\ncos(x)\n\n\n\\(tangente(x)\\)\ntan(x)\n\n\n\\(cos^{-1}(x)\\)\nacos(x)\n\n\n\\(sen^{-1}(x)\\)\nasin(x)\n\n\n\\(tan^{-1}(x)\\)\natan(x)\n\n\n\nAsignar un valor a cierta cantidad de variables por ejemplo: a una variable \\(w\\) el valor 3, a la variable \\(y\\) el valor 7 y a la variable \\(z\\) el valor 90, a una variable \\(suma\\) la adición de las variables anteriores y finalmente obtendremos la raíz cuadrada de la variable \\(suma\\) guardándola en una variable con el nombre raíz.\nA continuació le muestro el ejemplo en R\n\nw <- 3   # Para evaluar la instrucción se debe presionar la tecla Control + ENTER.\nw        # Para observar el valor de la variable nombra la variable.\n\n[1] 3\n\ny <- 7\ny\n\n[1] 7\n\nz <- 90 \nz\n\n[1] 90\n\nsuma <- w + y + z\nsuma\n\n[1] 100\n\nraiz <- sqrt(suma)\nraiz\n\n[1] 10\n\n\nEn la primera línea se observa el simbolo (#), el cual permite comentar el código, para tomar notas de interés.\nEn R tamién se puede almacenar cadenas de caracteres como se muestra en el siguiente ejemplo:\n\na <- \"Cálculo\"\na\n\n[1] \"Cálculo\"\n\nb <- \"Microeconomía\"\nb\n\n[1] \"Microeconomía\"\n\n\nPara obtener un listado o desplegado de las variables que han sido definidas en la sesio ́n se debe de escribir el comando ls().\n\nls()\n\n[1] \"a\"    \"b\"    \"raiz\" \"suma\" \"w\"    \"y\"    \"z\"   \n\n\n\n\n\nUn vector es una secuencia ordenada de datos, los cuales han de ser del mismo tipo, es decir, todos deben de ser números, caracteres, cadenas de caracteres, valores lógicos, etc. Los tipos de datos que se pueden almacenar en un vector se destacan los siguientes:\n\nlogical (lógicos: TRUE, verdadero, o FALSE, falso)\ninteger (números enteros)\nnumeric (números reales)\ncharacter (palabras)\n\n\n\nLa forma correcta de almacenar un conjunto de datos, es a través de una asignación utilizando el comando c, donde dicha lista de números se almacenan bajo nombre, y así mismo este se utiliza para referirse a los datos que almacena, la asignación se realiza especificando el símbolo <-.\n\nPara generar un vector utilizamos la función c separado cada uno de los elementos por medio de una coma (,) por ejemplo si se quisiera almacenar la secuencia \\(0,1,2,3,4,5,6,7,8,9\\) dentro de un vector llamado \\(vector\\)\n\nvector <- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\nvector\n\n [1] 0 1 2 3 4 5 6 7 8 9\n\n\nSi se desea crear un vector de letras, palabras o cadenas de caracteres llamadas string, se tiene que nombrar cada cadena de caracteres entre comillas de manera obligatoria\n\nvectorletra <- c(\"a\", \"b\", \"c\", \"d\", \"e\")\nvectorletra\n\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\nvectorpalabra <- c(\"Micro\", \"Economía\", \"en\", \"R\")\nvectorpalabra\n\n[1] \"Micro\"    \"Economía\" \"en\"       \"R\"       \n\n\nSe puede facilitar la creación de vectores podemos utilizar c(a:b) para datos de manera consecutiva, el comando seq(a, b, by = p) de manera aritmética, donde \\(a\\) es el primer elemento, \\(b\\) es el último elemento y \\(p\\) es la diferencia de cada elemento.\n\nw <- c(0:10)\nw\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\ny <- seq(0, 100, by = 10)\ny\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\n\n\n\n\nSe pueden realizar operaciones como suma, resta, producto de vectores, se utilizaran los vectores \\(w\\) e \\(y\\) para ejemplificar las operaciones.\n\nsuma <- w + y\nsuma \n\n [1]   0  11  22  33  44  55  66  77  88  99 110\n\nresta <- w - y\nresta\n\n [1]   0  -9 -18 -27 -36 -45 -54 -63 -72 -81 -90\n\nproducto <- w*y\nproducto\n\n [1]    0   10   40   90  160  250  360  490  640  810 1000\n\n\nEl manejo de vectores en R tiene una propiedad muy útil: podemos aplicar una función a todos los elementos de un vector en un solo paso.\n\nw + 5\n\n [1]  5  6  7  8  9 10 11 12 13 14 15\n\nw - 2\n\n [1] -2 -1  0  1  2  3  4  5  6  7  8\n\n10*w\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\nsqrt(w)\n\n [1] 0.000000 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751\n [9] 2.828427 3.000000 3.162278\n\nw^2\n\n [1]   0   1   4   9  16  25  36  49  64  81 100\n\n\nEntre otras funciones para aplicar a vectores, y de gran importancia son las relacionadas principalmente con la estadística. Por ejemplo\n\nmax y min calculan sus valores maximos y minimos respectivamente\nsum calcula la suma\nprod calcula el producto\nmean calcula la media\ndiff calcula el vector formado por las diferencias sucesivas entre entradas del vector original.\nsort ordena los elementos del vector en el orden natural creciente del tipo de datos que lo forman, se puede incluir en su argumento el parámetro decreasing = TRUE.\n\n\nw\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nmax(w)\n\n[1] 10\n\nmin(w)\n\n[1] 0\n\nsum(w)\n\n[1] 55\n\nprod(w)\n\n[1] 0\n\nmean(w)\n\n[1] 5\n\ndiff(w)\n\n [1] 1 1 1 1 1 1 1 1 1 1\n\nsort(w)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nsort(w, decreasing = TRUE)\n\n [1] 10  9  8  7  6  5  4  3  2  1  0\n\n\n\n\n\n\nLas matrices son un tipo de vector particular, es un vector con un atributo especial, llamado dimensión. La dimensión establece el número de renglones y el número de columnas que tendrá una matriz, se debe recordar que una matriz no es más que un arreglo de números en \\(m\\) renglones y \\(n\\) columnas.\nPor ejemplo una matriz de 3 renglones y 3 columnas\n\\[\\left[\\begin{array}{ccc}1 & 2 & 3 \\\\2 & 4 & 5 \\\\3 & 5 & 6\\end{array}\\right]\\] Se dispone de dos maneras básicas de definir una matriz en R. En primer lugar, la instrucción:\n\\[matrix(vector,nrow = n, byrow = valorlogico)\\]\nDefine una matriz de \\(n\\) filas (rows) formada por las entradas del vector. Si se captura byrow = TRUE, la matriz se construye por filas, mientras que con byrow = FALSE se construye por columnas; este último es el valor por defecto, por lo que no hace falta especificarlo. En vez de emplear nrow, se puede indicar el número de columnas con ncol. Veamos algunos ejemplos:\n\nmatrix(1:6,nrow = 2)\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\nmatrix(1:6, nrow = 3)\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\nmatrix(1:6, nrow = 2, byrow = TRUE)\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n\nmatrix(1:6, nrow = 3, byrow = TRUE)\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n[3,]    5    6\n\n\nObserve cómo muestra R las matrices: indica las filas con \\([i,]\\), donde \\(i\\) es el índice de la fila, y las columnas con \\([,j]\\), donde \\(j\\) es el índice de la columna. Otra posible manera de definir matrices es combinando filas o columnas. La instrucción:\n\\[rbind(vector1,vector2, vector3)\\] construya la matriz de filas \\(vector1, vector2, . . . , vector N\\) que han de tener la misma longitud en este orden. Si en lugar de rbind se usa cbind, se obtiene la matriz cuyas columnas son los vectores a los que se aplica.\n\nrbind(c(1, 0, 2), c(2, 3, 6), c(1, 2, 0))\n\n     [,1] [,2] [,3]\n[1,]    1    0    2\n[2,]    2    3    6\n[3,]    1    2    0\n\ncbind(c(1, 0, 2), c(2, 3, 6), c(1, 2, 0))\n\n     [,1] [,2] [,3]\n[1,]    1    2    1\n[2,]    0    3    2\n[3,]    2    6    0\n\n\n\n\n\nLa manera más conveniente de guardar una tabla de datos en R es en forma de \\(dataframe\\). En concreto, un \\(data\\) \\(frame\\) es una tabla de doble entrada, formada por variables en las columnas y observaciones de estas variables en las filas, de manera que cada fila contiene los valores de las variables para un mismo caso o individuo. En ese sentido, un \\(data\\) \\(frame\\) tiene la apariencia de una matriz, pero con la diferencia de que cada columna de un \\(data\\) \\(frame\\) puede contener datos de un tipo diferente siempre que todos los datos de una misma columna sean del mismo tipo porque corresponden a observaciones de una misma propiedad: así, una columna puede estar formada por números, por palabras, por valores lógicos, etcétera. De esta manera, las columnas de un data frame son vectores, mientras que las filas son listas.\n\n\nPara construir un \\(data\\) \\(frame\\) a partir de unos vectores, se usa la función data.frame aplicada a los vectores en el orden en el que queramos disponer las columnas de la tabla; de esta manera, las variables tomarán los nombres de los vectores. Estos nombres también se pueden especificar en el argumento de la función data.frame, entrando cada columna con una construcción de la forma:\n\\[Nombre~variable = vector~con~el~contenido~de~la~variable\\]\nPara ilustrar esta función usemos un ejemplo sencillo:\n\nUna compañía de seguros desea crear una base de datos para la gestión de las pólizas de sus asegurados. Para ello, los datos de los que dispone son los siguientes:\n\nDe cada póliza se guarda el número de póliza.\nEl tipo que puede ser “Hogar” o “Auto”.\nLa fecha de creación de la póliza.\ny el conjunto de coberturas incluidas en la póliza ( a elegir entre Incendio, Robo, Terceros y Responsabilidad Civil).\nPara cada póliza guardamos los atos de sus titulares, y sabemos que cada poliza tiene un único titular.\nDe los titulares guardamos nombre, sexo, edad y estado de providencia.\n\n\nPoliza <- c(1:9)\n\nTipo <- c(\"Hogar\", \"Auto\", \"Auto\", \"Auto\", \"Hogar\", \"Hogar\", \"Auto\",\n           \"Auto\", \"Hogar\")\n\nFecha <- c(\"12/12/2016\", \"08/02/2014\", \"10/08/2012\", \"01/01/2015\",\n           \"21/11/2011\", \"18/01/2016\", \"12/04/2005\", \"29/03/2007\",\n           \"18/02/2009\")\n\nCoberturas <- c(\"Incendio\", \"Robo\", \"Terceros\", \"Robo\", \"Robo\",\n                \"Incendio\", \"Terceros\", \"R. Civil\", \"Incendio\")\n\nNombre <- c(\"Carlos\", \"Nancy\", \"Pedro\", \"Cecilia\", \"Ricardo\", \"Sofia\",\n            \"Armando\", \"Vicente\", \"Fernando\")\n\nSexo <- c(\"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"M\", \"M\")\n\nEdad <- c(25, 35, 45, 47, 24, 43, 33, 31, 40)\n\nEstado <- c(\"Campeche\", \"Chiapas\", \"Ciudad de M ́exico\", \"Coahuila\",\n            \"Durango\", \"Guanajuato\", \"Guerrero\", \"Hidalgo\", \"Jalisco\")\n\ndataframe= data.frame(Poliza, Tipo, Fecha, Coberturas, Nombre, Sexo, Edad)\n\ndataframe\n\n  Poliza  Tipo      Fecha Coberturas   Nombre Sexo Edad\n1      1 Hogar 12/12/2016   Incendio   Carlos    M   25\n2      2  Auto 08/02/2014       Robo    Nancy    F   35\n3      3  Auto 10/08/2012   Terceros    Pedro    M   45\n4      4  Auto 01/01/2015       Robo  Cecilia    F   47\n5      5 Hogar 21/11/2011       Robo  Ricardo    M   24\n6      6 Hogar 18/01/2016   Incendio    Sofia    F   43\n7      7  Auto 12/04/2005   Terceros  Armando    M   33\n8      8  Auto 29/03/2007   R. Civil  Vicente    M   31\n9      9 Hogar 18/02/2009   Incendio Fernando    M   40\n\n\n\n\n\n\nR es un lenguaje que permite la implementación de paquetes adicionales que le dan una capacidad de gestión de datos más amplia y permiten la implementación de nuevas funciones que harán de R un programa que se adapte a las necesidades.\n\nEl procedimiento para instalar un paquete depende del sistema operativo usado y de la manera como se instalo R: ya sea desde el código fuente o desde o por medio de archivos binarios pre-compilados. Existen varias funciones para manejar paquetes tales como:\n\ninstalled.packages()\nCRAN.package()\ndownload.packages()\n\nPara verificar la versión de paquetes ya instalados en el sistema y actualizarlos a la versión más reciente utilizamos la siguiente función:\n\nupdate.packages()"
  },
  {
    "objectID": "posts/tidyverse/index.html",
    "href": "posts/tidyverse/index.html",
    "title": "Machine Learning en Tidyverse",
    "section": "",
    "text": "Asumire que el lector tiene cierto conocimiento de la teoría de modelos lineales, en caso de no ser así, no te preocupes visita este link para que puedas ir a leer las generalidades de estos modelos y su uso en R, principalmente los tres paquetes de broom que le permiten explorar estos modelos. En este post trataremos de combinar estas técnica para aprender más sobre estos modelos y sus datos.\nA continuación cargaremos algunos de los paquetes que nos ayudaran para poder realizar nuestra tarea,\n\nlibrary(tidyverse) # para manipulación de datos\nlibrary(gapminder) # marco de datos que utilizaremos \nlibrary(dslabs)    # conjunto de datos y funciones para analisis de datos\nlibrary(broom)     # Resumen informacion sobre objetos estadisticos en tibbles\n\nRecuerde que el marco de gapminder contiene informacion sobbre cada país desde 1960 hasta 2016. Crearemos una variable que llamaremos gap_anidado para obtener que las características de cada país este anidadas como un tibble. La ventaja de usar estos tibble es que podemos construir modelos lineales simples que predicen la esperanza de vida por año para cada país. Nos centraremos en aprender a usar los coeficientes de estos modelos para obtener nuevos conocimientos sobre los datos de gapminder.\n\ngap_anidado <- gapminder %>% group_by(country) %>% nest()\n\nhead(gap_anidado)\n\n# A tibble: 6 × 2\n# Groups:   country [6]\n  country             data             \n  <fct>               <list>           \n1 Albania             <tibble [57 × 8]>\n2 Algeria             <tibble [57 × 8]>\n3 Angola              <tibble [57 × 8]>\n4 Antigua and Barbuda <tibble [57 × 8]>\n5 Argentina           <tibble [57 × 8]>\n6 Armenia             <tibble [57 × 8]>\n\n\nTal como lo mencionamos previamente, gap_anidado contiene las características de cada país anidadas como un tibble. Con esto hecho, procederemos a construir modelos lineales para cada país, para ello usaremos la función map() del paquete purrr\n\ngap_models <- gap_anidado %>% \n  mutate(model = map(data, ~lm(life_expectancy~year,data = .x)))\n\ngap_models\n\n# A tibble: 185 × 3\n# Groups:   country [185]\n   country             data              model \n   <fct>               <list>            <list>\n 1 Albania             <tibble [57 × 8]> <lm>  \n 2 Algeria             <tibble [57 × 8]> <lm>  \n 3 Angola              <tibble [57 × 8]> <lm>  \n 4 Antigua and Barbuda <tibble [57 × 8]> <lm>  \n 5 Argentina           <tibble [57 × 8]> <lm>  \n 6 Armenia             <tibble [57 × 8]> <lm>  \n 7 Aruba               <tibble [57 × 8]> <lm>  \n 8 Australia           <tibble [57 × 8]> <lm>  \n 9 Austria             <tibble [57 × 8]> <lm>  \n10 Azerbaijan          <tibble [57 × 8]> <lm>  \n# … with 175 more rows\n\n\n\n\n\\[y = \\alpha + \\beta x\\]\nRepasemos brevemente cómo interpretar los coeficientes para un modelo de regresión lineal simple. Recuerda que esto implica calcular dos términos de coeficientes que relacionan la variable dependiente con la variable independiente \\(x\\).\nPara nuestros modelos, las variales:\n\n\\(y\\): Representa la esperanza de vida en relación con el año (variable \\(x\\)).\n\\(\\alpha\\): Representa el coeficiente del intercepto, nos dice la esperanza en el año 0. Esto no es significativo para nuestros datos, por lo que lo pasaremos por alto.\n\\(\\beta\\): Es el coeficiente del año (variable \\(x\\)), que para un modelo de regresión lineal simple corresponde directamente a la pendiente del mismo.\n\nUsando la función tidy() del paquete broom en el primer modelo, aprenderemos que con cada año que pasa la esperanza de vida promedio de la población de este país en particular aumenta aproximadamente 0.23 años. Este enfoque puede brindarle información sobre el crecimiento o la falta de crecimiento en la esperanza de vida a lo largo del tiempo para los países que esta modelando.\n\ntidy(gap_models$model[[1]])\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept) -397.     12.4         -32.1 2.48e-37\n2 year           0.236   0.00622      38.0 3.72e-41\n\n\n\n\n\nPuede generar estos coeficientes mapeando la funcíon tidy() para cada uno de nuestros modelos y luego simplificando el nuevo marco de datos usando la función unnest(). Esto da como resultado un tibble que contiene la estimación para cada coeficiente de cada país.\n\ngap_models %>% \n  mutate(coef = map(model, ~tidy(.x))) %>% \n  unnest(coef)\n\n# A tibble: 370 × 8\n# Groups:   country [185]\n   country             data     model  term    estimate std.e…¹ stati…²  p.value\n   <fct>               <list>   <list> <chr>      <dbl>   <dbl>   <dbl>    <dbl>\n 1 Albania             <tibble> <lm>   (Inter… -3.97e+2 1.24e+1   -32.1 2.48e-37\n 2 Albania             <tibble> <lm>   year     2.36e-1 6.22e-3    38.0 3.72e-41\n 3 Algeria             <tibble> <lm>   (Inter… -1.10e+3 4.05e+1   -27.2 1.51e-33\n 4 Algeria             <tibble> <lm>   year     5.86e-1 2.04e-2    28.8 7.84e-35\n 5 Angola              <tibble> <lm>   (Inter… -7.48e+2 1.12e+1   -67.0 2.03e-54\n 6 Angola              <tibble> <lm>   year     4.01e-1 5.62e-3    71.4 6.69e-56\n 7 Antigua and Barbuda <tibble> <lm>   (Inter… -3.79e+2 1.56e+1   -24.2 5.19e-31\n 8 Antigua and Barbuda <tibble> <lm>   year     2.26e-1 7.87e-3    28.8 7.64e-35\n 9 Argentina           <tibble> <lm>   (Inter… -3.56e+2 7.67e+0   -46.4 8.83e-46\n10 Argentina           <tibble> <lm>   year     2.15e-1 3.86e-3    55.7 4.58e-50\n# … with 360 more rows, and abbreviated variable names ¹​std.error, ²​statistic\n\n\n\n\n\nAnteriormente aprovechamos la función tidy() de broom para explorar los coeficientes de nuestros modelos. Al hacerlo, obtuvimos información sobre cómo cambió la esperanza de vida con el tiempo para cada uno de los países en nuestro conjunto de datos. Ahora, aprenderá a usar la función glance() de broom para medir que tan bien se ajusta cada uno de estos modelos a sus datos subyacentes.\nUna forma de medir el ajuste de un modelo de regresión lineal es calcular su métrica \\(R^2\\)\n\\[\nR^2 = \\frac{\\%~variación~explicada~por~el~modelo}{\\%~variación~total~de~los~datos}\n\\]\nLa métrica \\(R^2\\) mide la relación entre la variación explicada por el modelo de regresión y la variación total de los datos. Toma valores entre 0 y 1.\nEn la siguiente figura, le muestro dos ejemplos, el primero con un valor alto y el segundo con un valor bajo de su \\(R^2\\) respectivamente. Note que en el caso donde el \\(R^2 = 0.009\\) es bajo o cercano a cero, esto nos indica que un modelo lineal esta capturando una cantidad proporcionalmente pequeña de la variación en los datos y. por lo tanto, no se ajusta bien. Por el contrario el modelo con \\(R^2 = 0.965\\) valor que es más cercano a 1, lo que indica que este modelo lineal se ajusta bien a los datos. Puede evaluar el ajuste de los modelos midiendo el valor del \\(R^2\\) para cada modelo.\n\nMuy bien, con el conocimiento previo, hechemos un vistazo a nuestros modelos. Para ello usamos map() y glance() para crear un marco de datos de estadísticas de resumen para cada modelo almacenado como la columna coef. Luego, puede simplificar estos marcos de datos usando la función unnest(). Esto nos dará como resultado un tibble que contendrá las estadisticas del modelo para cada modelo de país.\n\nmodel_perf <- gap_models %>% \n  mutate(coef = map(model,~glance(.x))) %>% \n  unnest(coef)\n\nmodel_perf\n\n# A tibble: 185 × 15\n# Groups:   country [185]\n   country    data     model r.squ…¹ adj.r…² sigma stati…³  p.value    df logLik\n   <fct>      <list>   <lis>   <dbl>   <dbl> <dbl>   <dbl>    <dbl> <dbl>  <dbl>\n 1 Albania    <tibble> <lm>    0.963   0.963 0.772  1443.  3.72e-41     1  -65.1\n 2 Algeria    <tibble> <lm>    0.938   0.937 2.53    828.  7.84e-35     1 -133. \n 3 Angola     <tibble> <lm>    0.989   0.989 0.698  5091.  6.69e-56     1  -59.3\n 4 Antigua a… <tibble> <lm>    0.938   0.937 0.977   828.  7.64e-35     1  -78.6\n 5 Argentina  <tibble> <lm>    0.983   0.982 0.479  3103.  4.58e-50     1  -37.9\n 6 Armenia    <tibble> <lm>    0.288   0.275 1.57     22.2 1.70e- 5     1 -106. \n 7 Aruba      <tibble> <lm>    0.882   0.880 0.964   412.  3.28e-27     1  -77.8\n 8 Australia  <tibble> <lm>    0.983   0.983 0.540  3240.  1.42e-50     1  -44.7\n 9 Austria    <tibble> <lm>    0.989   0.989 0.430  4949.  1.45e-55     1  -31.7\n10 Azerbaijan <tibble> <lm>    0.679   0.673 1.54    116.  3.48e-15     1 -105. \n# … with 175 more rows, 5 more variables: AIC <dbl>, BIC <dbl>, deviance <dbl>,\n#   df.residual <int>, nobs <int>, and abbreviated variable names ¹​r.squared,\n#   ²​adj.r.squared, ³​statistic\n\n\nSi observamos los valores de \\(R^2\\) de los primeros 5 modelos notamos que tienen un \\(R^2\\) alto, lo que nos dice que los modelos para estos países se han ajustado bien a los datos de esos países en particular.\n\n\n\nSiendo un poco más curiosos, tratemos de explorar el ajuste de los modelos. Para ver esto, podemos filtrar los valores más alto de r.squared, tomaremos como un r.squared alto 0.995 en adelante.\nPor ejemplo, podemos usar la función slice_max() de dplyr para encontrar los modelos que mejor se ajustan. Asimismo, podemos encontrar los modelos con el peor ajuste utilizando la función slice_min(). Hechemos un vistazo al código y los resultados generados,\n\nmejores_models <- model_perf %>% filter(r.squared > 0.995)\nmejores_models\n\n# A tibble: 3 × 15\n# Groups:   country [3]\n  country     data     model r.squ…¹ adj.r…² sigma stati…³  p.value    df logLik\n  <fct>       <list>   <lis>   <dbl>   <dbl> <dbl>   <dbl>    <dbl> <dbl>  <dbl>\n1 Bahamas     <tibble> <lm>    0.995   0.995 0.235  11428. 1.74e-65     1  2.67 \n2 Israel      <tibble> <lm>    0.996   0.996 0.250  15626. 3.29e-69     1 -0.826\n3 Switzerland <tibble> <lm>    0.996   0.995 0.244  12349. 2.08e-66     1  0.508\n# … with 5 more variables: AIC <dbl>, BIC <dbl>, deviance <dbl>,\n#   df.residual <int>, nobs <int>, and abbreviated variable names ¹​r.squared,\n#   ²​adj.r.squared, ³​statistic\n\n\ny para los peores filtremos los países que tienen un modelo con un r.squared menor a 0.3\n\npeores_modelos <- model_perf %>% filter(r.squared < 0.3) \npeores_modelos\n\n# A tibble: 12 × 15\n# Groups:   country [12]\n   country    data     model r.squ…¹ adj.r.…² sigma stati…³ p.value    df logLik\n   <fct>      <list>   <lis>   <dbl>    <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl>\n 1 Armenia    <tibble> <lm>  2.88e-1  0.275    1.57 2.22e+1 1.70e-5     1 -106. \n 2 Botswana   <tibble> <lm>  8.21e-4 -0.0173   4.98 4.52e-2 8.32e-1     1 -171. \n 3 Central A… <tibble> <lm>  2.76e-1  0.262    3.13 2.09e+1 2.76e-5     1 -145. \n 4 Latvia     <tibble> <lm>  1.92e-1  0.177    1.88 1.31e+1 6.49e-4     1 -116. \n 5 Lesotho    <tibble> <lm>  3.46e-2  0.0170   5.23 1.97e+0 1.66e-1     1 -174. \n 6 Lithuania  <tibble> <lm>  2.94e-1  0.281    1.24 2.29e+1 1.32e-5     1  -92.0\n 7 Russia     <tibble> <lm>  2.63e-2  0.00856  1.80 1.48e+0 2.28e-1     1 -113. \n 8 South Afr… <tibble> <lm>  2.69e-1  0.256    3.57 2.03e+1 3.54e-5     1 -152. \n 9 Swaziland  <tibble> <lm>  6.92e-5 -0.0181   5.83 3.80e-3 9.51e-1     1 -180. \n10 Ukraine    <tibble> <lm>  1.73e-1  0.158    1.41 1.15e+1 1.30e-3     1  -99.4\n11 Zambia     <tibble> <lm>  4.13e-2  0.0239   4.13 2.37e+0 1.30e-1     1 -161. \n12 Zimbabwe   <tibble> <lm>  1.37e-1  0.122    5.75 8.75e+0 4.55e-3     1 -180. \n# … with 5 more variables: AIC <dbl>, BIC <dbl>, deviance <dbl>,\n#   df.residual <int>, nobs <int>, and abbreviated variable names ¹​r.squared,\n#   ²​adj.r.squared, ³​statistic\n\n\n\n\n\nPara hacer esto, primero debe crear un marco de datos que contenga tanto los valores predichos como los originales. Esto requiere primero usar map() y augment() para trabajar en la columna de la lista que contiene los modelos para crear marcos de datos anidados que contengan tanto los valores originales como los predichos. Luego, puede usar unnest() en esta nueva columna para simplificar estos marcos de datos y permitir una mayor exploración.\n\naugment_models <- gap_models %>% \n  mutate(augmented = map(model,~augment(.x))) %>% \n  unnest(augmented)\n\naugment_models\n\n# A tibble: 10,545 × 11\n# Groups:   country [185]\n   country data     model  life_exp…¹  year .fitted .resid   .hat .sigma .cooksd\n   <fct>   <list>   <list>      <dbl> <int>   <dbl>  <dbl>  <dbl>  <dbl>   <dbl>\n 1 Albania <tibble> <lm>         62.9  1960    65.7 -2.80  0.0684  0.672 0.517  \n 2 Albania <tibble> <lm>         63.9  1961    65.9 -1.99  0.0648  0.728 0.245  \n 3 Albania <tibble> <lm>         64.8  1962    66.1 -1.30  0.0614  0.758 0.0989 \n 4 Albania <tibble> <lm>         65.6  1963    66.4 -0.778 0.0581  0.772 0.0332 \n 5 Albania <tibble> <lm>         66.2  1964    66.6 -0.434 0.0549  0.777 0.00970\n 6 Albania <tibble> <lm>         66.6  1965    66.9 -0.260 0.0518  0.779 0.00327\n 7 Albania <tibble> <lm>         66.9  1966    67.1 -0.206 0.0489  0.779 0.00193\n 8 Albania <tibble> <lm>         67.1  1967    67.3 -0.213 0.0461  0.779 0.00192\n 9 Albania <tibble> <lm>         67.3  1968    67.6 -0.239 0.0435  0.779 0.00227\n10 Albania <tibble> <lm>         67.6  1969    67.8 -0.245 0.0409  0.779 0.00224\n# … with 10,535 more rows, 1 more variable: .std.resid <dbl>, and abbreviated\n#   variable name ¹​life_expectancy\n\n\nAhora, visualizaremos algunos de estos modelos.\n\n\n\nNote que dado que su \\(R^2\\) es bastante alto, podemos asumir que el modelo lineal se ajusta bien a los datos. Puede comparar el ajuste del modelo con los datos originales trazando ambos en el mismo gráfico. En este ejemplo, usaremos ggplot2 para trazar los valores originales de la esperanza de vida como un diagrama de dispensión usando geom_point() y agregué el ajuste del modelo lineal como una línea roja usando geom_line()\n\naugment_models %>% filter(country == \"Bahamas\") %>% \n  ggplot(aes(x = year, y = life_expectancy)) + \n  geom_point() + \n  geom_line(aes(y = .fitted), color = \"red\") + \n  labs(title = \"Modelo Regresión Lineal para Bahamas\",\n       x = \"Año\",\n       y = \"Esperanza de Vida\") + \n  theme_minimal()\n\n\n\n\nSi observa el gráfico, podemos pensar que un modelo de regresión lineal se va ajustando bien a los datos de este país en particular.\n\n\n\nAhora veamos el modelo correspondiente al país Ukraine, que tiene un valor de \\(R^2\\) super más bajo que el de Bahamas. Claramente, esperariamos encontrarnos con un modelo que no se ajuste bien a los datos dado el antecedente del \\(R^2\\)\n\naugment_models %>% filter(country == \"Ukraine\") %>% \n  ggplot(aes(x = year, y = life_expectancy)) + \n  geom_point() + \n  geom_line(aes(y = .fitted), color = \"red\") + \n  labs(title = \"Modelo de Regresión Lineal para Ukraine\", \n       x = \"Año\", \n       y = \"Esperanza de  Vida\") + \n  theme_minimal()\n\n\n\n\nComo pudo ver en estos dos ejemplos, augment() y ggplot() facilitan la exploración visual del ajuste de un modelo.\n\n\n\nEn este caso, prepararemos los cuatro mejores modelos que consideramos anteriormente y los peores y los visualizaremos,\n\nmejores_augment <- mejores_models %>% \n  mutate(augmented = map(model, ~augment(.x))) %>% \n  unnest(augmented)\n\npeores_augment <- peores_modelos %>% \n  mutate(augmented = map(model, ~augment(.x))) %>% \n  unnest(augmented)\n\nBien, ahora visualizamos los modelos\n\nmejores_augment %>% \n  ggplot(aes(x = year)) + \n  geom_point(aes(y = life_expectancy)) + \n  geom_line(aes(y = .fitted), color = \"red\") + \n  facet_wrap(~country, scales = \"free_y\") + \n  theme_minimal()\n\n\n\n\n\npeores_augment %>% \n  ggplot(aes(x = year)) + \n  geom_point(aes(y = life_expectancy)) + \n  geom_line(aes(y = .fitted), color = \"red\") + \n  facet_wrap(~country, scales = \"free_y\") + \n  theme_minimal()\n\n\n\n\nParcelas geniales! Puede ver que un modelo lineal hace un gran trabajo para los mejores 3 modelos de ajuste, pero los peores modelos de ajuste no parecen tener una relación lineal. Trabajaremos para mejorar este ajuste en la proxima serie de ejercicios mediante la incorporación de funciones adicionales.\n\n\n\nCon la información que reunimos con Augment() y glance(), aprendimos que algunos de los modelos de regresión lineal simple no se ajustan adecuadamente a las tendencias subyacentes de nuestros datos. Para separar esto emplearemos un modelo de regresión múltiple.\n\n\n\\[Y = \\alpha + \\beta_1x_1 9 \\beta_2x_2 + . . . \\]\nEste modelo es una extensión natural del modelo de regresión lineal simple. La diferencia clave es que usa más variables explicativas para explicar el resultados, lo que significa que, en lugar de ajustar una linea de mejor ajuste, estamos ajustando un plano multidimensional. En el conjunto de datos gapminder, podemos usar características adicionales de nuestras observaciones para modelr la esperanza de vida. Entonces, vamos a usarlo,\nLa elección de que características usar se puede controlar en el campo de fórmula de la función lm(). Recuerde que para un modelo simple usamos la fórmula de la esperanza de vida explicada por año. De manera similar para un modelo de regresión múltiple, puede definir explícitamente la fórmula incluyendo el nombre de cada característica separada por un signo + o si sabe que desa incluir todas las características, puede capturarlas usando un punto,como veremos posteriormente.\n\n\n\nEl comportamiento de las funciones de broom sigue siendo el mismo. tidy() devuelve las estimaciones de los coeficientes de los modelos, esto ahora incluye estimaciones para las cuatro características adicionales. Lo mismo ocurre con augment(), además, de los valores ajustados para cada observación, se devuelven los valores de cuatro caracteristicas nuevas. y aunque la salida esperada de glance() sigue siendo la misma, tenemos que cambiar nuestro enfoque del valor de r cuadrado al valor de r cuadrado ajustado al evaluar el ajuste de nuestros modelos o comparar modelos de regresión lineal simple y múltiple.\n\n\n\nRecuerde que r.squared mide la variación explicada por el modelo. Agregar cualquier característica nueva a un modelo, independientemente de su relación con la variable dependiente, siempre aumentará el valor de r.squared del modelo. Esto se vuelve problemático cuando se compara el ajuste de modelos con diferente número de características explicativas utilizadas. Para compensar esto, en su lugar, utilizará el valor adj.r.squared (r cuadrado ajustado) esta es una métrica r cuadrada modificada cuyo cálculo tiene en cuenta la cantidad de características utilizadas en el modelo.\nLa interpretación del adj.r.squared es muy similar al r.squared y lo usaremos para evaluar el ajuste de nuestros modelos y compararlos con los modelos lineales simples creados anteriormente.\n\n\n\n\nAnteriormente, creamos una colección de modelos simples para ajustarse a la expectativa de vida usando la característica de año. Su análisis anterior mostro que algunos de estos modelos no encajaban muy bien.\nEn esta sección, construiremos modelos de regresión múltiple para cada país utilizando todas las funciones disponibles. Puede que le interese comparar el rendimiento de los 12 modelos con el peor ajuste\n\n\n\nPaís\nAdj.r.squared\n\n\n\n\nArmenia\n0.274831633\n\n\nBotswana\n-0.017346290\n\n\nCentral African Republic\n0.262392009\n\n\nLatvia\n0.177428933\n\n\nLesotho\n0.017078583\n\n\nLithuania\n0.281255888\n\n\nRussia\n0.008564872\n\n\nSouth Africa\n0.255968853\n\n\nSwaziland\n-0.018111402\n\n\nUkraine\n0.157855451\n\n\nZambia\n0.023859596\n\n\nZimbabwe\n0.1216212616\n\n\n\nAhora si, apliquemos un modelo lineal generalizado para ver si mejorar estos datos\n\n# Creamos un modelo lineal para cada país\ngap_fullmodel <- gap_anidado %>% \n  mutate(model = map(data, \n                     ~lm(life_expectancy~year+population+fertility+gdp, data = .x)))\n\nfullmodel_perf <- gap_fullmodel %>% \n  # Extraigaimos las estadísticas de ajuste de cada modelo en marcos de datos\n  mutate(fit = map(model, ~glance(.x))) %>% \n  # Simplifiquemos los marcos de datos de ajuste para cada modelo\n  unnest(fit)\n\n# Vea el rendimiento de los 12 países con el peor ajuste, es decir, \n# los dos modelos simples que viste antes\nfullmodel_perf %>% \n  filter(country %in% peores_modelos$country) %>% \n  select(country, adj.r.squared)\n\n# A tibble: 12 × 2\n# Groups:   country [12]\n   country                  adj.r.squared\n   <fct>                            <dbl>\n 1 Armenia                          0.923\n 2 Botswana                         0.736\n 3 Central African Republic         0.931\n 4 Latvia                           0.687\n 5 Lesotho                          0.855\n 6 Lithuania                        0.893\n 7 Russia                           0.652\n 8 South Africa                     0.896\n 9 Swaziland                        0.905\n10 Ukraine                          0.692\n11 Zambia                           0.872\n12 Zimbabwe                         0.978\n\n\nNote que los valores para adj.r.squared mejoraron considerablemente. Si bien adj.r.squared nos dice qué tan bien se ajusta el modelo a nuestros datos, no da ninguna indicación sobre cómo se desempeñaria con nuevos datos. En otro post, les mostraré como estimar el rendimiento del modelo utilizando los datos retenidos de la construcción del modelo."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Modelo Prophet de Facebook",
    "section": "",
    "text": "En este post, te presento la implementación de Facebook Prophet, así como sus principales hiperparámetros ajustados para generar el modelo predictivo, dicho modelo lo implementaremos para predecir el tipo de cambio de Honduras versus el dólar EE:UU (USD/HNL), considerando que esto será unicamente para conocer el funcionamiento del modelo, no para justificar que es el mejor modelo para realizar la actividad descrita previamente."
  },
  {
    "objectID": "posts/welcome/index.html#descripción-general-del-modelo",
    "href": "posts/welcome/index.html#descripción-general-del-modelo",
    "title": "Modelo Prophet de Facebook",
    "section": "Descripción General del Modelo",
    "text": "Descripción General del Modelo\nFacebook Prophet es un modelo y una biblioteca que proporciona características tanto de modelos lineales generalizados (MLG) como de modelos aditivos (MA), principalmente extendiendo el MLG mediante el uso de funciones de suavizado no lineal. Fue especificado por Taylor y Letham en 2017.\nProphet es un software de código abierto lanzado por el equipo Core Data Science de Facebook. Está disponible para su descarga en CRAN y PyPI. En esta ocasión usaremos el lenguaje R para implementar el modelo, sin embargo, tu puedes hacerlo en Python si es de tu preferencia.\nProphet funciona mejor con series temporales que tienen fuertes efectos estacionales y varias temporadas de datos históricos. Prophet es resistente a los datos faltantes y los cambios en la tendencia, y por lo general maneja bien los valores atípicos. Prophet esta diseñado especificamente para la predicción de series temporales de negocios.\nSu modelo aditivo que consta de cuatro componentes, esta dado por:\n\\[\ny(t) = g(t) + s(t) + h(t) + \\epsilon_{t}\n\\]\ndonde,\n\n\\(g(t)\\): Representa la tendencia y el objetivo es capturar la tendencia de la serie. Por ejemplo, es probable que la cantidad de vistas de anuncios de Facebook aumente con el tiempo a medida que más personas se unen a la red. Pero, ¿cuál sería la función exacta del aumento?\n\\(s(t)\\): Es el componente de Estacionalidad. El número de anuncios también puede depender de la temporada. Por ejemplo, en el hemisferio norte durante los meses de verano, es probable que las personas pasen más tiempo al aire libre y menos tiempo frente a sus computadoras. Tales fluctuaciones pueden ser muy diferentes para diferentes series temporales de negocios. El segundo componente es, por lo tanto, una función que modela las tendencias estacionales.\n\\(h(t)\\): Representa los efectos de las vaciones. Usamos la información para días festivos que tienen claro impacto en la mayoria de las series temporales comerciales. Tenga en cuenta que las vaciones varían entre años, países, etc. Y, por lo tanto, la información debe proporcionarse explícitamente al modelo.\n\\(\\epsilon_{t}\\): Es el término de error. Representa fluctuaciones aleatorias que el modelo no puede explicar. Como de costumbre, se supone que \\(\\epsilon_{t}\\) sigue una distribución \\(N(0,1)\\) con media cero y varianza desconocida \\(\\sigma\\) que debe derivarse de los datos ."
  },
  {
    "objectID": "posts/welcome/index.html#hiperparámetros",
    "href": "posts/welcome/index.html#hiperparámetros",
    "title": "Modelo Prophet de Facebook",
    "section": "Hiperparámetros",
    "text": "Hiperparámetros\nHay varios parámetros personalizables en la implementación de Facebook Prophet (revisar), siendo los principales:\n\nPuntos de cambio: definen los cambios de tendencia. Estos pueden ser encontrados por el propio algoritmo o también pueden ser definidos y ajustados por el analista.\nEstacionalidad: define las funciones periódicas que pueden afectar a la serie temporal. De forma predeterminada, Prophet considera la estacionalidad anual, semanal y diaria e intenta encontrar tendencias que representan esos efectos periódicos en los datos.\nDías festivos: los días especiales (días festivos o cualquier otro evento recurrente) también pueden ser modelados por el modelo aditivo.\n\nEn R, se usa la API de ajuste de modelo normal. Proporcionamos una función prophet que realiza el ajuste y devuelve un objeto de modelo. Posteriormeente usted puede llamar a la función predict y plot en este objeto modelo."
  },
  {
    "objectID": "posts/welcome/index.html#datos-y-preparación",
    "href": "posts/welcome/index.html#datos-y-preparación",
    "title": "Modelo Prophet de Facebook",
    "section": "Datos y Preparación",
    "text": "Datos y Preparación\nLos datos que utilizaremos los encontramos en Yahoo! Finance. Así como Python tiene un paquete para importar datos directamente de Yahoo Finance, R también cuenta con sus paquetes particular que nos permiten realizar una tarea similar. Necesitamos los siguiente paquetes:\n\nlibrary(TTR)\n\nWarning: package 'TTR' was built under R version 4.2.3\n\nlibrary(quantmod)\n\nWarning: package 'quantmod' was built under R version 4.2.3\n\n\nLoading required package: xts\n\n\nWarning: package 'xts' was built under R version 4.2.3\n\n\nLoading required package: zoo\n\n\nWarning: package 'zoo' was built under R version 4.2.3\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nSi aún no los tienes instalados sugiero los instales usando install.packages(\"name paquete\"). Muy bien, ahora si estamos listos para poder extraer nuestros datos de yahoo finance y para ello usaremos la funcion getSymbols del paquete quantmod. Veamos,\n\ndf <- getSymbols('HNL=X',src = 'yahoo',\n                 from = \"2010-01-01\",\n                 to = \"2022-12-20\",\n                 auto.assign = FALSE)\n\nTenga en cuenta que from =  \"2010-01-01\" y to = \"2022-12-20\" nos ayudan a indicar desde que fecha quiero comenzar a tomar mis datos y hasta que fecha quiero tomarlos. Además, auto.assign = FALSE indica a getSymbols que devuelva los datos.\nAhora, conozcamos nuestros datos\n\nhead(df)\n\n           HNL=X.Open HNL=X.High HNL=X.Low HNL=X.Close HNL=X.Volume\n2010-01-04     18.690     18.691    18.517      18.518            0\n2010-01-05     18.550     18.550    18.550      18.550            0\n2010-01-06     18.572     18.645    18.544      18.545            0\n2010-01-07     18.451     18.550    18.451      18.539            0\n2010-01-08     18.556     18.556    18.556      18.556            0\n2010-01-11     18.550     18.550    18.550      18.550            0\n           HNL=X.Adjusted\n2010-01-04         18.518\n2010-01-05         18.550\n2010-01-06         18.545\n2010-01-07         18.539\n2010-01-08         18.556\n2010-01-11         18.550\n\n\nDe estos datos únicamente usaremos el valor de cierre (HNL=X.Close) de manera diaria del lempira hondureño contra el dólar, para enfocarnos solo en esos datos, primero convertiremos nuestro conjunto de datos df en un dataframe, dado que inicialmente es un objeto de tipo xts,\n\nclass(df)\n\n[1] \"xts\" \"zoo\"\n\n\npara realizar el cambio a un dataframe, considere la siguiente función\n\nxts_to_datframe<-function(data_xts){\n  df_t<-data.frame(fecha=(index(data_xts)),\n                   value=coredata(data_xts))\n  colnames(df_t)<-c(\"ds\", \"y\")\n  df_t\n}\n\nTiene que tener cuidado con el nombramiento de sus columnas, dado que prophet reconoce unicamente marcos de datos con columnas nombras como ds y y, qu contienen la fecha y el valor numérico de sus observaciones respectivamente. Con esto en mente, pasemos a transformar df a un objeto de clase dataframe por medio de la función que construimos previamente:\n\nHNL <- xts_to_datframe(df$`HNL=X.Close`) \nclass(HNL)\n\n[1] \"data.frame\"\n\n\nPuede apreciar que ya tenemos nuestro marco de datos como un dataframe, y estamos listos para comenzar a crear nuestro modelo."
  },
  {
    "objectID": "posts/welcome/index.html#implementación-del-modelo",
    "href": "posts/welcome/index.html#implementación-del-modelo",
    "title": "Modelo Prophet de Facebook",
    "section": "Implementación del Modelo",
    "text": "Implementación del Modelo\nPrimero visualicemos nuestros datos\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::first()  masks xts::first()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::last()   masks xts::last()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(ggplot2)\n\nHNL %>% ggplot(aes(x = ds, y = y))+\n  geom_line()+\n  theme_minimal()+\n   labs(title = 'Datos Historicos del Tipo de Cambio del USD/HNL',\n       subtitle = '2010 - 2022',\n       x = 'Fecha',\n       y = 'HNL',\n       caption = 'Elaboracion propia con datos de yahoo finance')\n\n\n\n\n\nlibrary(prophet)\n\nLoading required package: Rcpp\n\n\nLoading required package: rlang\n\n\n\nAttaching package: 'rlang'\n\n\nThe following objects are masked from 'package:purrr':\n\n    %@%, flatten, flatten_chr, flatten_dbl, flatten_int, flatten_lgl,\n    flatten_raw, invoke, splice\n\nm <- prophet(HNL,daily.seasonality = TRUE)\n\nfuture <- make_future_dataframe(m,periods = 3,freq = 'day')\ntail(future)\n\n             ds\n3380 2022-12-16\n3381 2022-12-19\n3382 2022-12-20\n3383 2022-12-21\n3384 2022-12-22\n3385 2022-12-23\n\n\n\nforecast <- predict(m, future)\n\ndyplot.prophet(m, forecast)\n\n\n\n\n\nDe la figura previa,\n\nLos puntos negros representan medidas reales\nLa linea azul el pronóstico de Prophet\nLa banda azul representa el intervalo de incertidumbre"
  },
  {
    "objectID": "posts/welcome/index.html#desglose-del-pronóstico",
    "href": "posts/welcome/index.html#desglose-del-pronóstico",
    "title": "Modelo Prophet de Facebook",
    "section": "Desglose del Pronóstico",
    "text": "Desglose del Pronóstico\nSi bien el pronóstico arroja muchas cosas, podemos centrarnos en algunas como:\n\nds fecha que se pronostica\nyhat predicción para el valor y (tipo de cambio) ese día en particular.\nyhat_lower valor esperado más bajo para el rango del valor y previsto ese día\nyhat_upper valor esperado más alto para el rango de valor y previsto de ese día\n\nCon tail() podemos ver la salida de los últimos días pronosticados los cuales son 21, 22 y 23 de diciembre 2022.\n\ntail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')])\n\n             ds     yhat yhat_lower yhat_upper\n3380 2022-12-16 24.11296   23.36023   24.84664\n3381 2022-12-19 24.06289   23.38277   24.78892\n3382 2022-12-20 24.07617   23.36034   24.81428\n3383 2022-12-21 24.11976   23.36930   24.88180\n3384 2022-12-22 24.12084   23.42593   24.86375\n3385 2022-12-23 24.14074   23.39429   24.83643\n\n\nSegun nuestros resultados, nuestro modelo nos ve obteniendo para el día 21 de diciembre entre 23.35901 (yhat_lower) y 24.83438 (yhat_upper) lempiras por un dolar de EE.UU.\nPara entender el pronóstico más a detalle, podemos gráficar sus componentes con:\n\nprophet_plot_components(m,forecast)\n\n\n\n\nRecuerde que el fin de este post, no es abogar por el uso indiscriminado de Prophet como el mejor modelo para pronosticar el tipo de cambio hondureño vs el dólar. Espero hayas conocido las generalidades de este modelo y su utilidad en el ambito predictivo."
  },
  {
    "objectID": "software_citations.html",
    "href": "software_citations.html",
    "title": "Juan Isaula",
    "section": "",
    "text": "On this page I collect citations to software I maintain or am an author of. Software citations are particularly poorly captured by things like Google Scholar, both because software exists outside of standard citation formats and because software citations are often poorly formatted in publications. For that reason, I find it useful to keep my own list of projects which have cited my work.\nIf you cited any of my packages in a publication, please let me know – either on Mastodon or via email at mike.mahoney.218+site@gmail.com . I can’t guarantee I’ll add them to this list, for secret reasons, but it always makes me happy to see."
  },
  {
    "objectID": "software_citations.html#how-to-cite-software",
    "href": "software_citations.html#how-to-cite-software",
    "title": "Juan Isaula",
    "section": "How to cite software",
    "text": "How to cite software\nThe rOpenSci blog has a fantastic post on how to cite R and R packages, which I quickly summarize below. I highly recommend their post, however, even if you aren’t an R user; most of the topic generalizes to other software pretty easily.\nA software citation serves two functions for your readers:\n\nTells them what you did; for instance, if I see someone cite the sf package, I suddenly know more about the details of their spatial calculations than I can probably get from the text alone.\nTells them how you did it; package version information and source information helps others to replicate your work, and also can help readers assess an analysis. If you use sf >= 1.0.0, for instance, I know that you probably didn’t run into issues doing distance calculations with geographic coordinates, so I don’t need to consider that when I’m reading your results.\n\nSoftware citations also help the developers of your packages justify developing packages further; if you’re a user of scientific software and want there to still be scientific software in the future, you should cite your software. It also makes me, personally, feel great to see people benefiting from my work, and to see them credit me for any help my software gave them!\nAs such, you should cite any package that was relevant to the study you performed. If uninstalling the package (or deleting the relevant function calls) would change your results or make your code not run, you should cite it.\nIf you are an R user, you can get the citations for both R and your packages using the citation() function:\n\ncitation()\n\n\nTo cite R in publications use:\n\n  R Core Team (2022). R: A language and environment for statistical\n  computing. R Foundation for Statistical Computing, Vienna, Austria.\n  URL https://www.R-project.org/.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2022},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\ncitation(\"rsample\")\n\n\nTo cite package 'rsample' in publications use:\n\n  Frick H, Chow F, Kuhn M, Mahoney M, Silge J, Wickham H (2022).\n  _rsample: General Resampling Infrastructure_. R package version\n  1.1.1, <https://CRAN.R-project.org/package=rsample>.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {rsample: General Resampling Infrastructure},\n    author = {Hannah Frick and Fanny Chow and Max Kuhn and Michael Mahoney and Julia Silge and Hadley Wickham},\n    year = {2022},\n    note = {R package version 1.1.1},\n    url = {https://CRAN.R-project.org/package=rsample},\n  }\n\n\nIf you aren’t an R user, many scientific software libraries will still provide information on how to cite them – for instance, here’s the instructions for citing numpy. If Google and such return nothing, then I think your best option is to style citations after the official R citation: mimic book citation style, using authors, year, title, publication location, and an accessible URL."
  },
  {
    "objectID": "software_citations.html#how-i-track-citations",
    "href": "software_citations.html#how-i-track-citations",
    "title": "Juan Isaula",
    "section": "How I track citations",
    "text": "How I track citations\nAs suggested in a different rOpenSci post, I find the best general tool I have for finding software citations is to set up a Google Scholar alert for my packages and investigate each alert as it comes in. This is not a foolproof method, and I’m sure I miss things; as mentioned above, if you cited any of my packages in a publication, please let me know either on Mastodon or via email at mike.mahoney.218+site@gmail.com .\nI only track citations for packages I’m an author on, once I’m an author on them. In cases where a paper mentions the package but doesn’t cite it, I only list the article if it was published after I became an author on the package.\nWhile I track both citations and mentions of my packages, I really want to stress that citations are fantastic, help me justify maintaining open source scientific software (both to my boss and to myself), and make me really happy. Mentions do not. If you are going to mention one of these packages, please give it a full citation.\nThe citations below are in a variety of formats; I’ll confess to copying journal “cite this article” citations without reformatting for this list. If I messed up my citation for your article, please get in touch to let me know."
  },
  {
    "objectID": "software_citations.html#software-citations-1",
    "href": "software_citations.html#software-citations-1",
    "title": "Juan Isaula",
    "section": "Software citations",
    "text": "Software citations\n\nterrainr\n\nFox, N., Serrano-Vergel, R., Van Berkel, D., Lindquist, M. 2022. Towards Gamified Decision Support Systems: In-game 3D Representation of Real-word Landscapes from GIS Datasets. Journal of Digital Landscape Architecture. https://doi.org/10.14627/537724035\nTamiminia, H., Salehi, B., Mahdianpari, M., Beier, C. M., Johnson, L. 2022. Mapping Two Decades of New York State Forest Aboveground Biomass Change Using Remote Sensing. Remote Sensing 14(16): 4097. https://doi.org/10.3390/rs14164097\n\nThe following are self-citations:\n\nJohnson, L. K., Mahoney, M. J., Desrochers, M. L., & Beier, C. M. 2023. Mapping historical forest biomass for stock-change assessments at parcel to landscape scales. arXiv:2304.02632. https://doi.org/10.48550/arXiv.2304.02632\nJohnson, L. K., Mahoney, M. J., Bevilacqua, E., Stehman, S. V., Domke, G. M., & Beier, C. M. (2022). Fine-resolution landscape-scale biomass mapping using a spatiotemporal patchwork of LiDAR coverages. International Journal of Applied Earth Observation and Geoinformation, 114, 103059. https://doi.org/10.1016/j.jag.2022.103059\nMahoney, M. J., Johnson, L. K., Guinan, A. Z., & Beier, C. M. (2022). Classification and mapping of low-statured shrubland cover types in post-agricultural landscapes of the US Northeast. International Journal of Remote Sensing, 43(19-24), 7117-7138. https://doi.org/10.1080/01431161.2022.2155086\nMahoney et al., (2022). unifir: A Unifying API for Working with Unity in R. Journal of Open Source Software, 7(73), 4388, https://doi.org/10.21105/joss.04388\nTamiminia, H., Salehi, B., Mahdianpari, M., Beier, C. M., Johnson, L., Phoenix, D. B., and Mahoney, M. 2022. Decision tree-based machine learning models for above-ground biomass estimation using multi-source remote sensing data and object-based image analysis. Geocarto International 37(26): 12763-12791. https://doi.org/10.1080/10106049.2022.2071475\n\n\ncitation(\"terrainr\")\n\n\nThe United States Geological Survey provides guidelines for citing USGS\ndata products (as downloaded from 'get_tiles') at:\nhttps://www.usgs.gov/faqs/how-should-i-cite-datasets-and-services-national-map\n\nTo cite terrainr in publications please use:\n\n  Mahoney M. J., Beier C. M., and Ackerman, A. C. (2022). terrainr: An\n  R package for creating immersive virtual environments. Journal of\n  Open Source Software, 7(69), 4060,\n  https://doi.org/10.21105/joss.04060\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    year = {2022},\n    publisher = {The Open Journal},\n    volume = {7},\n    number = {69},\n    pages = {4060},\n    author = {Michael J. Mahoney and Colin M. Beier and Aidan C. Ackerman},\n    title = {{terrainr}: An R package for creating immersive virtual environments},\n    journal = {Journal of Open Source Software},\n    doi = {10.21105/joss.04060},\n    url = {https://doi.org/10.21105/joss.04060},\n  }\n\n\n\n\nunifir\n\ncitation(\"unifir\")\n\n\nTo cite unifir in publications please use:\n\n  Mahoney M. J., Beier C. M., and Ackerman, A. C. (2022). unifir: A\n  Unifying API for Working with Unity in R. Journal of Open Source\n  Software, 7(73), 4388, https://doi.org/10.21105/joss.04388\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    year = {2022},\n    publisher = {The Open Journal},\n    volume = {7},\n    number = {73},\n    pages = {4388},\n    author = {Michael J. Mahoney and Colin M. Beier and Aidan C. Ackerman},\n    title = {{unifir:} A Unifying {API} for Working with {Unity} in {R}},\n    journal = {Journal of Open Source Software},\n    doi = {10.21105/joss.04388},\n    url = {https://doi.org/10.21105/joss.04388},\n  }\n\n\n\n\nwaywiser\n\ncitation(\"waywiser\")\n\n\nTo cite waywiser in publications please use:\n\n  Mahoney M. J. (2023). waywiser: Ergonomic Methods for Assessing\n  Spatial Models. arXiv:2303.11312 [cs.MS].\n  https://doi.org/10.48550/arXiv.2303.11312\n\nA BibTeX entry for LaTeX users is\n\n  @Misc{,\n    title = {waywiser: Ergonomic Methods for Assessing Spatial Models},\n    author = {Michael J Mahoney},\n    year = {2023},\n    eprint = {2303.11312},\n    archiveprefix = {arXiv},\n    primaryclass = {cs.MS},\n    doi = {10.48550/arXiv.2303.11312},\n    url = {https://arxiv.org/abs/2303.11312},\n  }\n\n\n\n\nspatialsample\nI took over maintenance of spatialsample in mid-2022, after spending the summer interning with the tidymodels crew at Posit working on spatialsample and rsample. I’m responsible for the majority of package functionality. I only track citations here for versions of the package I’m an author on (>= 0.2.0).\n\nPebesma, E., Bivand, R. (2023). Spatial Data Science: With Applications in R (1st ed.). 314 pages. Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016\nde Lara, A., Mieno, T., Luck, J.D. et al. Predicting site-specific economic optimal nitrogen rate using machine learning methods and on-farm precision experimentation. Precision Agric (2023). https://doi.org/10.1007/s11119-023-10018-8\nTutland, Niko J., Rodman, Kyle C., Andrus, Robert A., and Hart, Sarah J. 2023. “Overlapping Outbreaks of Multiple Bark Beetle Species are Rarely More Severe than Single-Species Outbreaks.” Ecosphere 14(3): e4478. https://doi.org/10.1002/ecs2.4478\nSkinner, E.B., Glidden, C.K., MacDonald, A.J. et al. Human footprint is associated with shifts in the assemblages of major vector-borne diseases. Nat Sustain (2023). https://doi.org/10.1038/s41893-023-01080-1\n\nThe following are self-citations:\n\nMahoney, MJ In Review. waywiser: Ergonomic methods for assessing spatial models. https://arxiv.org/abs/2303.11312\n\n\ncitation(\"spatialsample\")\n\n\nTo cite spatialsample in publications please use:\n\n  Mahoney M. J., Johnson, L. K., Silge, J., Frick, H., Kuhn, M., and\n  Beier C. M. (2023). Assessing the performance of spatial\n  cross-validation approaches for models of spatially structured data.\n  arXiv. https://doi.org/10.48550/arXiv.2303.07334\n\nA BibTeX entry for LaTeX users is\n\n  @Misc{,\n    title = {Assessing the performance of spatial cross-validation approaches for models of spatially structured data},\n    author = {Michael J Mahoney and Lucas K Johnson and Julia Silge and Hannah Frick and Max Kuhn and Colin M Beier},\n    year = {2023},\n    eprint = {2303.07334},\n    archiveprefix = {arXiv},\n    primaryclass = {stat.CO},\n    doi = {10.48550/arXiv.2303.07334},\n    url = {https://arxiv.org/abs/2303.07334},\n  }\n\n\n\n\nrsample\nI am an author on rsample after implementing functions for grouped resampling and clustered cross-validation (as well as the “common resampling patterns” vignette and a few other improvements). I only track citations here for versions of the package I’m an author on (>= 1.1.1).\n\nLundell, J. 2023. EZtune: A Package for Automated Hyperparameter Tuning in R. https://arxiv.org/abs/2303.12177\nYing R., Monteiro, F. M., Wilson, J. D., and Schmidt, D. N. 2023. ForamEcoGEnIE 2.0: incorporating symbiosis and spine traits into a trait-based global planktic foraminiferal model. Geosci. Model Dev., 16, 813–832, https://doi.org/10.5194/gmd-16-813-2023\nLyu H, Grafton M, Ramilan T, Irwin M, Sandoval E. Assessing the Leaf Blade Nutrient Status of Pinot Noir Using Hyperspectral Reflectance and Machine Learning Models. Remote Sensing. 2023; 15(6):1497. https://doi.org/10.3390/rs15061497\n\nThe following are self-citations:\n\nMahoney, MJ, Johnson, L. K., Silge, J., Frick, H., Kuhn, M., and Beier, C. M. In Review. Assessing the performance of spatial cross-validation approaches for models of spatially structured data. https://arxiv.org/abs/2303.07334\nMahoney, MJ In Review. waywiser: Ergonomic methods for assessing spatial models. https://arxiv.org/abs/2303.11312\n\nrsample is used in (but not cited in) Wang et al 2023; Lienard et al 2022; Adu-Oppong et al 2022; Zappaterra et al 2022; Mull et al 2022; Dematheis et al 2022; Bellows et al 2022; Yates et al; Stevelink et al 2022; Bartz-Beielstein et al 2023; Han Nh 2022; Yan et al 2023; dos Santos et al 2022; Badonyi et al 2022; Badonyi et al 2022; Peguero et al 2023; Howard et al 2023.\n\ncitation(\"rsample\")\n\n\nTo cite package 'rsample' in publications use:\n\n  Frick H, Chow F, Kuhn M, Mahoney M, Silge J, Wickham H (2022).\n  _rsample: General Resampling Infrastructure_. R package version\n  1.1.1, <https://CRAN.R-project.org/package=rsample>.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {rsample: General Resampling Infrastructure},\n    author = {Hannah Frick and Fanny Chow and Max Kuhn and Michael Mahoney and Julia Silge and Hadley Wickham},\n    year = {2022},\n    note = {R package version 1.1.1},\n    url = {https://CRAN.R-project.org/package=rsample},\n  }\n\n\n\n\ngeojsonio\nI took over maintaining geojsonio in mid-2022, in order to keep the package on CRAN. Most functionality was either contributed by Scott and Andy or by community contributors; I primarily fix issues to keep the package on CRAN and shepherd community contributions prior to merging them into the project. As with rsample, I only track citations since I joined the project.\ngeojsonio is used in (but not cited in) Chauhan et al 2022; Wang 2023; de Souza et al 2022.\n\ncitation(\"geojsonio\")\n\n\nTo cite package 'geojsonio' in publications use:\n\n  Chamberlain S, Teucher A, Mahoney M (2023). _geojsonio: Convert Data\n  from and to 'GeoJSON' or 'TopoJSON'_. R package version 0.11.1,\n  <https://CRAN.R-project.org/package=geojsonio>.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {geojsonio: Convert Data from and to 'GeoJSON' or 'TopoJSON'},\n    author = {Scott Chamberlain and Andy Teucher and Michael Mahoney},\n    year = {2023},\n    note = {R package version 0.11.1},\n    url = {https://CRAN.R-project.org/package=geojsonio},\n  }"
  },
  {
    "objectID": "papers/index.html",
    "href": "papers/index.html",
    "title": "Juan Isaula",
    "section": "",
    "text": "Courses\n\n\n\n\nCourses\n\nSaludos! Aquí encontraras diferentes cursos que he preparado para ti.\n\n\n\n\nModelando Riesgo Crediticio con Python\nFundamentos Estadísticos con R\nMatemáticas de la Optimización - Microeconomía\nTest de Jarque-Bera con Python\nRedes Neuronales LSTM vs GRU\nPronósticos de Inflación Honduras utilizando Redes Neuronales"
  },
  {
    "objectID": "presentations/index.html",
    "href": "presentations/index.html",
    "title": "Cursos Impartidos en UNAH",
    "section": "",
    "text": "Saludos! Bienvenido a esta sección de mi website. Aquí podra encontrar información sobre algnos cursos en los cuales soy colaborador.\n\n2023\n\n\nEstadística Aplicada - Maestría UNAH\n\nEste apartado está dedicado a los estudiantes de la maestría en Formulación, Gestión y Evaluación de Proyectos de la UNAH. Donde podrán encontrar el contenido sobre el taller de fundamentos estadísticos utilizando el Software de R. Mismo que tuve la oportunidad de impartirles.\n\nFundamentos estadísticos utilizando el Software de R\nLibro sobre fundamentos estadísticos con R - Juan Isaula\n\nBases de datos utilizadas\n\nco2.csv\nAAPL.csv\n\n\n\n\nMicroeconomía II - UNAH\n\n\nPrograma del curso\n\n\nModulo I - Teoria del Consumidor\n\n\nkaggle - Comandos Generales Python\nMaterial de repaso - Matemáticas de la optimización\nAula virtual Classroom\n\n\nModulo II - Teoria del Productor\n\n\nElasticidad Sustitución, Función de costos y matriz sustitución\n\n\nVideos\n\n\nComandos Generales Python\n\n\nModulo III - Estructuras de Mercado\n\n\nEjercicios equilibro a corto plazo - Competencia Perfecta\nCompetencia Perfecta: Largo y Corto Plazo\nPresentaciones sobre Monopolios\n\n\nAsignaciones\n\n\nTarea I\nTarea 3 - Teoría del Productor\nTarea Final - Estructuras de Mercado utilizando Python\n\n\nBibliografía Recomendada\n\n\nAdvanced Microeconomic Theory, Geoffrey A. Jehle Philip J.Reny\nTeoría Microeconómica (Principios básicos y ampliaciones-Walter Nikolso)\nMicroeconomia II - UNAH - Juan Isaula"
  },
  {
    "objectID": "subscribe.html",
    "href": "subscribe.html",
    "title": "Juan Isaula",
    "section": "",
    "text": "Subscribe to new posts\n\nGet new content in a weekly email"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "App/Dashboards",
    "section": "",
    "text": "En este sitio encontraras algunos Dashboards que he realizado en lenguajes de programación R y Python para algunas instituciones del País (Honduras) .\n\nGeoRGe\nEs una App que elaboré en el lenguaje de programación R, utilizando principalmente los paquetes shiny | shinydashboard | DT | tidyverse | shinyWidgets | fresh. En la actualizad es utilizada en el Instituto Hondureño de Seguridad Social (IHSS).\nIA-JIM\nApp que ayuda con el cómputo de gran parte de los indicadores actuariales primarios y secundarios del IHSS, correspondientes al Régimen del Seguro de Previsión Social (RSPS)."
  },
  {
    "objectID": "posts/port_mg/estructuras_mercado/index.html",
    "href": "posts/port_mg/estructuras_mercado/index.html",
    "title": "Estructuras de Mercado con Python",
    "section": "",
    "text": "Este post tiene como objetivo dar a conocer la importancia del software de Python en el ambito microeconomico, particularmente en este caso hablamos de las diferentes estructuras de mercado; competencia perfecta, monopolio y oligopolio."
  },
  {
    "objectID": "posts/port_mg/estructuras_mercado/index.html#condiciones-necesaria-para-la-competencia-perfecta",
    "href": "posts/port_mg/estructuras_mercado/index.html#condiciones-necesaria-para-la-competencia-perfecta",
    "title": "Estructuras de Mercado con Python",
    "section": "Condiciones necesaria para la competencia perfecta",
    "text": "Condiciones necesaria para la competencia perfecta\n\nMuchos productores, ninguno de los cuales tiene una gran cuota de mercado.\nUna industria puede ser perfectamente competitiva sólo si los consumidores consideran como equivalentes a los productos de todos los productores (producto homogéneo)"
  },
  {
    "objectID": "posts/port_mg/estructuras_mercado/index.html#libre-entrada-y-salida",
    "href": "posts/port_mg/estructuras_mercado/index.html#libre-entrada-y-salida",
    "title": "Estructuras de Mercado con Python",
    "section": "Libre entrada y salida",
    "text": "Libre entrada y salida\nExiste libre entrada y salida en una industria cuando nuevos productores pueden entrar facilmente en esa industria a los que ya estan en ella pueden abondonarla sin coste alguno.\n\nRegla de Producción Optima\nLa regla de producción optima dice que el beneficio se maximiza cuando se produce la cantidad de output para la cual el ingreso marginal de la última unidad de output producida es igual a su coste marginal.\n\\[\nIMg = CMg\n\\]\n\n\nFunción de Benenficios\nLa función de beneficios \\((\\pi)\\) representa las diferencias entre los costos totales, \\(C(Q)\\) e ingresos totales,\\(R(Q)\\) , de las empresas\n\\[\n\\pi = R(Q) - C(Q)\n\\]\n\n\nTomador de Precios\nPrecio igual al costo marginal\n\\[\n\\begin{eqnarray*}\nCMg = IMg = P\n\\end{eqnarray*}\n\\]\nPor tanto, se dice que el beneficio de una empresa precio-aceptante se maximiza produciendo la cantidad de output para la cual el costo marginal de la última unidad producida es igual al precio de mercado, tal como se aprecia en el siguiente gráfico\n\n\n\nCantidad de producto que maximiza el beneficio de una empresa precio-aceptante"
  },
  {
    "objectID": "posts/port_mg/estructuras_mercado/index.html#costes-y-producción-en-el-corto-plazo",
    "href": "posts/port_mg/estructuras_mercado/index.html#costes-y-producción-en-el-corto-plazo",
    "title": "Estructuras de Mercado con Python",
    "section": "Costes y Producción en el Corto Plazo",
    "text": "Costes y Producción en el Corto Plazo\nEn el corto plazo tenemos las siguientes condiciones de producción de empresas competitivas\n\n\n\n\n\n\n\nCondiciones\nResultados\n\n\n\n\nP &gt; CVMe mínimo\nLa empresa produce en el corto plazo. Si P &lt; CTMe mínimo, la empresa cubre sus costos variables y parte de sus costes fijos pero no todos. Si P &gt; CTMe mínimo, la empresa cubre todos sus costes variables y sus costes fijos.\n\n\nP = CVMe mínimo\nLa empresa es indiferente entre producir en el corto plazo o no producir. Cubre exactamente sus costes variables.\n\n\nP &lt; CVMe mínimo\nLa empresa cierra en el corto plazo. No cubre sus costes variables."
  },
  {
    "objectID": "posts/port_mg/estructuras_mercado/index.html#ejemplo-1--corto-plazo",
    "href": "posts/port_mg/estructuras_mercado/index.html#ejemplo-1--corto-plazo",
    "title": "Estructuras de Mercado con Python",
    "section": "Ejemplo # 1- Corto Plazo",
    "text": "Ejemplo # 1- Corto Plazo\nPrimero resolveremos el siguiente ejercicio de manera manual y posteriormente lo resolveremos en Python.\nSuponga que la empresa tiene una curva de costos de corto plazo dada por\n\\[\nC(Q) = 100 + 20Q + Q^2\n\\]\n\n¿Cuál es la ecuación para el costo variable Medio?\n¿Cuál es el valor mínimo para el costo variable promedio?\n¿Cuál es la curva de oferta de corto plazo?\n\nSolución\n\nDada la función de costo \\(C(Q) = 100 + 20Q + Q^2\\) es claro que el costo variable, CV, esta dado por \\[CV = 20Q + Q^2\\] por tanto su costo variable promedio es \\[CVMe = \\frac{CV}{Q} = 20 + Q\\]\nAhora bien, su costo marginal sabemos que unicamente requiere aplicar la regla de diferenciación, ya que \\[CMg = \\frac{\\partial C(Q)}{\\partial Q} = 20 + 2Q\\]\nSi queremos encontrar el costo variable promedio mínimo, \\[CVMe_{\\min}\\], se obtiene como \\[CMg = CVMe \\longrightarrow Q = \\fbox{0}\\]\nEntonces la función de oferta es: \\[\\begin{eqnarray*}CMg &=& p\\\\[0.2cm] 20 + 2Q &=& P\\\\[0.2cm] Q(P) &=& \\frac{P}{2} - 10 \\end{eqnarray*}\\]\n\nPor tanto, también podemos obtener el precio de equilibrio, ya que \\[0 = \\frac{P}{2} - 10 \\longrightarrow P = \\fbox{20}\\]\nAhora, encontremos estos resultados en Python:\n\n# Paquete previo \nfrom sympy import *\nQ = symbols(\"Q\")\n\n\n# función de costo de corto plazo \nCT = 100 + 20*Q + Q**2\n# costo variale promedio \nCV = 20 + Q \n# Encontrar el costo variable minimo \n# Primero: costo marginal\n\nCM = diff(CT,Q)\n\n\n# igualar costo marginal y costo variable promedio \nsolve(Eq(CM,CV))\n\n[0]\n\n\n\ncantidad = solve(Eq(CM,CV))\ncantidad[0]\n\n\\(\\displaystyle 0\\)\n\n\n\nP = CV.subs({Q:cantidad[0]})\nP\n\n\\(\\displaystyle 20\\)\n\n\n\nplot(CT, CT/Q, CV, CM, (Q,0,100), xlim = (0, 100), ylim = (0,100), xlabel = \"Q\", ylabel = \"P\")\n\n\n\n\n&lt;sympy.plotting.plot.Plot at 0x27e122c6aa0&gt;\n\n\nPuedes notar lo rápido y fácil que resulta realizar estos procedimientos con Python y la utilidad que puede brindarte en caso de que trabajes con volumnes de datos.\n\nEjemplo # 2 - Corto Plazo\nAhora suponga que la empresa tiene una curva costos en el corto plazo de la siguiente forma:\n\\[\nC(Q) = 1 + 10Q + Q^2\n\\]\nSi la empresa opera en un mercado perfectamente competitivo, donde \\(P = 12\\), ¿Cuál será los beneficios de la empresa en el corto plazo?\nSolución\nSabemos que la función de beneficios esta dada por\n\\[\n\\pi = R - C\n\\]\nentonces,\n\\[\n\\frac{\\partial \\pi}{\\partial Q} = IMg - CMg = 0\n\\]\nasí pues,\n\\[\nCMg = 10 + 2Q \\hspace{1cm}y\\hspace{1cm} IMg = P\n\\]\npor tanto,\n\\[\n\\begin{eqnarray*}\nCMg &=& IMg\\\\[0.2cm]\n10 + 2Q &=& P\\\\[0.2cm]\nQ &=& \\frac{P}{2} - 5\\\\[0.2cm]\nQ &=& \\frac{12}{2} - 5, \\hspace{2cm}\\mbox{ya que P = 12}\\\\[0.2cm]\nQ &=& \\fbox{1}\n\\end{eqnarray*}\n\\]\nentonces,\n\\[\n\\pi = 12 - (1 + 10 +1) = \\fbox{0}\n\\]\nAhora veamos esta solución en Python:\n\n# Función de costos a corto plazo \nQ = symbols(\"Q\")\nCT = Q**2 + 10*Q + 1\nP = 12\nR = P*Q\n# costo marginal\nCM = diff(CT,Q)\nCM\nIM = diff(R,Q)\nIM\ncantidad = solve(Eq(IM,CM))\nprint(\"El valor de la producción que garantiza un equilibrio será:\", cantidad[0])\n\nEl valor de la producción que garantiza un equilibrio será: 1\n\n\nEste resultado lo que nos dice es que la empresa oferta una unidad de producción \\(Q = 1\\).\n\n# Beneficio = IT - CT\ncosto = CT.subs({Q:cantidad[0]})\ncosto\n\n\\(\\displaystyle 12\\)\n\n\n\ningreso = R.subs({Q:cantidad[0]})\ningreso \n\n\\(\\displaystyle 12\\)\n\n\n\nBeneficios = R - CT\npi = Beneficios.subs({Q:cantidad[0]})\npi\n\n\\(\\displaystyle 0\\)\n\n\n\nplot(CT,CM,CT/Q,(Q,0,60), xlim=(0,5), ylim=(0,30), xlabel='Q', ylabel='CT,CM')\n\n\n\n\n&lt;sympy.plotting.plot.Plot at 0x27e0c90e830&gt;\n\n\nRecuerde que todo este análisis se realizo para un mercado en competencia perfecta a corto plazo.\nPronto actualizare para el mercado en competencia perfecta a largo plazo, monopolio, e introducirnos un poco a la teoria de juegos."
  },
  {
    "objectID": "posts/RN/index.html",
    "href": "posts/RN/index.html",
    "title": "Redes Neuronales Recurrentes (LSTM)",
    "section": "",
    "text": "Las redes neuronales recurrentes son una arquitectura bastante empleada puesto que emplean los output de salida para retroalimentarse y continuar prediciendo un output.\n\n\n\n\nPrincipalmente sirve para contextos donde el orden importa y sirve como predictor recurrente (series de tiempo, textos, audios)\nSin embargo, ¿que tanto recordar el pasado? ¿cuál es la consecuencia en el rendimiento y demora de estimación?\nSus tipos más utilizados son LSTM y GRU\n\nEn este post nos enfocaremos en utilizar, describir y simular la red LSTM.\n\n\n\n\nPredictor de la siguiente palabra\nSeries de tiempo\nNo recomendable para transversal"
  },
  {
    "objectID": "posts/RN/index.html#red-de-memoria-de-corto-y-largo-plazo-lstm",
    "href": "posts/RN/index.html#red-de-memoria-de-corto-y-largo-plazo-lstm",
    "title": "Redes Neuronales Recurrentes (LSTM)",
    "section": "Red de Memoria de Corto y Largo Plazo (LSTM)",
    "text": "Red de Memoria de Corto y Largo Plazo (LSTM)\nLas redes LSTM (Long Short-Term Memory) son un tipo especial de redes neuronales recurrentes diseñadas con celdas de memoria que mantienen su estado a largo plazo. El principal objetivo de este tipo de redes es la solución del desvanecimiento del gradiente experimentado en las redes recurrentes. Globalmente, el flujo computacional de LSTM se ve de la siguiente manera:\n\n\n\nFlujo computacional de LSTM\n\n\nLas redes neuronales recurrentes pasan solo un estado oculto \\(h_t\\) a través de cada iteración. Pero LSTM pasa dos vectores: \\(h_t-\\)estado oculto (memoria a corto plazo) y \\(c_t-\\)estado celular (memoria a largo plazo).\nLas salidas de la celda LSTM se calculan a traves de las fórmulas que se muestran a continuación:\n\\[\\begin{eqnarray}\ni_t &=& \\sigma(w_{ii}x_t + b_ii + w_{hi}h_{(t-1)} + b_{hi})\\\\[0.2cm]\nf_t &=& \\sigma(w_{if}x_t + b_{if} + w_{hj}h_{(t-1)} + b_{hf})\\\\[0.2cm]\ng_t &=& \\tanh(w_{ig}x_t + b_{ig} + w_{hg}h_{(t-1)} + b_{hn})\\\\[0.2cm]\no_t &=& \\sigma(w_{io}x_t + b_{io} + w_{ho}h_{(t-1)} + b_{ho})\\\\[0.2cm]\nc_t &=& f_t \\circ c_{t-1} + i_t\\circ g_t\\\\[0.2cm]\nh_t &=& o_t \\circ \\tanh(c_t)\n\\end{eqnarray}\\]\ndonde:\n\n\\(\\sigma\\) es la función sigmoidea\n\\(\\circ\\) es el producto de Hadamard, que es:\n\\[\n\\begin{bmatrix}\na_1 \\\\\na_2 \\\\\na_3\n\\end{bmatrix} \\circ\n\\begin{bmatrix}\nb_1 \\\\\nb_2 \\\\\nb_3\n\\end{bmatrix} = \\begin{bmatrix}\na_1b_1\\\\\na_2b_2\\\\\na_3b_3\n\\end{bmatrix}\n\\]\n\n\nVariables\n\n\\(i_t\\) (puerta de entrada) es la variable que se utiliza para actualizar el estado de la celda \\(c_t\\). El estado previamente oculto \\(c_t\\) y la entrada secuencial actual \\(x_t\\) se dan como entrada a una función sigmoidea. Si la salida está cerca a uno, más importante es la información.\n\\(f_t\\) (puerta de olvido) es la variable que decide que información debe olvidarse en el estado de celda \\(c_t\\). El estadp previamente oculto \\(h_t\\) y la entrada de secuencia \\(x_t\\) se dan como entradas a una función sigmoidea. Si la salida \\(f_t\\) está cerca de cero, entonces la información puede olvidarse, mientras que si la salida esta cerca de uno, la información debe almacenarse.\n\\(g_t\\) representa información importante potencialmente nueva para el estado celular \\(c_t\\).\n\\(c_t\\) (estado celular) es una suma de:\n\nEstado de celada anterior \\(c_{t-1}\\) con alguna información olvidada \\(f_t\\).\nNueva información de \\(g_t\\).\n\n\n\n\n\\(o_t\\) (puerta de salida) es la variable para actualizar el estado oculto \\(h_t\\).\n\\(h_t\\) (estado oculto) es el siguiente estado oculto que se calcula seleccionando la información importante \\(o_t\\) del estado de celda \\(c_t\\).\n\nLa siguiente figura muestra el gráfico computacional de la celda LSTM:\n\n\n\nGráfico computacional de LSTM\n\n\nLa red LSTM tiene los siguientes parámetros, que se ajustan durante el entrenamiento:\n\n\\(w_{ii}, w_{hi}, w_{if}, w_{hf}, w_{ig}, w_{hg}, w_{io}, w_{ho}\\) - Pesos\n\\(b_{ii}, b_{hi}, b_{if}, b_{hf}, b_{ig}, b_{io}, b_{ho}\\) - Sesgos\n\nLos modelos LSTM son lo suficientemente potentes como para aprender los comportamientos pasados más importantes y comprender si esos comportamientos pasados son características importantes para hacer predicciones futuras. Hay varias aplicaciones en las que las LSTM se utilizan mucho. Aplicaciones como reconocimiento de voz, composición musical, reconocimiento de escritura a mano.\nParticularmente considero que las LSTM es como un modelo que tiene su propia memoria y que puede comportarse como un humano inteligente en la toma de desiciones."
  },
  {
    "objectID": "posts/RN/index.html#simulación-de-pronósticon-usando-lstm-con-python",
    "href": "posts/RN/index.html#simulación-de-pronósticon-usando-lstm-con-python",
    "title": "Redes Neuronales Recurrentes (LSTM)",
    "section": "Simulación de Pronósticon usando LSTM con Python",
    "text": "Simulación de Pronósticon usando LSTM con Python\n\n# Librerías \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandas import datetime\nimport math, time\nimport itertools\nfrom sklearn import preprocessing\nimport datetime\nfrom operator import itemgetter\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.layers import LSTM\nfrom keras.models import load_model\nimport keras\nimport h5py\nimport requests\nimport os\n\nC:\\Users\\juani\\AppData\\Local\\Temp\\ipykernel_19320\\3683430178.py:5: FutureWarning:\n\nThe pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n\n\n\n\n# Cargamos nuestro Dataset\ndf = pd.read_csv(\"prices-split-adjusted.csv\", index_col = 0)\n\n\n# Graficamos el precio de cierre (Close) de AAPL\nplt.figure(figsize=(15, 5));\nplt.subplot(1,2,1);\nplt.plot(df[df.symbol == 'EQIX'].close.values, color='green', label='close')\nplt.title('Indice de AAPL')\nplt.xlabel('días')\nplt.ylabel('precio de cierre (Close)')\nplt.legend(loc='best')\n\n<matplotlib.legend.Legend at 0x2708c43af50>\n\n\n\n\n\n\n# data_df es nuestra data que comenzara a tratarse y posterioremente con la cual\n# se estara trabajando el resto del proyecto\ndata_df = pd.read_csv(\"prices-split-adjusted.csv\", index_col = 0)\ndata_df.head()\n\n\n\n\n\n  \n    \n      \n      symbol\n      open\n      close\n      low\n      high\n      volume\n    \n    \n      date\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2016-01-05\n      WLTW\n      123.430000\n      125.839996\n      122.309998\n      126.250000\n      2163600.0\n    \n    \n      2016-01-06\n      WLTW\n      125.239998\n      119.980003\n      119.940002\n      125.540001\n      2386400.0\n    \n    \n      2016-01-07\n      WLTW\n      116.379997\n      114.949997\n      114.930000\n      119.739998\n      2489500.0\n    \n    \n      2016-01-08\n      WLTW\n      115.480003\n      116.620003\n      113.500000\n      117.440002\n      2006300.0\n    \n    \n      2016-01-11\n      WLTW\n      117.010002\n      114.970001\n      114.089996\n      117.330002\n      1408600.0\n    \n  \n\n\n\n\n\ndata_df = data_df[data_df.symbol == 'AAPL']\ndata_df.drop(['symbol'],1,inplace=True)\ndata_df.head()\n\nC:\\Users\\juani\\AppData\\Local\\Temp\\ipykernel_19320\\1763401402.py:2: FutureWarning:\n\nIn a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n\n\n\n\n\n\n\n  \n    \n      \n      open\n      close\n      low\n      high\n      volume\n    \n    \n      date\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2010-01-04\n      30.490000\n      30.572857\n      30.340000\n      30.642857\n      123432400.0\n    \n    \n      2010-01-05\n      30.657143\n      30.625713\n      30.464285\n      30.798571\n      150476200.0\n    \n    \n      2010-01-06\n      30.625713\n      30.138571\n      30.107143\n      30.747143\n      138040000.0\n    \n    \n      2010-01-07\n      30.250000\n      30.082857\n      29.864286\n      30.285715\n      119282800.0\n    \n    \n      2010-01-08\n      30.042856\n      30.282858\n      29.865715\n      30.285715\n      111902700.0\n    \n  \n\n\n\n\n\ndata_df['date'] = data_df.index\ndata_df.head()\n\n\n\n\n\n  \n    \n      \n      open\n      close\n      low\n      high\n      volume\n      date\n    \n    \n      date\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2010-01-04\n      30.490000\n      30.572857\n      30.340000\n      30.642857\n      123432400.0\n      2010-01-04\n    \n    \n      2010-01-05\n      30.657143\n      30.625713\n      30.464285\n      30.798571\n      150476200.0\n      2010-01-05\n    \n    \n      2010-01-06\n      30.625713\n      30.138571\n      30.107143\n      30.747143\n      138040000.0\n      2010-01-06\n    \n    \n      2010-01-07\n      30.250000\n      30.082857\n      29.864286\n      30.285715\n      119282800.0\n      2010-01-07\n    \n    \n      2010-01-08\n      30.042856\n      30.282858\n      29.865715\n      30.285715\n      111902700.0\n      2010-01-08\n    \n  \n\n\n\n\n\ndata_df['date'] = pd.to_datetime(data_df['date'])\n\n\nmin_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\ndataset = min_max_scaler.fit_transform(data_df['close'].values.reshape(-1, 1))\n\n\ntrain_size = int(len(dataset) * 0.7)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\nprint(len(train), len(test))\n\n1233 529\n\n\n\n# create_dataset: convertir una matriz de valores en una matriz de conjunto de datos\ndef create_dataset(dataset, look_back=15):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)\n\n\nx_train, y_train = create_dataset(train, look_back=15)\nx_test, y_test = create_dataset(test, look_back=15)\n\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)\n\n(1217, 15)\n(1217,)\n(513, 15)\n(513,)\n\n\n\nx_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\nx_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n\n\nlook_back = 15\nmodel = Sequential()\nmodel.add(LSTM(40, input_shape=(1, look_back)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(x_train, y_train, epochs=60, batch_size=12, verbose=2)\n\nEpoch 1/60\n\n\n102/102 - 2s - loss: 0.0150 - 2s/epoch - 23ms/step\n\n\nEpoch 2/60\n\n\n102/102 - 0s - loss: 7.6262e-04 - 183ms/epoch - 2ms/step\n\n\nEpoch 3/60\n\n\n102/102 - 0s - loss: 6.6221e-04 - 192ms/epoch - 2ms/step\n\n\nEpoch 4/60\n\n\n102/102 - 0s - loss: 6.3328e-04 - 183ms/epoch - 2ms/step\n\n\nEpoch 5/60\n\n\n102/102 - 0s - loss: 6.0453e-04 - 184ms/epoch - 2ms/step\n\n\nEpoch 6/60\n\n\n102/102 - 0s - loss: 5.8064e-04 - 188ms/epoch - 2ms/step\n\n\nEpoch 7/60\n\n\n102/102 - 0s - loss: 5.4382e-04 - 186ms/epoch - 2ms/step\n\n\nEpoch 8/60\n\n\n102/102 - 0s - loss: 5.1208e-04 - 180ms/epoch - 2ms/step\n\n\nEpoch 9/60\n\n\n102/102 - 0s - loss: 4.8958e-04 - 202ms/epoch - 2ms/step\n\n\nEpoch 10/60\n\n\n102/102 - 0s - loss: 4.6846e-04 - 190ms/epoch - 2ms/step\n\n\nEpoch 11/60\n\n\n102/102 - 0s - loss: 4.4484e-04 - 184ms/epoch - 2ms/step\n\n\nEpoch 12/60\n\n\n102/102 - 0s - loss: 4.1551e-04 - 211ms/epoch - 2ms/step\n\n\nEpoch 13/60\n\n\n102/102 - 0s - loss: 4.1124e-04 - 191ms/epoch - 2ms/step\n\n\nEpoch 14/60\n\n\n102/102 - 0s - loss: 4.0314e-04 - 190ms/epoch - 2ms/step\n\n\nEpoch 15/60\n\n\n102/102 - 0s - loss: 3.8374e-04 - 199ms/epoch - 2ms/step\n\n\nEpoch 16/60\n\n\n102/102 - 0s - loss: 3.5150e-04 - 196ms/epoch - 2ms/step\n\n\nEpoch 17/60\n\n\n102/102 - 0s - loss: 3.7239e-04 - 205ms/epoch - 2ms/step\n\n\nEpoch 18/60\n\n\n102/102 - 0s - loss: 3.2483e-04 - 190ms/epoch - 2ms/step\n\n\nEpoch 19/60\n\n\n102/102 - 0s - loss: 2.9874e-04 - 183ms/epoch - 2ms/step\n\n\nEpoch 20/60\n\n\n102/102 - 0s - loss: 2.8785e-04 - 184ms/epoch - 2ms/step\n\n\nEpoch 21/60\n\n\n102/102 - 0s - loss: 2.8977e-04 - 185ms/epoch - 2ms/step\n\n\nEpoch 22/60\n\n\n102/102 - 0s - loss: 2.6227e-04 - 186ms/epoch - 2ms/step\n\n\nEpoch 23/60\n\n\n102/102 - 0s - loss: 2.6883e-04 - 181ms/epoch - 2ms/step\n\n\nEpoch 24/60\n\n\n102/102 - 0s - loss: 2.4219e-04 - 210ms/epoch - 2ms/step\n\n\nEpoch 25/60\n\n\n102/102 - 0s - loss: 2.4725e-04 - 189ms/epoch - 2ms/step\n\n\nEpoch 26/60\n\n\n102/102 - 0s - loss: 2.3647e-04 - 181ms/epoch - 2ms/step\n\n\nEpoch 27/60\n\n\n102/102 - 0s - loss: 2.5362e-04 - 185ms/epoch - 2ms/step\n\n\nEpoch 28/60\n\n\n102/102 - 0s - loss: 2.2308e-04 - 185ms/epoch - 2ms/step\n\n\nEpoch 29/60\n\n\n102/102 - 0s - loss: 2.0847e-04 - 183ms/epoch - 2ms/step\n\n\nEpoch 30/60\n\n\n102/102 - 0s - loss: 2.2562e-04 - 189ms/epoch - 2ms/step\n\n\nEpoch 31/60\n\n\n102/102 - 0s - loss: 2.0874e-04 - 186ms/epoch - 2ms/step\n\n\nEpoch 32/60\n\n\n102/102 - 0s - loss: 2.1588e-04 - 185ms/epoch - 2ms/step\n\n\nEpoch 33/60\n\n\n102/102 - 0s - loss: 2.1389e-04 - 184ms/epoch - 2ms/step\n\n\nEpoch 34/60\n\n\n102/102 - 0s - loss: 1.9209e-04 - 180ms/epoch - 2ms/step\n\n\nEpoch 35/60\n\n\n102/102 - 0s - loss: 1.9363e-04 - 179ms/epoch - 2ms/step\n\n\nEpoch 36/60\n\n\n102/102 - 0s - loss: 2.2127e-04 - 184ms/epoch - 2ms/step\n\n\nEpoch 37/60\n\n\n102/102 - 0s - loss: 1.9697e-04 - 183ms/epoch - 2ms/step\n\n\nEpoch 38/60\n\n\n102/102 - 0s - loss: 1.8795e-04 - 189ms/epoch - 2ms/step\n\n\nEpoch 39/60\n\n\n102/102 - 0s - loss: 1.9005e-04 - 186ms/epoch - 2ms/step\n\n\nEpoch 40/60\n\n\n102/102 - 0s - loss: 1.7190e-04 - 191ms/epoch - 2ms/step\n\n\nEpoch 41/60\n\n\n102/102 - 0s - loss: 1.8237e-04 - 188ms/epoch - 2ms/step\n\n\nEpoch 42/60\n\n\n102/102 - 0s - loss: 2.1899e-04 - 180ms/epoch - 2ms/step\n\n\nEpoch 43/60\n\n\n102/102 - 0s - loss: 1.9020e-04 - 192ms/epoch - 2ms/step\n\n\nEpoch 44/60\n\n\n102/102 - 0s - loss: 1.6493e-04 - 188ms/epoch - 2ms/step\n\n\nEpoch 45/60\n\n\n102/102 - 0s - loss: 1.7761e-04 - 182ms/epoch - 2ms/step\n\n\nEpoch 46/60\n\n\n102/102 - 0s - loss: 1.6017e-04 - 192ms/epoch - 2ms/step\n\n\nEpoch 47/60\n\n\n102/102 - 0s - loss: 1.9724e-04 - 192ms/epoch - 2ms/step\n\n\nEpoch 48/60\n\n\n102/102 - 0s - loss: 1.8514e-04 - 194ms/epoch - 2ms/step\n\n\nEpoch 49/60\n\n\n102/102 - 0s - loss: 1.8597e-04 - 180ms/epoch - 2ms/step\n\n\nEpoch 50/60\n\n\n102/102 - 0s - loss: 1.7456e-04 - 187ms/epoch - 2ms/step\n\n\nEpoch 51/60\n\n\n102/102 - 0s - loss: 1.9399e-04 - 193ms/epoch - 2ms/step\n\n\nEpoch 52/60\n\n\n102/102 - 0s - loss: 1.4870e-04 - 179ms/epoch - 2ms/step\n\n\nEpoch 53/60\n\n\n102/102 - 0s - loss: 1.7235e-04 - 173ms/epoch - 2ms/step\n\n\nEpoch 54/60\n\n\n102/102 - 0s - loss: 1.6592e-04 - 192ms/epoch - 2ms/step\n\n\nEpoch 55/60\n\n\n102/102 - 0s - loss: 1.6269e-04 - 173ms/epoch - 2ms/step\n\n\nEpoch 56/60\n\n\n102/102 - 0s - loss: 1.9207e-04 - 182ms/epoch - 2ms/step\n\n\nEpoch 57/60\n\n\n102/102 - 0s - loss: 1.4854e-04 - 184ms/epoch - 2ms/step\n\n\nEpoch 58/60\n\n\n102/102 - 0s - loss: 1.6661e-04 - 189ms/epoch - 2ms/step\n\n\nEpoch 59/60\n\n\n102/102 - 0s - loss: 1.5341e-04 - 180ms/epoch - 2ms/step\n\n\nEpoch 60/60\n\n\n102/102 - 0s - loss: 1.5276e-04 - 181ms/epoch - 2ms/step\n\n\n<keras.callbacks.History at 0x2708cf178e0>\n\n\n\ntrainPredict = model.predict(x_train)\ntestPredict = model.predict(x_test)\n# invertimos las predicciones\ntrainPredict = min_max_scaler.inverse_transform(trainPredict)\ntrainY = min_max_scaler.inverse_transform([y_train])\ntestPredict = min_max_scaler.inverse_transform(testPredict)\ntestY = min_max_scaler.inverse_transform([y_test])\n# calculate root mean squared e\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))\n\n 1/39 [..............................] - ETA: 13s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31/39 [======================>.......] - ETA: 0s \n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39/39 [==============================] - 0s 2ms/step\n\n\n 1/17 [>.............................] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b17/17 [==============================] - 0s 2ms/step\n\n\nTrain Score: 1.26 RMSE\nTest Score: 1.96 RMSE\n\n\n\n# shift train predictions for plotting\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nplt.plot(min_max_scaler.inverse_transform(dataset), label = \"Precio Historico\")\nplt.plot(trainPredictPlot, label = \"Datos Entrenamiento\")\nplt.plot(testPredictPlot, label = \"Predicción de Precio\")\nplt.legend()\nplt.title('Indice de AAPL')\nplt.xlabel('días')\nplt.ylabel('precio de cierre (Close)')\nplt.show()"
  },
  {
    "objectID": "posts/RN/index.html#simulación-de-pronóstico-usando-lstm-con-python",
    "href": "posts/RN/index.html#simulación-de-pronóstico-usando-lstm-con-python",
    "title": "Redes Neuronales Recurrentes (LSTM)",
    "section": "Simulación de Pronóstico Usando LSTM con Python",
    "text": "Simulación de Pronóstico Usando LSTM con Python\nEl pronóstico que realizamos para poner en marcha nuestro modelo LSTM es sobre el precio de cierre (close) del índice bursátil de Apple (AAPL). La librería o paquete principal para construcción de nuestro modelo fue Tensorflow. A continuación el lector puede apreciar la codificación que se llevó a cabo para poder construir nuestro modelo.\n\n# Librerías \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandas import datetime\nimport math, time\nimport itertools\nfrom sklearn import preprocessing\nimport datetime\nfrom operator import itemgetter\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.layers import LSTM\nfrom keras.models import load_model\nimport keras\nimport h5py\nimport requests\nimport os\n\nC:\\Users\\juani\\AppData\\Local\\Temp\\ipykernel_22428\\3683430178.py:5: FutureWarning:\n\nThe pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n\n\n\n\n# Cargamos nuestro Dataset\ndf = pd.read_csv(\"prices-split-adjusted.csv\", index_col = 0)\n\n\n# Graficamos el precio de cierre (Close) de AAPL\nplt.figure(figsize=(15, 5));\nplt.subplot(1,2,1);\nplt.plot(df[df.symbol == 'EQIX'].close.values, color='green', label='close')\nplt.title('Indice de AAPL')\nplt.xlabel('días')\nplt.ylabel('precio de cierre (Close)')\nplt.legend(loc='best')\n\n<matplotlib.legend.Legend at 0x1e62400af50>\n\n\n\n\n\n\n# data_df es nuestra data que comenzara a tratarse y posterioremente con la cual\n# se estara trabajando el resto del proyecto\ndata_df = pd.read_csv(\"prices-split-adjusted.csv\", index_col = 0)\ndata_df.head()\n\n\n\n\n\n  \n    \n      \n      symbol\n      open\n      close\n      low\n      high\n      volume\n    \n    \n      date\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2016-01-05\n      WLTW\n      123.430000\n      125.839996\n      122.309998\n      126.250000\n      2163600.0\n    \n    \n      2016-01-06\n      WLTW\n      125.239998\n      119.980003\n      119.940002\n      125.540001\n      2386400.0\n    \n    \n      2016-01-07\n      WLTW\n      116.379997\n      114.949997\n      114.930000\n      119.739998\n      2489500.0\n    \n    \n      2016-01-08\n      WLTW\n      115.480003\n      116.620003\n      113.500000\n      117.440002\n      2006300.0\n    \n    \n      2016-01-11\n      WLTW\n      117.010002\n      114.970001\n      114.089996\n      117.330002\n      1408600.0\n    \n  \n\n\n\n\n\ndata_df = data_df[data_df.symbol == 'AAPL']\ndata_df.drop(['symbol'],1,inplace=True)\ndata_df.head()\n\nC:\\Users\\juani\\AppData\\Local\\Temp\\ipykernel_22428\\1763401402.py:2: FutureWarning:\n\nIn a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n\n\n\n\n\n\n\n  \n    \n      \n      open\n      close\n      low\n      high\n      volume\n    \n    \n      date\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2010-01-04\n      30.490000\n      30.572857\n      30.340000\n      30.642857\n      123432400.0\n    \n    \n      2010-01-05\n      30.657143\n      30.625713\n      30.464285\n      30.798571\n      150476200.0\n    \n    \n      2010-01-06\n      30.625713\n      30.138571\n      30.107143\n      30.747143\n      138040000.0\n    \n    \n      2010-01-07\n      30.250000\n      30.082857\n      29.864286\n      30.285715\n      119282800.0\n    \n    \n      2010-01-08\n      30.042856\n      30.282858\n      29.865715\n      30.285715\n      111902700.0\n    \n  \n\n\n\n\n\ndata_df['date'] = data_df.index\ndata_df.head()\n\n\n\n\n\n  \n    \n      \n      open\n      close\n      low\n      high\n      volume\n      date\n    \n    \n      date\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2010-01-04\n      30.490000\n      30.572857\n      30.340000\n      30.642857\n      123432400.0\n      2010-01-04\n    \n    \n      2010-01-05\n      30.657143\n      30.625713\n      30.464285\n      30.798571\n      150476200.0\n      2010-01-05\n    \n    \n      2010-01-06\n      30.625713\n      30.138571\n      30.107143\n      30.747143\n      138040000.0\n      2010-01-06\n    \n    \n      2010-01-07\n      30.250000\n      30.082857\n      29.864286\n      30.285715\n      119282800.0\n      2010-01-07\n    \n    \n      2010-01-08\n      30.042856\n      30.282858\n      29.865715\n      30.285715\n      111902700.0\n      2010-01-08\n    \n  \n\n\n\n\n\ndata_df['date'] = pd.to_datetime(data_df['date'])\n\n\nmin_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\ndataset = min_max_scaler.fit_transform(data_df['close'].values.reshape(-1, 1))\n\n\ntrain_size = int(len(dataset) * 0.7)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\nprint(len(train), len(test))\n\n1233 529\n\n\n\n# create_dataset: convertir una matriz de valores en una matriz de conjunto de datos\ndef create_dataset(dataset, look_back=15):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)\n\n\nx_train, y_train = create_dataset(train, look_back=15)\nx_test, y_test = create_dataset(test, look_back=15)\n\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)\n\n(1217, 15)\n(1217,)\n(513, 15)\n(513,)\n\n\n\nx_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\nx_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n\n\n# Creamos y entrenamos el modelo LSTM\nlook_back = 15\nmodel = Sequential()\nmodel.add(LSTM(40, input_shape=(1, look_back)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(x_train, y_train, epochs=80, batch_size=12, verbose=2)\n\nEpoch 1/80\n\n\n102/102 - 3s - loss: 0.0113 - 3s/epoch - 32ms/step\n\n\nEpoch 2/80\n\n\n102/102 - 0s - loss: 6.3842e-04 - 260ms/epoch - 3ms/step\n\n\nEpoch 3/80\n\n\n102/102 - 0s - loss: 5.7844e-04 - 258ms/epoch - 3ms/step\n\n\nEpoch 4/80\n\n\n102/102 - 0s - loss: 5.6023e-04 - 258ms/epoch - 3ms/step\n\n\nEpoch 5/80\n\n\n102/102 - 0s - loss: 5.1903e-04 - 263ms/epoch - 3ms/step\n\n\nEpoch 6/80\n\n\n102/102 - 0s - loss: 4.8845e-04 - 257ms/epoch - 3ms/step\n\n\nEpoch 7/80\n\n\n102/102 - 0s - loss: 4.5870e-04 - 258ms/epoch - 3ms/step\n\n\nEpoch 8/80\n\n\n102/102 - 0s - loss: 4.3559e-04 - 260ms/epoch - 3ms/step\n\n\nEpoch 9/80\n\n\n102/102 - 0s - loss: 4.0958e-04 - 261ms/epoch - 3ms/step\n\n\nEpoch 10/80\n\n\n102/102 - 0s - loss: 3.9100e-04 - 266ms/epoch - 3ms/step\n\n\nEpoch 11/80\n\n\n102/102 - 0s - loss: 3.6612e-04 - 263ms/epoch - 3ms/step\n\n\nEpoch 12/80\n\n\n102/102 - 0s - loss: 3.5953e-04 - 260ms/epoch - 3ms/step\n\n\nEpoch 13/80\n\n\n102/102 - 0s - loss: 3.2104e-04 - 249ms/epoch - 2ms/step\n\n\nEpoch 14/80\n\n\n102/102 - 0s - loss: 3.0965e-04 - 257ms/epoch - 3ms/step\n\n\nEpoch 15/80\n\n\n102/102 - 0s - loss: 2.8168e-04 - 254ms/epoch - 2ms/step\n\n\nEpoch 16/80\n\n\n102/102 - 0s - loss: 2.5952e-04 - 251ms/epoch - 2ms/step\n\n\nEpoch 17/80\n\n\n102/102 - 0s - loss: 2.3784e-04 - 252ms/epoch - 2ms/step\n\n\nEpoch 18/80\n\n\n102/102 - 0s - loss: 2.3917e-04 - 255ms/epoch - 2ms/step\n\n\nEpoch 19/80\n\n\n102/102 - 0s - loss: 2.6529e-04 - 253ms/epoch - 2ms/step\n\n\nEpoch 20/80\n\n\n102/102 - 0s - loss: 2.2736e-04 - 251ms/epoch - 2ms/step\n\n\nEpoch 21/80\n\n\n102/102 - 0s - loss: 2.2051e-04 - 257ms/epoch - 3ms/step\n\n\nEpoch 22/80\n\n\n102/102 - 0s - loss: 2.1977e-04 - 265ms/epoch - 3ms/step\n\n\nEpoch 23/80\n\n\n102/102 - 0s - loss: 2.4310e-04 - 261ms/epoch - 3ms/step\n\n\nEpoch 24/80\n\n\n102/102 - 0s - loss: 2.3080e-04 - 254ms/epoch - 2ms/step\n\n\nEpoch 25/80\n\n\n102/102 - 0s - loss: 1.9992e-04 - 254ms/epoch - 2ms/step\n\n\nEpoch 26/80\n\n\n102/102 - 0s - loss: 2.1494e-04 - 251ms/epoch - 2ms/step\n\n\nEpoch 27/80\n\n\n102/102 - 0s - loss: 2.1917e-04 - 254ms/epoch - 2ms/step\n\n\nEpoch 28/80\n\n\n102/102 - 0s - loss: 2.0118e-04 - 269ms/epoch - 3ms/step\n\n\nEpoch 29/80\n\n\n102/102 - 0s - loss: 2.1571e-04 - 258ms/epoch - 3ms/step\n\n\nEpoch 30/80\n\n\n102/102 - 0s - loss: 1.9306e-04 - 255ms/epoch - 2ms/step\n\n\nEpoch 31/80\n\n\n102/102 - 0s - loss: 2.5637e-04 - 254ms/epoch - 2ms/step\n\n\nEpoch 32/80\n\n\n102/102 - 0s - loss: 1.9886e-04 - 256ms/epoch - 3ms/step\n\n\nEpoch 33/80\n\n\n102/102 - 0s - loss: 2.1006e-04 - 260ms/epoch - 3ms/step\n\n\nEpoch 34/80\n\n\n102/102 - 0s - loss: 1.8493e-04 - 266ms/epoch - 3ms/step\n\n\nEpoch 35/80\n\n\n102/102 - 0s - loss: 1.9396e-04 - 260ms/epoch - 3ms/step\n\n\nEpoch 36/80\n\n\n102/102 - 0s - loss: 1.9777e-04 - 258ms/epoch - 3ms/step\n\n\nEpoch 37/80\n\n\n102/102 - 0s - loss: 1.8756e-04 - 259ms/epoch - 3ms/step\n\n\nEpoch 38/80\n\n\n102/102 - 0s - loss: 1.8287e-04 - 254ms/epoch - 2ms/step\n\n\nEpoch 39/80\n\n\n102/102 - 0s - loss: 1.7400e-04 - 255ms/epoch - 3ms/step\n\n\nEpoch 40/80\n\n\n102/102 - 0s - loss: 1.8051e-04 - 260ms/epoch - 3ms/step\n\n\nEpoch 41/80\n\n\n102/102 - 0s - loss: 1.8086e-04 - 267ms/epoch - 3ms/step\n\n\nEpoch 42/80\n\n\n102/102 - 0s - loss: 2.1853e-04 - 267ms/epoch - 3ms/step\n\n\nEpoch 43/80\n\n\n102/102 - 0s - loss: 1.7517e-04 - 256ms/epoch - 3ms/step\n\n\nEpoch 44/80\n\n\n102/102 - 0s - loss: 1.9113e-04 - 258ms/epoch - 3ms/step\n\n\nEpoch 45/80\n\n\n102/102 - 0s - loss: 1.6536e-04 - 269ms/epoch - 3ms/step\n\n\nEpoch 46/80\n\n\n102/102 - 0s - loss: 1.7508e-04 - 264ms/epoch - 3ms/step\n\n\nEpoch 47/80\n\n\n102/102 - 0s - loss: 1.8322e-04 - 256ms/epoch - 3ms/step\n\n\nEpoch 48/80\n\n\n102/102 - 0s - loss: 1.6636e-04 - 259ms/epoch - 3ms/step\n\n\nEpoch 49/80\n\n\n102/102 - 0s - loss: 1.7943e-04 - 260ms/epoch - 3ms/step\n\n\nEpoch 50/80\n\n\n102/102 - 0s - loss: 1.8184e-04 - 255ms/epoch - 2ms/step\n\n\nEpoch 51/80\n\n\n102/102 - 0s - loss: 1.8314e-04 - 254ms/epoch - 2ms/step\n\n\nEpoch 52/80\n\n\n102/102 - 0s - loss: 1.6062e-04 - 259ms/epoch - 3ms/step\n\n\nEpoch 53/80\n\n\n102/102 - 0s - loss: 1.6473e-04 - 260ms/epoch - 3ms/step\n\n\nEpoch 54/80\n\n\n102/102 - 0s - loss: 1.6214e-04 - 255ms/epoch - 2ms/step\n\n\nEpoch 55/80\n\n\n102/102 - 0s - loss: 1.7255e-04 - 260ms/epoch - 3ms/step\n\n\nEpoch 56/80\n\n\n102/102 - 0s - loss: 1.5994e-04 - 268ms/epoch - 3ms/step\n\n\nEpoch 57/80\n\n\n102/102 - 0s - loss: 1.6509e-04 - 271ms/epoch - 3ms/step\n\n\nEpoch 58/80\n\n\n102/102 - 0s - loss: 1.6058e-04 - 258ms/epoch - 3ms/step\n\n\nEpoch 59/80\n\n\n102/102 - 0s - loss: 1.5973e-04 - 257ms/epoch - 3ms/step\n\n\nEpoch 60/80\n\n\n102/102 - 0s - loss: 1.6962e-04 - 261ms/epoch - 3ms/step\n\n\nEpoch 61/80\n\n\n102/102 - 0s - loss: 1.7296e-04 - 257ms/epoch - 3ms/step\n\n\nEpoch 62/80\n\n\n102/102 - 0s - loss: 1.8389e-04 - 250ms/epoch - 2ms/step\n\n\nEpoch 63/80\n\n\n102/102 - 0s - loss: 1.6510e-04 - 255ms/epoch - 2ms/step\n\n\nEpoch 64/80\n\n\n102/102 - 0s - loss: 1.5845e-04 - 255ms/epoch - 3ms/step\n\n\nEpoch 65/80\n\n\n102/102 - 0s - loss: 1.5989e-04 - 255ms/epoch - 3ms/step\n\n\nEpoch 66/80\n\n\n102/102 - 0s - loss: 1.6230e-04 - 254ms/epoch - 2ms/step\n\n\nEpoch 67/80\n\n\n102/102 - 0s - loss: 1.9168e-04 - 253ms/epoch - 2ms/step\n\n\nEpoch 68/80\n\n\n102/102 - 0s - loss: 1.4577e-04 - 273ms/epoch - 3ms/step\n\n\nEpoch 69/80\n\n\n102/102 - 0s - loss: 1.5320e-04 - 264ms/epoch - 3ms/step\n\n\nEpoch 70/80\n\n\n102/102 - 0s - loss: 1.7691e-04 - 252ms/epoch - 2ms/step\n\n\nEpoch 71/80\n\n\n102/102 - 0s - loss: 1.5635e-04 - 268ms/epoch - 3ms/step\n\n\nEpoch 72/80\n\n\n102/102 - 0s - loss: 1.4415e-04 - 265ms/epoch - 3ms/step\n\n\nEpoch 73/80\n\n\n102/102 - 0s - loss: 1.6942e-04 - 262ms/epoch - 3ms/step\n\n\nEpoch 74/80\n\n\n102/102 - 0s - loss: 1.4780e-04 - 266ms/epoch - 3ms/step\n\n\nEpoch 75/80\n\n\n102/102 - 0s - loss: 1.5037e-04 - 266ms/epoch - 3ms/step\n\n\nEpoch 76/80\n\n\n102/102 - 0s - loss: 1.6177e-04 - 259ms/epoch - 3ms/step\n\n\nEpoch 77/80\n\n\n102/102 - 0s - loss: 1.5421e-04 - 253ms/epoch - 2ms/step\n\n\nEpoch 78/80\n\n\n102/102 - 0s - loss: 1.6364e-04 - 254ms/epoch - 2ms/step\n\n\nEpoch 79/80\n\n\n102/102 - 0s - loss: 1.6383e-04 - 264ms/epoch - 3ms/step\n\n\nEpoch 80/80\n\n\n102/102 - 0s - loss: 1.4784e-04 - 266ms/epoch - 3ms/step\n\n\n<keras.callbacks.History at 0x1e624aeb910>\n\n\n\n# Metricas utilizadas en el modelo \n\ntrainPredict = model.predict(x_train)\ntestPredict = model.predict(x_test)\n# invertimos las predicciones\ntrainPredict = min_max_scaler.inverse_transform(trainPredict)\ntrainY = min_max_scaler.inverse_transform([y_train])\ntestPredict = min_max_scaler.inverse_transform(testPredict)\ntestY = min_max_scaler.inverse_transform([y_test])\n# calculate root mean squared \ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))\n\n 1/39 [..............................] - ETA: 22s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b26/39 [===================>..........] - ETA: 0s \n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39/39 [==============================] - 1s 2ms/step\n\n\n 1/17 [>.............................] - ETA: 0s\n\n\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b17/17 [==============================] - 0s 2ms/step\n\n\nTrain Score: 1.49 RMSE\nTest Score: 2.44 RMSE\n\n\n\n# Graficamos los resultados \n\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n\nplt.plot(min_max_scaler.inverse_transform(dataset), label = \"Precio Historico\")\nplt.plot(trainPredictPlot, label = \"Datos Entrenamiento\")\nplt.plot(testPredictPlot, label = \"Predicción de Precio\")\nplt.legend()\nplt.title('Indice de AAPL')\nplt.xlabel('días')\nplt.ylabel('precio de cierre (Close)')\nplt.show()\n\n\n\n\nUn ejercicio interesante para el lector podría ser, asumir el reto de tratar de mejorar las métricas RMSE para Train como para el Test. Una posible alternativa es utilizar más capas intermedias. Intenta asumir el reto y comenta tus resultados aquí en el post."
  },
  {
    "objectID": "sobre_juan.html",
    "href": "sobre_juan.html",
    "title": "Historias",
    "section": "",
    "text": "En esta sección de mi website conoceras un poco de las diferentes actividades que realizó o he realizado en algunos de mis días.\nCelebrando el cumpleaños de mi amigo Elmer, felicidades crack.\n\nLinda Experiencia, impartiendo el curso sobre fundamentos estadísticos utilizando el software de R a estudiantes de la maestría en Gestión de Proyectos de la UNAH.\n\n\n\n\n\nParticipación en conversatorio estudiantes egresados de la Lic. Matemáticas UNAH 2023\n\nNoche de Cine - 8/07/2023\n\nEquipo de Trabajo - IHSS\n\nFestejando Graduación (Lic. Matemáticas) de Amigos\n\nFormando parte del jurado de la fería cientifica de los chicos del Instituto Hildegard"
  },
  {
    "objectID": "posts/RN/index.html#pronósticos-para-el-índice-de-aapl-utilizando-una-red-lstm",
    "href": "posts/RN/index.html#pronósticos-para-el-índice-de-aapl-utilizando-una-red-lstm",
    "title": "Redes Neuronales Recurrentes (LSTM)",
    "section": "Pronósticos para el índice de AAPL utilizando una red LSTM",
    "text": "Pronósticos para el índice de AAPL utilizando una red LSTM\nA continuación realizaremos un ejercicio donde intentamos pronósticar el precio de cierre (Close) del índice de AAPL, la data la puede encontrar dando click en prices-split-adjusted.csv .\nComenzamos importando las librerías a utilizar.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandas import datetime\nimport math, time\nimport itertools\nfrom sklearn import preprocessing\nimport datetime\nfrom operator import itemgetter\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.layers import LSTM\nfrom keras.models import load_model\nimport keras\nimport h5py\nimport requests\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\nC:\\Users\\juani\\AppData\\Local\\Temp\\ipykernel_18008\\2001173417.py:4: FutureWarning:\n\nThe pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n\n\n\nCargamos el DataSet y lo almacenamos en la variable df y data_df. La data almacenada en data_df es la que utilizaremos para realizar todo nuestro estudio.\n\ndf = pd.read_csv(\"prices-split-adjusted.csv\", index_col = 0)\n\n\ndata_df = pd.read_csv(\"prices-split-adjusted.csv\", index_col = 0)\ndata_df.head()\n\n\n\n\n\n\n\n\nsymbol\nopen\nclose\nlow\nhigh\nvolume\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n2016-01-05\nWLTW\n123.430000\n125.839996\n122.309998\n126.250000\n2163600.0\n\n\n2016-01-06\nWLTW\n125.239998\n119.980003\n119.940002\n125.540001\n2386400.0\n\n\n2016-01-07\nWLTW\n116.379997\n114.949997\n114.930000\n119.739998\n2489500.0\n\n\n2016-01-08\nWLTW\n115.480003\n116.620003\n113.500000\n117.440002\n2006300.0\n\n\n2016-01-11\nWLTW\n117.010002\n114.970001\n114.089996\n117.330002\n1408600.0\n\n\n\n\n\n\n\nEste bloque de código fue de mucha utilidad, dado que aquí filtramos de nuestro dataset unicamente la información para el indice de AAPL y visualizamos la data.\n\ndata_df = data_df[data_df.symbol == 'AAPL']\ndata_df.drop(['symbol'],1,inplace=True)\ndata_df.head()\n\n\n\n\n\n\n\n\nopen\nclose\nlow\nhigh\nvolume\n\n\ndate\n\n\n\n\n\n\n\n\n\n2010-01-04\n30.490000\n30.572857\n30.340000\n30.642857\n123432400.0\n\n\n2010-01-05\n30.657143\n30.625713\n30.464285\n30.798571\n150476200.0\n\n\n2010-01-06\n30.625713\n30.138571\n30.107143\n30.747143\n138040000.0\n\n\n2010-01-07\n30.250000\n30.082857\n29.864286\n30.285715\n119282800.0\n\n\n2010-01-08\n30.042856\n30.282858\n29.865715\n30.285715\n111902700.0\n\n\n\n\n\n\n\nPreliminarmente con este bloque de código podemos ver como se comporta la serie correspondiente al precio de cierre de las acciones de AAPL.\n\nplt.figure(figsize=(15, 5));\nplt.subplot(1,2,1);\nplt.plot(df[df.symbol == 'EQIX'].close.values, color='green', label='close')\nplt.title('Indice de AAPL')\nplt.xlabel('días')\nplt.ylabel('precio de cierre (Close)')\nplt.legend(loc='best')\n\n&lt;matplotlib.legend.Legend at 0x236b99436a0&gt;\n\n\n\n\n\nNecesitamos manipular nuestro campo de fecha para poder manipularlas como lo que son en realidad (fechas).\n\ndata_df['date'] = data_df.index\ndata_df.head()\n\n\n\n\n\n\n\n\nopen\nclose\nlow\nhigh\nvolume\ndate\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n2010-01-04\n30.490000\n30.572857\n30.340000\n30.642857\n123432400.0\n2010-01-04\n\n\n2010-01-05\n30.657143\n30.625713\n30.464285\n30.798571\n150476200.0\n2010-01-05\n\n\n2010-01-06\n30.625713\n30.138571\n30.107143\n30.747143\n138040000.0\n2010-01-06\n\n\n2010-01-07\n30.250000\n30.082857\n29.864286\n30.285715\n119282800.0\n2010-01-07\n\n\n2010-01-08\n30.042856\n30.282858\n29.865715\n30.285715\n111902700.0\n2010-01-08\n\n\n\n\n\n\n\n\ndata_df['date'] = pd.to_datetime(data_df['date'])\n\nTransformamos los datos con MinMaxScaler() para que se distribuyan normal estándar, recuerde que esto es con media cero y varianza 1.\n\nmin_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\ndataset = min_max_scaler.fit_transform(data_df['close'].values.reshape(-1, 1))\n\nDividimos la data en datos de entrenamiento (train), tomando el 70% de los datos para entrenar nuestro modelo y un 20% para prueba (test).\n\ntrain_size = int(len(dataset) * 0.7)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\nprint(len(train), len(test))\n\n1233 529\n\n\n\n# convertir una matriz de valores en una matriz de conjunto de datos\ndef create_dataset(dataset, look_back=15):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)\n\n\nx_train, y_train = create_dataset(train, look_back=15)\nx_test, y_test = create_dataset(test, look_back=15)\n\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)\n\n(1217, 15)\n(1217,)\n(513, 15)\n(513,)\n\n\n\nx_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\nx_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n\nComenzamos a crear y entrenar nuestro modelo LSTM.\n\nlook_back = 15\nmodel = Sequential()\nmodel.add(LSTM(20, input_shape=(1, look_back)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(x_train, y_train, epochs=90, batch_size=8, verbose=2)\n\nEpoch 1/90\n153/153 - 2s - loss: 0.0174 - 2s/epoch - 16ms/step\nEpoch 2/90\n153/153 - 0s - loss: 5.3418e-04 - 273ms/epoch - 2ms/step\nEpoch 3/90\n153/153 - 0s - loss: 4.4450e-04 - 278ms/epoch - 2ms/step\nEpoch 4/90\n153/153 - 0s - loss: 4.2874e-04 - 277ms/epoch - 2ms/step\nEpoch 5/90\n153/153 - 0s - loss: 4.0739e-04 - 268ms/epoch - 2ms/step\nEpoch 6/90\n153/153 - 0s - loss: 3.8709e-04 - 284ms/epoch - 2ms/step\nEpoch 7/90\n153/153 - 0s - loss: 3.7214e-04 - 273ms/epoch - 2ms/step\nEpoch 8/90\n153/153 - 0s - loss: 3.6078e-04 - 276ms/epoch - 2ms/step\nEpoch 9/90\n153/153 - 0s - loss: 3.5206e-04 - 290ms/epoch - 2ms/step\nEpoch 10/90\n153/153 - 0s - loss: 3.2790e-04 - 269ms/epoch - 2ms/step\nEpoch 11/90\n153/153 - 0s - loss: 3.0376e-04 - 288ms/epoch - 2ms/step\nEpoch 12/90\n153/153 - 0s - loss: 3.0369e-04 - 272ms/epoch - 2ms/step\nEpoch 13/90\n153/153 - 0s - loss: 3.1673e-04 - 272ms/epoch - 2ms/step\nEpoch 14/90\n153/153 - 0s - loss: 2.6855e-04 - 288ms/epoch - 2ms/step\nEpoch 15/90\n153/153 - 0s - loss: 2.6134e-04 - 274ms/epoch - 2ms/step\nEpoch 16/90\n153/153 - 0s - loss: 2.7831e-04 - 266ms/epoch - 2ms/step\nEpoch 17/90\n153/153 - 0s - loss: 2.3250e-04 - 280ms/epoch - 2ms/step\nEpoch 18/90\n153/153 - 0s - loss: 2.4377e-04 - 277ms/epoch - 2ms/step\nEpoch 19/90\n153/153 - 0s - loss: 2.1988e-04 - 300ms/epoch - 2ms/step\nEpoch 20/90\n153/153 - 0s - loss: 2.1443e-04 - 309ms/epoch - 2ms/step\nEpoch 21/90\n153/153 - 0s - loss: 2.0727e-04 - 308ms/epoch - 2ms/step\nEpoch 22/90\n153/153 - 0s - loss: 2.1768e-04 - 303ms/epoch - 2ms/step\nEpoch 23/90\n153/153 - 0s - loss: 1.9675e-04 - 301ms/epoch - 2ms/step\nEpoch 24/90\n153/153 - 0s - loss: 1.8817e-04 - 298ms/epoch - 2ms/step\nEpoch 25/90\n153/153 - 0s - loss: 2.0940e-04 - 302ms/epoch - 2ms/step\nEpoch 26/90\n153/153 - 0s - loss: 1.8725e-04 - 273ms/epoch - 2ms/step\nEpoch 27/90\n153/153 - 0s - loss: 1.9996e-04 - 268ms/epoch - 2ms/step\nEpoch 28/90\n153/153 - 0s - loss: 1.8666e-04 - 269ms/epoch - 2ms/step\nEpoch 29/90\n153/153 - 0s - loss: 2.0690e-04 - 289ms/epoch - 2ms/step\nEpoch 30/90\n153/153 - 0s - loss: 1.8579e-04 - 290ms/epoch - 2ms/step\nEpoch 31/90\n153/153 - 0s - loss: 1.8400e-04 - 327ms/epoch - 2ms/step\nEpoch 32/90\n153/153 - 0s - loss: 2.0776e-04 - 370ms/epoch - 2ms/step\nEpoch 33/90\n153/153 - 0s - loss: 1.7955e-04 - 285ms/epoch - 2ms/step\nEpoch 34/90\n153/153 - 0s - loss: 1.8656e-04 - 283ms/epoch - 2ms/step\nEpoch 35/90\n153/153 - 0s - loss: 1.7452e-04 - 363ms/epoch - 2ms/step\nEpoch 36/90\n153/153 - 0s - loss: 1.8671e-04 - 291ms/epoch - 2ms/step\nEpoch 37/90\n153/153 - 0s - loss: 2.0337e-04 - 276ms/epoch - 2ms/step\nEpoch 38/90\n153/153 - 0s - loss: 1.8612e-04 - 290ms/epoch - 2ms/step\nEpoch 39/90\n153/153 - 0s - loss: 1.7868e-04 - 287ms/epoch - 2ms/step\nEpoch 40/90\n153/153 - 0s - loss: 1.6047e-04 - 288ms/epoch - 2ms/step\nEpoch 41/90\n153/153 - 0s - loss: 1.7351e-04 - 274ms/epoch - 2ms/step\nEpoch 42/90\n153/153 - 0s - loss: 1.7513e-04 - 277ms/epoch - 2ms/step\nEpoch 43/90\n153/153 - 0s - loss: 1.6558e-04 - 286ms/epoch - 2ms/step\nEpoch 44/90\n153/153 - 0s - loss: 1.6894e-04 - 273ms/epoch - 2ms/step\nEpoch 45/90\n153/153 - 0s - loss: 1.9839e-04 - 270ms/epoch - 2ms/step\nEpoch 46/90\n153/153 - 0s - loss: 1.6972e-04 - 283ms/epoch - 2ms/step\nEpoch 47/90\n153/153 - 0s - loss: 1.9237e-04 - 287ms/epoch - 2ms/step\nEpoch 48/90\n153/153 - 0s - loss: 1.7812e-04 - 276ms/epoch - 2ms/step\nEpoch 49/90\n153/153 - 0s - loss: 1.6258e-04 - 283ms/epoch - 2ms/step\nEpoch 50/90\n153/153 - 0s - loss: 1.5556e-04 - 296ms/epoch - 2ms/step\nEpoch 51/90\n153/153 - 0s - loss: 1.5876e-04 - 279ms/epoch - 2ms/step\nEpoch 52/90\n153/153 - 0s - loss: 1.5916e-04 - 266ms/epoch - 2ms/step\nEpoch 53/90\n153/153 - 0s - loss: 1.7933e-04 - 363ms/epoch - 2ms/step\nEpoch 54/90\n153/153 - 0s - loss: 1.6076e-04 - 298ms/epoch - 2ms/step\nEpoch 55/90\n153/153 - 0s - loss: 1.5508e-04 - 276ms/epoch - 2ms/step\nEpoch 56/90\n153/153 - 0s - loss: 2.0915e-04 - 270ms/epoch - 2ms/step\nEpoch 57/90\n153/153 - 0s - loss: 1.6386e-04 - 340ms/epoch - 2ms/step\nEpoch 58/90\n153/153 - 0s - loss: 1.8083e-04 - 276ms/epoch - 2ms/step\nEpoch 59/90\n153/153 - 0s - loss: 1.5268e-04 - 274ms/epoch - 2ms/step\nEpoch 60/90\n153/153 - 0s - loss: 1.4961e-04 - 275ms/epoch - 2ms/step\nEpoch 61/90\n153/153 - 0s - loss: 1.8783e-04 - 271ms/epoch - 2ms/step\nEpoch 62/90\n153/153 - 0s - loss: 1.4447e-04 - 280ms/epoch - 2ms/step\nEpoch 63/90\n153/153 - 0s - loss: 1.4833e-04 - 275ms/epoch - 2ms/step\nEpoch 64/90\n153/153 - 0s - loss: 1.5035e-04 - 270ms/epoch - 2ms/step\nEpoch 65/90\n153/153 - 0s - loss: 1.6430e-04 - 272ms/epoch - 2ms/step\nEpoch 66/90\n153/153 - 0s - loss: 1.5268e-04 - 280ms/epoch - 2ms/step\nEpoch 67/90\n153/153 - 0s - loss: 1.6926e-04 - 282ms/epoch - 2ms/step\nEpoch 68/90\n153/153 - 0s - loss: 1.4859e-04 - 270ms/epoch - 2ms/step\nEpoch 69/90\n153/153 - 0s - loss: 1.6119e-04 - 285ms/epoch - 2ms/step\nEpoch 70/90\n153/153 - 0s - loss: 1.6663e-04 - 262ms/epoch - 2ms/step\nEpoch 71/90\n153/153 - 0s - loss: 1.6530e-04 - 280ms/epoch - 2ms/step\nEpoch 72/90\n153/153 - 0s - loss: 1.7051e-04 - 285ms/epoch - 2ms/step\nEpoch 73/90\n153/153 - 0s - loss: 1.6448e-04 - 275ms/epoch - 2ms/step\nEpoch 74/90\n153/153 - 0s - loss: 1.6769e-04 - 278ms/epoch - 2ms/step\nEpoch 75/90\n153/153 - 0s - loss: 1.6086e-04 - 271ms/epoch - 2ms/step\nEpoch 76/90\n153/153 - 0s - loss: 1.6478e-04 - 279ms/epoch - 2ms/step\nEpoch 77/90\n153/153 - 0s - loss: 1.5804e-04 - 263ms/epoch - 2ms/step\nEpoch 78/90\n153/153 - 0s - loss: 1.5207e-04 - 334ms/epoch - 2ms/step\nEpoch 79/90\n153/153 - 0s - loss: 1.3981e-04 - 295ms/epoch - 2ms/step\nEpoch 80/90\n153/153 - 0s - loss: 1.3907e-04 - 287ms/epoch - 2ms/step\nEpoch 81/90\n153/153 - 0s - loss: 1.5976e-04 - 307ms/epoch - 2ms/step\nEpoch 82/90\n153/153 - 0s - loss: 1.6238e-04 - 339ms/epoch - 2ms/step\nEpoch 83/90\n153/153 - 0s - loss: 1.4658e-04 - 497ms/epoch - 3ms/step\nEpoch 84/90\n153/153 - 0s - loss: 1.6490e-04 - 310ms/epoch - 2ms/step\nEpoch 85/90\n153/153 - 0s - loss: 1.5613e-04 - 283ms/epoch - 2ms/step\nEpoch 86/90\n153/153 - 0s - loss: 1.5913e-04 - 302ms/epoch - 2ms/step\nEpoch 87/90\n153/153 - 0s - loss: 1.5089e-04 - 288ms/epoch - 2ms/step\nEpoch 88/90\n153/153 - 0s - loss: 1.6357e-04 - 276ms/epoch - 2ms/step\nEpoch 89/90\n153/153 - 0s - loss: 1.4136e-04 - 271ms/epoch - 2ms/step\nEpoch 90/90\n153/153 - 0s - loss: 1.4603e-04 - 275ms/epoch - 2ms/step\n\n\n&lt;keras.callbacks.History at 0x236b9801000&gt;\n\n\nEvaluamos nuestro modelo, utilizando la métrica del RMSE para los datos de train y test.\n\ntrainPredict = model.predict(x_train)\ntestPredict = model.predict(x_test)\n# Invertimos las predicciones, dado que las habiamos transformado con MinMaxScaler\ntrainPredict = min_max_scaler.inverse_transform(trainPredict)\ntrainY = min_max_scaler.inverse_transform([y_train])\ntestPredict = min_max_scaler.inverse_transform(testPredict)\ntestY = min_max_scaler.inverse_transform([y_test])\n# calculamos el RMSE\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))\n\n 1/39 [..............................] - ETA: 13s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39/39 [==============================] - 0s 1ms/step\n 1/17 [&gt;.............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b17/17 [==============================] - 0s 1ms/step\nTrain Score: 1.20 RMSE\nTest Score: 1.91 RMSE\n\n\nFinalmente, observamos nuestro resultados gráficamente\n\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n\nplt.plot(min_max_scaler.inverse_transform(dataset), label = \"Precio Historico\")\nplt.plot(trainPredictPlot, label = \"Datos Entrenamiento\")\nplt.plot(testPredictPlot, label = \"Predicción de Precio\")\nplt.legend()\nplt.show()\n\n\n\n\nNote que nuestros resultados son muy buenos, sin embargo, podrían mejorarse, quizas aplicando más capas ocultas a nuestra red, recuerde que solo utilizamos 20. Este podría ser un buen ejercicio para que usted intente mejorar estos resultados.\nRecuerda que puedes comentar este post, agradeceria que lo hagas ya sea para alguna sugerencia u observación. Saludos espero hayas conocido un poco sobre este tipo de Red Neuronal en particular y su potente poder predectivo."
  },
  {
    "objectID": "posts/XGBoost/index.html",
    "href": "posts/XGBoost/index.html",
    "title": "Time Series Forecasting with XGBoost",
    "section": "",
    "text": "MLForecast es un marco de datos para realizar pronósticos de series de tiempo utilizando modelos de aprendizaje automático, con la opción de escalar a cantidades masivas de datos utilizando clústeres remotos.\n\n\nLas alternativas actuales de Python para los modelos de aprendizaje automático son lentas, imprecisas y no escalan bien. Así que se crearón una biblioteca que se puede usar para hacer pronósticos en entornos de producción. MLForecast incluye ingeniería de características eficientes para entrenar cualquier modelo de aprendizaje automático (con fit y predict métodos como sklearn) para adaptarse a millones de series temporales.\n\n\n\n\nLas implementaciones más rapidas de ingeniería de funciones para la previsión de series temporales en Python.\nCompatibilidad lista para usar con Spark, Dask y Ray\nPronósticos probabilísticos con predicción conforme.|\nSoporte para variables exógenas y covariables estáticas.\nSintaxis familiar sklearn: .fit y .predict\n\n\n\n\nLa validación cruzada de series temporales es un método para evaluar cómo se habría comportado un modelo en el pasado. Funciona definiendo una ventana deslizante a través de los datos históricos y prediciendo el período que le sigue.\nMLForecast tiene una implementación de validación cruzada de series de tiempo que es rápida y fácil de usar. Esta implementación hace que la validación cruzada sea una operación eficiente, lo que hace que consuma menos tiempo.\n\n\nUna vez que se ha instanciado el objeto MLForecast, podemos usar el método cross_validation, que toma los siguientes argumentos:\n\ndata: marco de datos de entrenamiento con formato MLForecast.\nwindow_size(int): representa los h pasos hacia el futuro que se pronosticarán\nn_windows (int): cantidad de ventanas utilizadas para la validación cruzada, es decir, la cantidad de procesos de pronóstico en el pasado que desea evaluar.\nid_col: identifica cada serie temporal\ntime_col: identifica la columna de la serie temporal\ntarget_col: identifica la columna a modelar\n\nEl objeto crossvaldation_df es un nuevo marco de datos que incluye las siguientes columnas:\n\nunique_id: identifica cada serie temporal\nds: marca de fecha o índice temporal\ncutoff: la última marca de fecha o índice temporal del n_windows\nmodel: columnas con el nombre del modelo y el valor ajustado.\n\n\n\n\nUna vez hecho todo lo anterior, podremos calcular la precisión del pronóstico utilizando una métrica de precisión adecuada. En mi caso particular uso el error cuadrático medio (RMSE). Para hacer esto, primero debemos instalar datasetsforecast, una biblioteca de Python desarrollada por Nixtla que incluye una función para calcular el RMSE.\nLa función para calcular el RMSE toma dos argumentos:\n\nLos valores reales\nLas predicciones\n\nEsta medida debería reflejar mejor las capacidades predictivas de nuestro modelo, ya que utilizo diferentes periodos de tiempo para probar su precisión."
  },
  {
    "objectID": "posts/XGBoost/index.html#toerema-del-modelo-xgboost",
    "href": "posts/XGBoost/index.html#toerema-del-modelo-xgboost",
    "title": "Time Series Forecasting with XGBoost",
    "section": "Toerema del Modelo XGBoost",
    "text": "Toerema del Modelo XGBoost\nDados los datos de entrenamiento \\(D = (x_1, y_1), (x_2, y_2), . . . , (x_n, y_n)\\) donde cada \\(x_i\\) es un vector de características de entrada y cada \\(y_i\\) es la etiqueta de salida correspondiente, el objetivo es encontrar una función \\(f(x)\\) que mapee los vectores de características a las etiquetas de salida y minimice el error de predicción en el conjunto de entrenamiento."
  },
  {
    "objectID": "posts/XGBoost/index.html#section",
    "href": "posts/XGBoost/index.html#section",
    "title": "Time Series Forecasting with XGBoost",
    "section": "",
    "text": "La construcción del modelo implica la creación de un conjunto de árboles de decisión, donde cada árbol se construye de manera secuencial para minimizar la función de costo global, que es la suma de las funciones de costo individuales de cada árbol.\nEl algoritmo XGBoost también utiliza técnicas de regularización para evitar el sobreajuste, lo que ayuda a mejorar el rendimiento en conjuntos de datos no visto. Estás técnicas incluyen la poda de árboles, la penalización \\(L_1\\) y \\(L_2\\), y el muestreo aleatorio de observaciones y variables.\nUna característica del modelo XGBoost es que puede trabajar con tados a lo bruto (es decir, bases que contengan datos faltantes), es tan robusto que puede trabajar con este tipo de datos."
  },
  {
    "objectID": "posts/XGBoost/index.html#modelo-xgboost-matemáticamente",
    "href": "posts/XGBoost/index.html#modelo-xgboost-matemáticamente",
    "title": "Time Series Forecasting with XGBoost",
    "section": "Modelo XGBoost Matemáticamente",
    "text": "Modelo XGBoost Matemáticamente\nEl modelo XGBoost se construye a través de una combinación de árboles de decisión y técnicas de optimización de gradiente. En términos matemáticos el modelo XGBoost se puede escribir como:\n\\[\nf(x) = \\sum T(x;\\theta_j)\n\\]\ndonde \\(f(x)\\) es la función de predicción para el conjunto de características de entrada \\(x\\), \\(T(x;\\theta_j)\\) es un árbol de decisión con parámetros \\(\\theta_j\\), y la suma se realiza sobre un conjunto de árboles de decisión.\nCada árbol de decisión se construye de manera secuencial para minimizar la función de costo global, que es la suma de las funciones de costo individuales de cada árbol, es decir:\n\\[L = \\sum l(y_i,f_i(x_i)) + \\sum \\Omega(\\theta_j)\\]\ndonde \\(l(y_i, f_i(x_i))\\) es la función de costo para el i-ésimo ejemplo de entrenamiento, \\(f_i(x_i)\\) es la predicción del modelo para el i-ésimo ejemplo de entrenamiento,y \\(\\Omega(\\theta_j)\\) es la penalización para el j-ésimo árbol de decisión, diseñada para evitar el sobreajuste.\nLa función de costo se puede escribir de varias maneras, dependiendo del problema específico. Por ejemplo, en un problema de regresión, la función de costo podría ser el error cuadrático medio (MSE), mientras que en un problema de clasificación, la función de costo podría ser la antropía cruzada.\nPara construir el modelo XGBoost, se utilizan técnicas de optimización de gradiente para minimizar la función de costo global. Estas técnicas implican calcular las derivadas de la función de costo con respecto a los parámetros del modelo, y ajustar los parámetros en consecuencia.\nAdemás, XGBoost utiliza técnicas de regularización para evitar el sobreajuste, como la poda de árboles, la penalización \\(L_1\\) y \\(L_2\\), y el muestreo aleatorio de observaciones y variables.\nEn resumen, el modelo XGBoost se construye a través de una combinación de árboles de decisión y técnicas de optimización de gradiente, con el objetivo de minimizar la función de costo global mientras se aplica la regularización para evitar el sobreajuste."
  },
  {
    "objectID": "posts/XGBoost/index.html#xgboost-para-series-de-tiempo",
    "href": "posts/XGBoost/index.html#xgboost-para-series-de-tiempo",
    "title": "Time Series Forecasting with XGBoost",
    "section": "XGBoost para series de tiempo",
    "text": "XGBoost para series de tiempo\nXGBoost también puede ser aplicado a problemas de series de tiempo. Sin embargo, es importante tener en cuenta que la aplicación del modelo a datos de series de tiempo requiere un enfoque ligeramente diferente en comparación con los problemas de clasificación y regresión estándar.\nPara aplicar XGBoost a datos de series de tiempo, es necesario crear características adecuadas para el modelo, lo que puede incluir características basadas en ventanas moviles, diferencias y tasas de cambio. También es importante considerar la estacionalidad y las tendencias en los datos de series de tiempo y aplicar técnicas de preprocesamiento de datos y validación cruzada adecuadas para este tipo de problemas.\nAdemás, se deben tener en cuenta algunas consideraciones especiales en la configuración de características relevantes para la serie de tiempo y la selección de la función de costo y métricas de evaluación adecuadas."
  },
  {
    "objectID": "posts/XGBoost/index.html#estimación-del-rendimiento-del-modelo",
    "href": "posts/XGBoost/index.html#estimación-del-rendimiento-del-modelo",
    "title": "Time Series Forecasting with XGBoost",
    "section": "Estimación del Rendimiento del Modelo",
    "text": "Estimación del Rendimiento del Modelo\n\nValidación cruzada (cross-validation)\nPara obtener una estimación de qué tan bien será nuestro modelo al predecir datos futuros, podemos realizar una validación cruzada, que consiste en entrenar algunos modelos de forma independiente en diferentes subconjuntos de datos, usándolos para predecir un conjunto de validación y medir su rendimiento.\nDado que nuestros datos dependen del tiempo, hacemos nuestras divisiones eliminando las últimas partes de la serie y usándolas como conjuntos de validación. Este procesos se implementa en MLForecast.cross_validation"
  },
  {
    "objectID": "posts/XGBoost/index.html#características",
    "href": "posts/XGBoost/index.html#características",
    "title": "Time Series Forecasting with XGBoost",
    "section": "",
    "text": "Las implementaciones más rapidas de ingeniería de funciones para la previsión de series temporales en Python.\nCompatibilidad lista para usar con Spark, Dask y Ray\nPronósticos probabilísticos con predicción conforme.|\nSoporte para variables exógenas y covariables estáticas.\nSintaxis familiar sklearn: .fit y .predict"
  },
  {
    "objectID": "posts/XGBoost/index.html#validación-cruzada",
    "href": "posts/XGBoost/index.html#validación-cruzada",
    "title": "Time Series Forecasting with XGBoost",
    "section": "",
    "text": "La validación cruzada de series temporales es un método para evaluar cómo se habría comportado un modelo en el pasado. Funciona definiendo una ventana deslizante a través de los datos históricos y prediciendo el período que le sigue.\nMLForecast tiene una implementación de validación cruzada de series de tiempo que es rápida y fácil de usar. Esta implementación hace que la validación cruzada sea una operación eficiente, lo que hace que consuma menos tiempo.\n\n\nUna vez que se ha instanciado el objeto MLForecast, podemos usar el método cross_validation, que toma los siguientes argumentos:\n\ndata: marco de datos de entrenamiento con formato MLForecast.\nwindow_size(int): representa los h pasos hacia el futuro que se pronosticarán\nn_windows (int): cantidad de ventanas utilizadas para la validación cruzada, es decir, la cantidad de procesos de pronóstico en el pasado que desea evaluar.\nid_col: identifica cada serie temporal\ntime_col: identifica la columna de la serie temporal\ntarget_col: identifica la columna a modelar\n\nEl objeto crossvaldation_df es un nuevo marco de datos que incluye las siguientes columnas:\n\nunique_id: identifica cada serie temporal\nds: marca de fecha o índice temporal\ncutoff: la última marca de fecha o índice temporal del n_windows\nmodel: columnas con el nombre del modelo y el valor ajustado.\n\n\n\n\nUna vez hecho todo lo anterior, podremos calcular la precisión del pronóstico utilizando una métrica de precisión adecuada. En mi caso particular uso el error cuadrático medio (RMSE). Para hacer esto, primero debemos instalar datasetsforecast, una biblioteca de Python desarrollada por Nixtla que incluye una función para calcular el RMSE.\nLa función para calcular el RMSE toma dos argumentos:\n\nLos valores reales\nLas predicciones\n\nEsta medida debería reflejar mejor las capacidades predictivas de nuestro modelo, ya que utilizo diferentes periodos de tiempo para probar su precisión."
  },
  {
    "objectID": "posts/risk_score/index.html",
    "href": "posts/risk_score/index.html",
    "title": "Credit Scoring and Segmentation using Python",
    "section": "",
    "text": "La calificación crediticia y la segmentación se refieren al proceso de evaluar la solvencia de personas o empresas y dividirlos en distintos grupos según sus perfiles crediticios. Su objetivo es evaluar la probabilidad de que los prestatarios pagen sus deudas y ayuda a las instituciones financieras a tomar decisiones informadas sobre préstamos y gestión del riesgo crediticio. Si desea aprender a calcular puntajes crediticios y segmentar clientes en función de sus puntajes crediticios, este artículo es para usted. En este artículo, lo guiaré a través de la tarea de segementación y calificación crediticia usando Python."
  },
  {
    "objectID": "posts/risk_score/index.html#calificación-crediticia-y-segmentación-usando-python",
    "href": "posts/risk_score/index.html#calificación-crediticia-y-segmentación-usando-python",
    "title": "Credit Scoring and Segmentation using Python",
    "section": "Calificación crediticia y segmentación usando Python",
    "text": "Calificación crediticia y segmentación usando Python\nAhora comencemos con la tarea de segmentación y calificación crediticia importando las bibliotecas de Python necesarias y el conjunto de datos\n\nimport pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_white\"\n\ndata = pd.read_csv(\"credit_scoring.csv\")\ndata.head()\n\n\n\n\n\n\n\n\nAge\nGender\nMarital Status\nEducation Level\nEmployment Status\nCredit Utilization Ratio\nPayment History\nNumber of Credit Accounts\nLoan Amount\nInterest Rate\nLoan Term\nType of Loan\n\n\n\n\n0\n60\nMale\nMarried\nMaster\nEmployed\n0.22\n2685.0\n2\n4675000\n2.65\n48\nPersonal Loan\n\n\n1\n25\nMale\nMarried\nHigh School\nUnemployed\n0.20\n2371.0\n9\n3619000\n5.19\n60\nAuto Loan\n\n\n2\n30\nFemale\nSingle\nMaster\nEmployed\n0.22\n2771.0\n6\n957000\n2.76\n12\nAuto Loan\n\n\n3\n58\nFemale\nMarried\nPhD\nUnemployed\n0.12\n1371.0\n2\n4731000\n6.57\n60\nAuto Loan\n\n\n4\n32\nMale\nMarried\nBachelor\nSelf-Employed\n0.99\n828.0\n2\n3289000\n6.28\n36\nPersonal Loan\n\n\n\n\n\n\n\nA continuación se muestra la descripción de todas los campos de los datos:\n\nAge: representa la edad del individuo\nGender: identifica el género del individuo\nMarital Status: denota el estado civil del individuo\nEducation Level: representa en nivel más alto de educación alcanzado por el individuo.\nEmployment Status: indica el estado de empleo actual del individuo\nCredit Utilization: refleja la proporción de crédito utilizado por el individuo en comparación con su límite de crédito total disponible.\nInterest Rate: tasa de interés asociada con el préstamo.\nPayment History: representa el comportamiento de pago neto mensual de cada cliente, tomando en cuenta factores como pagos a tiempo, pagos atrasados, pagos atrasados e incumplimientos.\nNumber of Credit Accounts: representa el conteo de cuentas de crédito activas que posee la persona.\nLoan Amount: indica el valor monetario del préstamo.\nLoan Term: indica la duraciòn o plazo del préstamo.\nType of Loan: incluye categorías como “Préstamo personal”, “Préstamo para automovil” o potencialmente otro tipos de préstamos.\n\nAhora echemos un vistazo a las estadísticas de las columnas antes de seguir adelante:\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 12 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   Age                        1000 non-null   int64  \n 1   Gender                     1000 non-null   object \n 2   Marital Status             1000 non-null   object \n 3   Education Level            1000 non-null   object \n 4   Employment Status          1000 non-null   object \n 5   Credit Utilization Ratio   1000 non-null   float64\n 6   Payment History            1000 non-null   float64\n 7   Number of Credit Accounts  1000 non-null   int64  \n 8   Loan Amount                1000 non-null   int64  \n 9   Interest Rate              1000 non-null   float64\n 10  Loan Term                  1000 non-null   int64  \n 11  Type of Loan               1000 non-null   object \ndtypes: float64(3), int64(4), object(5)\nmemory usage: 93.9+ KB\n\n\nAhora echemos un vistazo a las estadísticas descriptivas de los datos:\n\ndata.describe()\n\n\n\n\n\n\n\n\nAge\nCredit Utilization Ratio\nPayment History\nNumber of Credit Accounts\nLoan Amount\nInterest Rate\nLoan Term\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1.000000e+03\n1000.000000\n1000.000000\n\n\nmean\n42.702000\n0.509950\n1452.814000\n5.580000\n2.471401e+06\n10.686600\n37.128000\n\n\nstd\n13.266771\n0.291057\n827.934146\n2.933634\n1.387047e+06\n5.479058\n17.436274\n\n\nmin\n20.000000\n0.000000\n0.000000\n1.000000\n1.080000e+05\n1.010000\n12.000000\n\n\n25%\n31.000000\n0.250000\n763.750000\n3.000000\n1.298000e+06\n6.022500\n24.000000\n\n\n50%\n42.000000\n0.530000\n1428.000000\n6.000000\n2.437500e+06\n10.705000\n36.000000\n\n\n75%\n54.000000\n0.750000\n2142.000000\n8.000000\n3.653250e+06\n15.440000\n48.000000\n\n\nmax\n65.000000\n1.000000\n2857.000000\n10.000000\n4.996000e+06\n19.990000\n60.000000\n\n\n\n\n\n\n\nAhora echemos un vistazo a la distribución del índice de utilización del crédito en los datos:\n\ncredit_utilization_fig = px.box(data, y='Credit Utilization Ratio',\n                                title='Distribución del índice de utilización del crédito')\ncredit_utilization_fig.show()\n\n\n                                                \n\n\nAhora echemos un vistazo a la distribución del monto del préstamo en los datos:\n\nloan_amount_fig = px.histogram(data, x='Loan Amount', \n                               nbins=20, \n                               title='Distribución del monto del préstamo')\nloan_amount_fig.show()\n\n\n                                                \n\n\nLuego, echemos un vistazo a la correlación en los datos:\n\nnumeric_df = data[['Credit Utilization Ratio', \n                   'Payment History', \n                   'Number of Credit Accounts', \n                   'Loan Amount', 'Interest Rate', \n                   'Loan Term']]\ncorrelation_fig = px.imshow(numeric_df.corr(), \n                            title='Mapa de calor de correlación')\ncorrelation_fig.show()"
  },
  {
    "objectID": "posts/risk_score/index.html#calcular-puntajes-de-crédito",
    "href": "posts/risk_score/index.html#calcular-puntajes-de-crédito",
    "title": "Credit Scoring and Segmentation using Python",
    "section": "Calcular puntajes de crédito",
    "text": "Calcular puntajes de crédito\nEl conjunto de datos no tiene ninguna característica que represente los puntajes crediticios de las personas. Para calcular las puntuaciones de crédito, debemos utilizar una técnica adecuada. Existen varias técnicas ampliamente utilizadas para calcular puntajes credeticios, cada una con su propio proceso de cálculo. Un ejemplo es el puntaje FICO, es un modelo de calificación crediticia comúnmente utilizado en la industria.\nA continuación se muestra cómo podemos implementar el método de puntuación FICO para calcular las puntuaciones de crédito.\n\n# Definir el mapeo para características categóricas\neducation_level_mapping = {'High School': 1, 'Bachelor': 2, 'Master': 3, 'PhD': 4}\nemployment_status_mapping = {'Unemployed': 0, 'Employed': 1, 'Self-Employed': 2}\n\n# Aplicar mapeo  a características categóricas\ndata['Education Level'] = data['Education Level'].map(education_level_mapping)\ndata['Employment Status'] = data['Employment Status'].map(employment_status_mapping)\n\n# Calcule puntajes de crédito utilizando la fórmula FICO completa\ncredit_scores = []\n\nfor index, row in data.iterrows():\n    payment_history = row['Payment History']\n    credit_utilization_ratio = row['Credit Utilization Ratio']\n    number_of_credit_accounts = row['Number of Credit Accounts']\n    education_level = row['Education Level']\n    employment_status = row['Employment Status']\n    \n    # Apliaue la fórmula FICO para calcular el puntaje crediticio\n    credit_score = (payment_history * 0.35) + (credit_utilization_ratio * 0.30) + (number_of_credit_accounts * 0.15) + (education_level * 0.10) + (employment_status * 0.10)\n    credit_scores.append(credit_score)\n\n# Agregue los puntajes de crédito como una nueva columna al DataFrame\ndata['Credit Score'] = credit_scores\n\ndata.head()\n\n\n\n\n\n\n\n\nAge\nGender\nMarital Status\nEducation Level\nEmployment Status\nCredit Utilization Ratio\nPayment History\nNumber of Credit Accounts\nLoan Amount\nInterest Rate\nLoan Term\nType of Loan\nCredit Score\n\n\n\n\n0\n60\nMale\nMarried\n3\n1\n0.22\n2685.0\n2\n4675000\n2.65\n48\nPersonal Loan\n940.516\n\n\n1\n25\nMale\nMarried\n1\n0\n0.20\n2371.0\n9\n3619000\n5.19\n60\nAuto Loan\n831.360\n\n\n2\n30\nFemale\nSingle\n3\n1\n0.22\n2771.0\n6\n957000\n2.76\n12\nAuto Loan\n971.216\n\n\n3\n58\nFemale\nMarried\n4\n0\n0.12\n1371.0\n2\n4731000\n6.57\n60\nAuto Loan\n480.586\n\n\n4\n32\nMale\nMarried\n2\n2\n0.99\n828.0\n2\n3289000\n6.28\n36\nPersonal Loan\n290.797\n\n\n\n\n\n\n\nA continuación se muestra cómo funciona el código anterior:\n\nEn primer lugar, define asignaciones para dos características categóricas: “Nivel de educación” y “Estado laboral”. La asignación de “Nivel de educación” asigna valores numéricos a diferentes niveles de educación, como “Escuela secundaria” asignada a 1, “Licenciatura” a 2, “Maestría” a 3 y “Doctorado” a 4. El “Estado de empleo” el mapeo asigna valores numéricos a diferentes estados laborales, como “desempleado” asignado a 0, “empleado” asigna 1 y “autónomo” a 2.\nA continuación, el código aplica las asignaciones definidas a las columnas correspondientes en el DataFrame. Transforma los valores de las columnas “Nivel de educación” y “Estado de empleo” de su forma categórica original a las representaciones numéricas asignadas.\nDespués de eso, el código inicia una iteración sobre cada fila del DataFrame para calcular las puntuaciones de crédito de cada individuo. Recupera los valores de características relevantes, como “Historial de pagos”, “índice de utilización de crédito”, “Número de cuentas de crédito”, “Nivel de educación” y “Estado de empleo”, de cada fila.\n\nDentro de la iteración, se aplica la fórmula FICO para calcular el puntaje de crediticio de cada individuo. La fórmula incorpora los valores ponderados de las características mencionadas anteriormente:\n\nPeso del 35% para “Historial de pagos (Payment History)”\nPeso del 30% para el “índice de utilización de crédito (Credit Utilization Ratio)”\nPeso del 15% para “Número de cuentas de crédito (Number of Credit Accounts)”\n10% de peso para “Nivel de educación (Education Level)”\ny 10% de ponderación para “Estatus laboral (Employment Status)”\n\nLuego, el puntaje crediticio calculado se almacena en una lista llamada \"credit_scores\"."
  },
  {
    "objectID": "posts/risk_score/index.html#segmentación-basada-en-puntakes-crediticios",
    "href": "posts/risk_score/index.html#segmentación-basada-en-puntakes-crediticios",
    "title": "Credit Scoring and Segmentation using Python",
    "section": "Segmentación basada en puntakes crediticios",
    "text": "Segmentación basada en puntakes crediticios\nAhora, usemos el algoritmo de agrupamiento KMeans para segmentar a los clientes según sus puntajes crediticios.\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\nX = data[['Credit Score']]\nX = np.nan_to_num(X)\nkmeans = KMeans(n_clusters=4, n_init=10, random_state=42)\nkmeans.fit(X)\ndata['Segment'] = kmeans.labels_\n\nAhora echemos un vistazo a los segmentos:\n\ndata.head()\n\n\n\n\n\n\n\n\nAge\nGender\nMarital Status\nEducation Level\nEmployment Status\nCredit Utilization Ratio\nPayment History\nNumber of Credit Accounts\nLoan Amount\nInterest Rate\nLoan Term\nType of Loan\nCredit Score\nSegment\n\n\n\n\n0\n60\nMale\nMarried\n3\n1\n0.22\n2685.0\n2\n4675000\n2.65\n48\nPersonal Loan\n940.516\n3\n\n\n1\n25\nMale\nMarried\n1\n0\n0.20\n2371.0\n9\n3619000\n5.19\n60\nAuto Loan\n831.360\n3\n\n\n2\n30\nFemale\nSingle\n3\n1\n0.22\n2771.0\n6\n957000\n2.76\n12\nAuto Loan\n971.216\n3\n\n\n3\n58\nFemale\nMarried\n4\n0\n0.12\n1371.0\n2\n4731000\n6.57\n60\nAuto Loan\n480.586\n0\n\n\n4\n32\nMale\nMarried\n2\n2\n0.99\n828.0\n2\n3289000\n6.28\n36\nPersonal Loan\n290.797\n0\n\n\n\n\n\n\n\n\n# Convertir la columna segmento al tipo de datos categoría\ndata['Segment'] = data['Segment'].astype('category')\n\n# Visualiza los segmentos usando Plotly\nfig = px.scatter(data, x=data.index, y='Credit Score', color='Segment',\n                 color_discrete_sequence=['green', 'blue', 'yellow', 'red'])\nfig.update_layout(\n    xaxis_title='Indice de clientes',\n    yaxis_title='Credit Score',\n    title='Customer Segmentation based on Credit Scores'\n)\nfig.show()\n\n\n                                                \n\n\nAhora nombremos los segmentos según los grupos anteriores y echemos un vistazo a los segmentos nuevamente:\n\ndata['Segment'] = data['Segment'].map({2: 'Muy baja', \n                                       0: 'Baja',\n                                       1: 'Buena',\n                                       3: \"Excelente\"})\n\n# Convertir la columna segmento al tipo de datos de categoria\ndata['Segment'] = data['Segment'].astype('category')\n\n# Visualiza los segmentos usando Plotly\nfig = px.scatter(data, x=data.index, y='Credit Score', color='Segment',\n                 color_discrete_sequence=['green', 'blue', 'yellow', 'red'])\nfig.update_layout(\n    xaxis_title='Customer Index',\n    yaxis_title='Credit Score',\n    title='Customer Segmentation based on Credit Scores'\n)\nfig.show()\n\n\n                                                \n\n\nAsí es como puede realizar la segmentación y la calificación crediticia utilizando Python."
  },
  {
    "objectID": "posts/prima_seguros/index.html",
    "href": "posts/prima_seguros/index.html",
    "title": "Predicción de primas de seguros médicos con Machine Learning",
    "section": "",
    "text": "Una persona que ha contratado una póliza de seguro médico obtiene cobertura de seguro médico pagando una prima determinada. Existen muchos factores que determinan la prima del seguro médico. Entonces, si deseas saber como podemos utilizar Machine Learning para predecir la prima del seguro médico, este artículo es para ti. En este artículo, lo guiaré a traves de la tarea de predicción de primas de seguros médicos con Machine Learning usando Python."
  },
  {
    "objectID": "posts/prima_seguros/index.html#predicción-de-primas-de-seguro-médico",
    "href": "posts/prima_seguros/index.html#predicción-de-primas-de-seguro-médico",
    "title": "Predicción de primas de seguros médicos con Machine Learning",
    "section": "Predicción de primas de seguro médico",
    "text": "Predicción de primas de seguro médico\nEl monto de la prima de una póliza de seguro médico depende de persona a persona, ya que muchos factores afectan el monto de la prima de una póliza de seguro médico. Por ejemplo, la edad, una personas joven tiene menos probabilidad de tener problemas de salud importantes en comparación con una persona mayor. Por tanto, tratar a una persona mayor será caro en comparación con una joven. Por este motivo, una persona mayor debe pagar una prima más elevada que una persona joven.\nAdemás de la edad, muchos otros factores afectan la prima de una póliza de seguro médico. A este punto, espero haya comprendido qué es el seguro médico y cómo se determina la prima de una poliza de seguro médico. En la siguiente sección, lo guiaré a través de la tarea de predicción de primas de seguros médicos con aprendizaje automático utilizando Python."
  },
  {
    "objectID": "posts/prima_seguros/index.html#predicción-de-primas-de-seguros-médicos-usando-python",
    "href": "posts/prima_seguros/index.html#predicción-de-primas-de-seguros-médicos-usando-python",
    "title": "Predicción de primas de seguros médicos con Machine Learning",
    "section": "Predicción de primas de seguros médicos usando Python",
    "text": "Predicción de primas de seguros médicos usando Python\nEl conjunto de datos que estoy utilizando para la tarea de predicción de primas de seguros médicos se recopila de Kaggle. Contiene datos sobre:\n\nage: la edad de la persona.\nsex: género de la persona.\nbmi: índice de masa corporal de la persona.\nchildren: cuantos hijos va a tener la persona.\nsmoker: si la persona fuma o no.\nregion: la región donde vive la persona.\ncharges: cargos de la prima de segura.\n\nEntonces, importemos el conjunto de datos y las bibliotecas de Python necesarias para esta tarea:\n\nimport numpy as np\nimport pandas as pd\ndata = pd.read_csv(\"health_insurance_charges.csv\")\ndata.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nsmoker\nregion\nchildren\ncharges\n\n\n\n\n0\n21\nmale\n25.745000\nno\nnortheast\n2\n3279.868550\n\n\n1\n37\nfemale\n25.744165\nyes\nsoutheast\n3\n21454.494239\n\n\n2\n18\nmale\n30.030000\nno\nsoutheast\n1\n1720.353700\n\n\n3\n37\nmale\n30.676891\nno\nnortheast\n3\n6801.437542\n\n\n4\n58\nmale\n32.010000\nno\nsoutheast\n1\n11946.625900\n\n\n\n\n\n\n\nAntes de continuar, echemos un vistazo a si este conjunto de datos contiene valores nulos o no:\n\ndata.isnull().sum()\n\nage         0\nsex         0\nbmi         0\nsmoker      0\nregion      0\nchildren    0\ncharges     0\ndtype: int64\n\n\nPor lo tanto, el conjunto de datos está listo para ser utilizado. Después de tener las primeras impresiones de estos datos, me fijé en la columna smoker, que indica si la persona fuma o no. Esta es una característica importante de este conjunto de datos porque una persona que fuma tiene más probabilidades de tener problemas de salud importantes en comparación con una persona que no fuma. Así que veamos la distribución de personas que fuman y que no:\n\nimport plotly.express as px\ndata = data\nfigure = px.histogram(data, x = \"sex\", color = \"smoker\", title= \"Number of Smokers\")\nfigure.show()\n\n\n                                                \n\n\nSegún la visualización anterior, 1,144 hombres y 980 mujeres no fuman y 243 hombres y 133 mujeres fuman. Es importante utilizar esta función al entrenar un modelo de Machine Learning, por lo que ahora reemplazaré los valores de las columnas sex y smoker con 0 y 1, ya que ambas columnas contienen valores de cadena:\n\ndata[\"sex\"] = data[\"sex\"].map({\"female\": 0, \"male\": 1})\ndata[\"smoker\"] = data[\"smoker\"].map({\"no\": 0, \"yes\": 1})\nprint(data.head())\n\n   age  sex        bmi  smoker     region  children       charges\n0   21    1  25.745000       0  northeast         2   3279.868550\n1   37    0  25.744165       1  southeast         3  21454.494239\n2   18    1  30.030000       0  southeast         1   1720.353700\n3   37    1  30.676891       0  northeast         3   6801.437542\n4   58    1  32.010000       0  southeast         1  11946.625900\n\n\nAhora echemos un vistazo a la distribución de las regiones donde vive la gente según el conjunto de datos:\n\nimport plotly.express as px\npie = data[\"region\"].value_counts()\nregions = pie.index\npopulation = pie.values\nfig = px.pie(data, values=population, names=regions)\nfig.show()\n\n\n                                                \n\n\nAhora echemos un vistazo a la correlación entre las características de este conjunto de datos:\n\nprint(data.corr())\n\n               age       sex       bmi    smoker  children   charges\nage       1.000000 -0.151066  0.146278  0.032529 -0.055408  0.312068\nsex      -0.151066  1.000000 -0.005126  0.077443  0.146442  0.089900\nbmi       0.146278 -0.005126  1.000000  0.028656 -0.034233  0.197721\nsmoker    0.032529  0.077443  0.028656  1.000000 -0.174135  0.769390\nchildren -0.055408  0.146442 -0.034233 -0.174135  1.000000 -0.064515\ncharges   0.312068  0.089900  0.197721  0.769390 -0.064515  1.000000\n\n\nC:\\Users\\juani\\AppData\\Local\\Temp\\ipykernel_18556\\3359323643.py:1: FutureWarning:\n\nThe default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning."
  },
  {
    "objectID": "posts/prima_seguros/index.html#modelo-de-predicción-de-primas-de-seguro-médico",
    "href": "posts/prima_seguros/index.html#modelo-de-predicción-de-primas-de-seguro-médico",
    "title": "Predicción de primas de seguros médicos con Machine Learning",
    "section": "Modelo de predicción de primas de seguro médico",
    "text": "Modelo de predicción de primas de seguro médico\nPasemos ahora a entrenar un modelo de aprendizaje automático para la tarea de predecir las primas de seguros médicos. Primero, dividiré los datos en conjuntos de entrenamiento y prueba:\n\nx = np.array(data[[\"age\", \"sex\", \"bmi\", \"smoker\"]])\ny = np.array(data[\"charges\"])\n\nfrom sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)\n\nDespués de usar diferentes algoritmos de Machine Learning, encontré que el algoritmo de Random Forest es el de mejor rendimiento para esta tarea. Entonces aquí entrenaré el modelo usando el algoritmo de Random Forest Regression:\n\nfrom sklearn.ensemble import RandomForestRegressor\nforest = RandomForestRegressor()\nforest.fit(xtrain, ytrain)\n\nRandomForestRegressor()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestRegressorRandomForestRegressor()\n\n\nAhora echemos un vistazo a los valores predichos del modelo:\n\nypred = forest.predict(xtest)\ndata = pd.DataFrame(data={\"Monto de prima predicho\": ypred})\nprint(data.head())\n\n   Monto de prima predicho\n0              9406.796792\n1              4375.500954\n2             41854.323503\n3             15823.019738\n4              6563.550778\n\n\nAsí es como se puede entrenar un modelo de Machine Learning para la tarea de predicción de primas de seguros médicos utilizando Python."
  },
  {
    "objectID": "posts/prima_seguros/index.html#resumen",
    "href": "posts/prima_seguros/index.html#resumen",
    "title": "Predicción de primas de seguros médicos con Machine Learning",
    "section": "Resumen",
    "text": "Resumen\nEl monto de la prima de una póliza de seguro médico depende de persona a persona, ya que muchos factores afectan el monto de la prima de una póliza de seguro médico. Espero que te haya gustado este artículo sobre predicción de primas de seguros médicos con Machine Learning utilizando Python. No dude en hacer sus valiosas preguntas en la sección de comentarios a continuación."
  },
  {
    "objectID": "posts/random_variables/index.html",
    "href": "posts/random_variables/index.html",
    "title": "Tipos de Arquitecturas de Redes Neuronales",
    "section": "",
    "text": "Las arquitecturas de redes neuronales se refieren a los diseños estructurales y organizativos de redes neuronales artificiales (RNA). Estas arquitecturas determinan cómo se organiza la red, incluida la cantidad de capas, la cantidad de neuronas en cada capa, las conexiones entre neuoronas y las funciones de activación utilizadas. Se forman diferentes arquitecturas de redes neuronales alterando estos componentes estructurales para adaptarse a tareas o desafíos específicos. Si desea conocer los tipos de arquitectura de redes neuronales que debe conocer, este artículo es para usted. En este artículo, le explicaré los tipos de arquitecturas de redes neuronales en Machine Learning y cuándo elegirlas."
  },
  {
    "objectID": "posts/random_variables/index.html#tipo-de-arquitectura-de-redes-neuronales",
    "href": "posts/random_variables/index.html#tipo-de-arquitectura-de-redes-neuronales",
    "title": "Tipos de Arquitecturas de Redes Neuronales",
    "section": "Tipo de arquitectura de redes neuronales",
    "text": "Tipo de arquitectura de redes neuronales\nLas arquitecturas de redes neuronales se forman definiendo los componentges estructurales de la red, incluido el número de capas, el número de neuronas o células en cada capa y las conexiones entre ellas. La elección de la arquitectura depende de la naturaleza de los datos y de la tarea específica en cuestión, y se diseñan diferentes arquitecturas para abordar diferentes tipos de problemas y desafíos.\nA continuación te muestro las arquitecturas de redes neuronales en Machine Learning que debe conocer:\n\nFeedforward Neural Networks (redes neuronales de avance)\nConvolutional Neural Networks (redes neuronales convolucionales)\nRecurrent Neural Networks (redes neuronales reccurrentes)\nLong Short-Term Memory Networks (redes de memoria a largo plazo)\nTransformer Networks (redes de transformadores)\nGenerative Adversarial Networks (redes generativas de confrontación)\n\nAhora exploremos estas arquitecturas de redes neuronales en detalle una por una."
  },
  {
    "objectID": "posts/random_variables/index.html#feedforward-neural-networks",
    "href": "posts/random_variables/index.html#feedforward-neural-networks",
    "title": "Tipos de Arquitecturas de Redes Neuronales",
    "section": "Feedforward Neural Networks",
    "text": "Feedforward Neural Networks\nEstas constan de capas de neuronas interconectadas donde la información fluye en una dirección, de entrada a salida. Cada neurona recibe información, la procesa mediante funciones de activación y la pasa a la siguiente capa."
  },
  {
    "objectID": "posts/random_variables/index.html#feedforward-neural-networks-fnn",
    "href": "posts/random_variables/index.html#feedforward-neural-networks-fnn",
    "title": "Tipos de Arquitecturas de Redes Neuronales",
    "section": "Feedforward Neural Networks (FNN)",
    "text": "Feedforward Neural Networks (FNN)\nLas FNN constan de capas de neuronas interconectadas donde la información fluye en una dirección, de entrada a salida. Cada neurona recibe información, la procesa mediante funciones de activación y la pasa a la siguiente capa.\n\nComponentes de FNN:\n\nCapa de entrada: la capa de entrada es la primera capa de la red. Consta de neuronas que representan las características o variables de su conjunto de datos. Cada neurona en la capa de entrada corresponde a una característica específica de sus datos.\nCapas ocultas: entre las capas de entrada y salida, puede tener una o más capas ocultas. Estas capas contienen neuronas que procesan información de la capa anterior y la pasan a la siguiente. El término oculto proviene del hecho de que estas capas no están conectadas directamente a la entrada o salida; su proposito es capturar patrones complejos en los datos.\nCapa de salida: la capa de salida es la capa final de la red, responsable de producir las predicciones o clasificaciones de la red. La cantidad de neuronas en la capa de salida depende del tipo de problema. Para la clasificación binaria, es posible que tenga una neurona, mientras que las tareas de clasificación de clases múltiples tendrían múltiples neuronas (una para cada clase).\n\nUtilice FNN para tareas donde las relaciones entre entradas y salidas son complejas pero se pueden aprender mediante el entrenamiento, como clasificación de imágenes, análisis de sentimientos o predicción.\n\n\nConvolutional Neural Networks (CNN)\n\nLas CNN están diseñadas para datos en forma de cuadrícula, como imágenes. Utilizan capas convolucionales para escanear datos de entrada y aplicar filtros para detectar patrones. Las capas de agrupación reducen las dimensiones espaciales. Las capas convolucionales capturan jerarquías de características.\n\nComponentes de las CNN\n\nCapas convolucionales: Estas capas son el núcleo de las CNN y constan de múltiples filtros o núcleos que se pueden aprender. Cada filtro es una pequeña matriz que se desliza sobre la imagen de entrada y la escanea en busca de patronones relevantes. La operación de convolución implica la multiplicación por elementos del filtro y la región de imagen correspondiente, seguida de la suma. Este proceso genera mapas de características que representan la presencia de patrones o características específicas en diferentes partes de la imagen.\nCapas de activación: Después de la operación de convolución, se aplica una función de activación (normalmente ReLU) para introducir no linealidad en el modelo , lo que permite capturar patrones complejos de forma eficaz.\nCapas de agrupación: Las capas de agrupación reducen la muestra de los mapas de características, reduciendo sus dimensiones espaciales y el número de parámetros. Comunmente se usa la agrupación máxima, que retiene el valor máximo dentro de una ventana pequeña, preservando efectivamente las características más importantes.\nCapas totalmente conectadas: Estas capas son similares a las de las redes neuronales tradicionales y sirven para realizar tareas de clasificación o regresión basadas en las características de las capas anteriores.\n\nPodrían utilizar CNN cuando trabajen con datos estructurados en cuadrícula, especialmente para tareas de imágenes y videos como reconocimiento de imagenes, detección de objetos y reconocimiento facial.\n\n\n\nRecurrent Neural Networks\n\nLas RNN procesan secuencias de datos como el lenguaje natural utilizando conexiones recurrentes. Estas conexiones permiten que la información persista, lo que las hace adecuadas para tareas con dependencias secuenciales.\n\nComponentes de RNN:\n\nSecuencias de entrada: En cada paso de tiempo \\(t\\), la RNN recibe un vector de entrada que representa los datos en ese paso de tiempo. Por ejemplo, en el procesamiento del lenguaje natural, cada paso de tiempo puede corresponder a una palabra o un carácter de una oración.\nEstado oculto: La RNN mantiene un vector de estado oculto en cada paso de tiempo, que sirve como memoria. El estado oculto captura la información de la entrada actual y del estado oculto anterior, lo que permite a la red recordar información pasada.\nConexión recurrente: La característica clave de las RNN es la conexión recurrente, que conecta el estado oculto del paso único con el siguiente paso de tiempo. Esta conexión en bucle permite a la red compartir información en diferentes intervalos de tiempo, lo que la hace capaz de comprender la naturaleza secuencial de los datos.\nSalida: La RNN puede producir una salida en cada paso de tiempo en función del estado oculto correspondiente. Por ejemplo, en tareas de modelado de lenguaje, la RNN puede predecir la siguiente palabra de una oración basandose en las palabras anteriores y sus estados ocultos.\n\nElija RNN cuando trabaje con datos secuenciales, incluido el procesamiento del lenguaje natural y el reconocimiento de voz.\n\n\n\nLong Short-Term Memory Networks\n\nLas LSTM son un tipo de RNN con células de memoria especializadas. Pueden capturar dependencias a largo plazo en datos secuenciales y mitigar el problema del gradiente de desaparición, lo que los hace adecuados para secuencias largas.\n\nComponentes de LSTM:\n\nPuerte de entrada: La puerta de entrada determina qué partes de la entrada deben almacenar en la celda de memoria. Tiene en cuenta la entrada actual y el estado oculto anterior y genera un valor entre 0 y 1 para cada elemento de entrada, lo que indica la relevancia de la entrada para la celda de memoria actual.\nPuerta de olvido: La puerta de olvido determina qué información de la celda de memoria debe descartarse. Tiene en cuenta la entrada actual y el estado oculto anterior y genera un valor entre 0 y 1 para cada elemento en la celda de memoria, lo que indica la importancia de retener la información.\nPuerta de salida: La puerta de salida determina qué información de la celda de memoria debe pasar al siguiente paso de tiempo. Tiene en cuenta la entrada actual y el estado oculto anterior y genera un valor entre 0 y 1 para cada elemento en la celda de memoria, lo que indica la contribución de la información a la salida final.\n\nSe prefieren las LSTM cuando se trabaja con tareas que requieren memoria de estados pasados, como traducción automática, reconocimiento de voz, análisis de sentimiento y predicción de series temporales.\n\n\n\nTransformer Networks\n\nLas redes transformer están diseñadas especificamente para procesar datos secuenciales, como lenguaje natural, audio y datos de series temporales. La estructura de Transformer Networks se basa en mecanismos de autoatención, donde cada posición en la secuencia de entrada puede atender a todas las demás posiciones.\n\nComponentes de las redes de transformadores:\n\nCodificador: El codificador toma la secuencia de entrada y la procesa a través de múltiples capas de autoatención y redes neuronales de retroalimentación. El mecanismo de autoatención permite al modelo sopesar la importancia de cada posición en la secuencia de entrada en función de su relación con todas las demas posiciones. La salida del codificador es un conjunto de representaciones contextuales para cada posición en la secuencia de entrada.\nDecodificador: El decodificador también consta de múltiples capas de redes neuronales de autoatención y retroalimentación. Toma la salida del codificador y genera la secuencia de salida de un paso. Durante la decodificación, cada posición solo puede atender a las posiciones anteriores en la secuencia de salida para garantizar la generación autorregresiva.\nMecanismo de autoatención: El mecanismo de autoatención en Transformer Networks permite que cada posición en la secuencia atienda a todas las demás posiciones, capturando dependencias y contexto de manera más efectiva en comparación con el recurrente tradicional.\nRedes neuronales de retroalimentación: Las redes neuronales de retroalimentación dentro de cada capa del codificador y decodificador proporcionan transformaciones no lineales adicionales a las representaciones de secuencia.\n\nLos transformadores han revolucionado las tareas de procesamiento del lenguaje natural, como la traducción automática, la generación de texto y el análisis de sentimientos. También se utilizan en el procesamiento de imagenes ( por ejemplo, subtitulos de imágenes) y en el aprendizaje por refuerzo.\n\n\n\nGenerative Adversarial Networks (GAN)\n\nLas GAN constan de dos redes: un generador y un descriminador. El generador intenta crear datos que no se pueden distinguir de los datos reales, mientras que el discriminador pretende distinguir lo real de lo falso. Compiten y se mejoran entre sí de forma iterativa.\n\nComponentes de las GAN:\n\nRed del generador: El generador es responsable de crear muestras de datos falsos que se asemejan a datos reales. Toma ruido aleatorio como entrada y lo transforma en muestras de datos que deberían parecer pertenecer al conjunto de datos originales. El generador consta de varias capas que transforman gradualmente el ruido en patrones más complejos, generando muestras de datos que se vuelven cada vez más realistas a medida que avanza el entrenamiento.\nRed Discriminadora: El discriminador es el adversario del generador. Actúa como un clasificador binario y está entrenado para distinguir entre muestras de datos reales del conjunto de datos originales y muestras de datos falsos generados por el generador. El discriminador también consta de varias capas que procesan los datos de entrada y toman una decisión sobre su autenticidad.\n\nLas GAN son ideales para generar datos realistas, aumento de datos, transferencias de estilo y aplicaciones artísticas."
  },
  {
    "objectID": "posts/random_variables/index.html#resumen",
    "href": "posts/random_variables/index.html#resumen",
    "title": "Tipos de Arquitecturas de Redes Neuronales",
    "section": "Resumen",
    "text": "Resumen"
  },
  {
    "objectID": "posts/random_variables/index.html#section",
    "href": "posts/random_variables/index.html#section",
    "title": "Tipos de Arquitecturas de Redes Neuronales",
    "section": "",
    "text": "Espero que te haya gustado este artículo sobre los tipos de arquitecturas de redes neuronales y cómo elegirlas. No dude en hacer preguntas valiosas en la sección de comentarios del Website."
  },
  {
    "objectID": "posts/random_variables/index.html#tipos-de-redes-neuronales",
    "href": "posts/random_variables/index.html#tipos-de-redes-neuronales",
    "title": "Tipos de Arquitecturas de Redes Neuronales",
    "section": "Tipos de Redes Neuronales",
    "text": "Tipos de Redes Neuronales\nComenzaremos explorando algunas de las arquitecturas de redes neuronales más eficientes para el pronóstico de series de tiempo. Nos centraremos en la implementación de redes neuronales recurrentes (RNN), unidad recurrentes cerradas (GRU), redes de memoria a largo plazo (LSTM). Comprender los principios básicos de las RNN será una buena base para su aplicación directa y dominar otras arquitecturas similares. Trataremos de cubrir la lógica y el núcleo de cada arquitectura, su aplicación práctica y pros y contras.\nDiscutiremos los siguientes temas:\n\nRecurrent neural network (RNN)\nGated recurrent unit network (GRU)\nLong short-term memory network (LSTM)\n\n\nRecurrent Neural Network (RNN)\nRNN tiene un concepto de un estado oculto. Un estado oculto puede tratarse como memoria interna. El estado oculto no intenta recordar todos los valores pasados de la secuencia sino solo su efecto. Debido a la memoria interna, las RNN pueden recordar cosas importantes sobre su entrada, lo que les permite ser muy preciosos para predecir valores futuros.\nEstudiemos la teoría de RNN de una manera más formal. En RNN, la secuencia de entrada se representa a traves de un bucle. Cuando toma una decisión, considera la entrada actual y también lo que ha aprendido de las entradas que recibio anteriormente. Veamos el gráfico computacional de RNN para comprender esta lógica:\n\n\n\nGráfico Computacional de RNN\n\n\ndonde,\n\n\\(x_1, x_2, . . . , x_n\\) son la secuencia de entrada.\n\\(h_i\\) es el estado oculto. \\(h_i\\) es un vector de longitud \\(h\\).\nRNN Cell representa la capa de red neuronal que calcula la siguiente función: \\(h_t = \\tanh(W_{ih}x_t + b_{ih} + W_{hh}h_{(t-1)} + b_{hh})\\)\n\nPodemos ver a detalle la RNN Cell:\n\n\n\nGráfico computacional de RNN Cell\n\n\nLa RNN Cell combina información sobre el valor actual de la secuencia \\(x_i\\) y el estado previamente oculto \\(h_{i-1}\\). La célula RNN devuelve un estado oculto actualizado \\(h_i\\) después de aplicar la función de activación.\nLa RNN tiene los siguientes parámetros, que se ajustan durante el entrenamiento:\n\n\\(W_{ih}\\) pesos ocultos de entrada\n\\(b_{ih}\\) sesgos oculto de entrada\n\\(W_{hh}\\) pesos ocultos - ocultos\n\\(B_{hh}\\) sesgos oculto - oculto\n\nNota: Un error común ocurre cuando los subíndices en los parámetros RNN \\((W_{ih}, b_{ih}, W_{hh}, b_{hh})\\) se interpretan como una dimensión de índice o tensor. No, son solo la abreviatura de entrada-oculto \\((h_í)\\) y oculto-oculto \\((h)\\). El mismo principio aplica a los parámetros de otros modelos: GRU y LSTM.\nEn ocasiones, los cientificos de datos utilizan la siguiente representación de las RNN:\n\n\n\nVisualización alternativa de RNN\n\n\nEl gráfico que se muestra puede dar lugar a algunos malentendidos, y estoy tratando de evitar esto. Pero si este tipo de gráfico se adapta a tu intuición, entonces úsalo sin ninguna duda.\n\nAhora estamos listos para examinar una implementación de RNN utilizando PyTorch.\n\nimport torch.nn as nn\n\nclass RNN(nn.Module):\n\n    def __init__(self,\n                 hidden_size,\n                 in_size = 1,\n                 out_size = 1):\n        super(RNN, self).__init__()\n        self.rnn = nn.RNN(\n            input_size = in_size,\n            hidden_size = hidden_size,\n            batch_first = True)\n        self.fc = nn.Linear(hidden_size, out_size)\n\n    def forward(self, x, h = None):\n        out, _ = self.rnn(x, h)\n        last_hidden_states = out[:, -1]\n        out = self.fc(last_hidden_states)\n        return out, last_hidden_states\n\nNote que nuestro modelo devuelve dos salidas: predicción y estado oculto. Es crucial reutilizar los estados ocultos durante la evaluación RNN. Utilizaremos conjuntos de datos de consumo de energía por hora ( https://www.kaggle.com/robikscube/Hourly-energy-Consumed) para la implementación de RNN.\n\nimport pandas as pd\nimport torch\n\ndf = pd.read_csv('AEP_hourly.csv')\nts = df['AEP_MW'].astype(int).values.reshape(-1, 1)[-3000:]\n\nimport matplotlib.pyplot as plt\n\nplt.title('AEP Hourly')\nplt.plot(ts[:500])\nplt.show()\n\n\n\n\nPodemos ver en que esta es una serie de tiempo realmente complicada. Tiene varios factores de estacionalidad con picos apenas predecibles.\nA continuación, voy a mostrarte como se desempeña RNN en la serie de tiempo AEP Hourly:\n\nimport copy\nimport random\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom sklearn.preprocessing import MinMaxScaler\n\nrandom.seed(1)\ntorch.manual_seed(1)\n\n# Parametros globales\n\n\nfeatures = 240\n# Longitud del conjunto de datos de prueba\ntest_ts_len = 300\n# tamaño del estado oculto\nrnn_hidden_size = 24\n# tasa de aprendizaje de optimizador\nlearning_rate = 0.02\n\ntraining_epochs = 500\n\ndef sliding_window(ts, features):\n    X = []\n    Y = []\n\n    for i in range(features + 1, len(ts) + 1):\n        X.append(ts[i - (features + 1):i - 1])\n        Y.append([ts[i - 1]])\n\n    return X, Y\n\ndef get_training_datasets(ts, features, test_len):\n    X, Y = sliding_window(ts, features)\n\n    X_train, Y_train, X_test, Y_test = X[0:-test_len],\\\n                                       Y[0:-test_len],\\\n                                       X[-test_len:],\\\n                                       Y[-test_len:]\n\n    train_len = round(len(ts) * 0.7)\n\n    X_train, X_val, Y_train, Y_val = X_train[0:train_len],\\\n                                     X_train[train_len:],\\\n                                     Y_train[0:train_len],\\\n                                     Y_train[train_len:]\n\n    x_train = torch.tensor(data = X_train).float()\n    y_train = torch.tensor(data = Y_train).float()\n\n    x_val = torch.tensor(data = X_val).float()\n    y_val = torch.tensor(data = Y_val).float()\n\n    x_test = torch.tensor(data = X_test).float()\n    y_test = torch.tensor(data = Y_test).float()\n\n    return x_train, x_val, x_test,\\\n           y_train.squeeze(1), y_val.squeeze(1), y_test.squeeze(1)\n           \n\n# Preparando datos para entrenamiento\nscaler = MinMaxScaler()\nscaled_ts = scaler.fit_transform(ts)\nx_train, x_val, x_test, y_train, y_val, y_test =\\\n    get_training_datasets(scaled_ts, features, test_ts_len)\n    \n\n# Inicialización del modelo \nmodel = RNN(hidden_size = rnn_hidden_size)\nmodel.train()\n\nC:\\Users\\juani\\AppData\\Local\\Temp\\ipykernel_15172\\1156180628.py:50: UserWarning:\n\nCreating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n\n\n\nRNN(\n  (rnn): RNN(1, 24, batch_first=True)\n  (fc): Linear(in_features=24, out_features=1, bias=True)\n)\n\n\n\n# Entrenamiento\noptimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\nmse_loss = torch.nn.MSELoss()\n\nbest_model = None\nmin_val_loss = sys.maxsize\n\ntraining_loss = []\nvalidation_loss = []\n\nfor t in range(training_epochs):\n\n    prediction, _ = model(x_train)\n    loss = mse_loss(prediction, y_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    val_prediction, _ = model(x_val)\n    val_loss = mse_loss(val_prediction, y_val)\n\n    training_loss.append(loss.item())\n    validation_loss.append(val_loss.item())\n\n    if val_loss.item() &lt; min_val_loss:\n        best_model = copy.deepcopy(model)\n        min_val_loss = val_loss.item()\n\n    if t % 50 == 0:\n        print(f'epoch {t}: train - {round(loss.item(), 4)}, '\n              f'val: - {round(val_loss.item(), 4)}')\n\nepoch 0: train - 0.377, val: - 0.0866\nepoch 50: train - 0.0061, val: - 0.0133\nepoch 100: train - 0.0021, val: - 0.0044\nepoch 150: train - 0.0018, val: - 0.0034\nepoch 200: train - 0.0015, val: - 0.003\nepoch 250: train - 0.0014, val: - 0.0027\nepoch 300: train - 0.0013, val: - 0.0026\nepoch 350: train - 0.0012, val: - 0.0025\nepoch 400: train - 0.0012, val: - 0.0024\nepoch 450: train - 0.0012, val: - 0.0024\n\n\nY aquí llegamos al punto más difícil. Debe pasar el estado oculto al modelo RNN cuando lo evalua. La forma más sencilla de calentar el estado oculto es ejecutar el modelo en los datos de validación una vez y pasar un estado oculto cálido a través de cada iteración y por último evaluamos el modelo que construimos en el conjunto de datos de prueba.\n\nbest_model.eval()\n_, h_list = best_model(x_val)\n\nh = (h_list[-1, :]).unsqueeze(-2)\n\n\npredicted = []\nfor test_seq in x_test.tolist():\n    x = torch.Tensor(data = [test_seq])\n \n    y, h = best_model(x, h.unsqueeze(-2))\n    unscaled = scaler.inverse_transform(np.array(y.item()).reshape(-1, 1))[0][0]\n    predicted.append(unscaled)\n\nreal = scaler.inverse_transform(y_test.tolist())\nplt.title(\"conjutno de datos prueba\")\nplt.plot(real, label = 'real')\nplt.plot(predicted, label = 'predicción')\nplt.legend()\nplt.show()\n\n\n\n\nRNN muestra un gran rendimiento en el conjunto de datos de prueba. El modelo que hemos entrenado predice picos estacionales con mucha precisión.\nY finalmente, examinamos el proceso de entrenamiento en sí.\n\nplt.title('Entrenamiento')\nplt.yscale('log')\nplt.plot(training_loss, label = 'Entrenamiento')\nplt.plot(validation_loss, label = 'validación')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n\n\n\n\nEl proceso del entrenamiento es suave sin picos agudos e impredecibles.\nAhora, podemos establecer con confianza la promesa y la efectividad de la aplicación de RNN a los problemas de pronósticos de la serie temporal.\nA pesar de todas las ventajas de RNN, tiene desventajas significativas:\n\nDebido a la complejidad computacional, sufren problemas de gradiente de fuga. El proceso de entrenamiento se vuelve demasiado lento. El problema del gradient e de fuga es un problema común a todas las RNN.\nEl estado oculto se actualiza en cada iteración, lo que dificulta el almacenamiento de información a largo plazo en RNN. Las arquitecturas GRU y LSTM resuelven este problema. Tienen enfoques similares sobre cómo almacenar información a largo plazo.\n\n\n\nGated recurrent unit network (GRU)\nLa GRU es es una versión avanzada de la RNN clásica. El propósito principal de GRU es almacenar información a largo plazo. En breve exploraremos como GRU logra esto.\nLa forma más fácil de almacenar información a largo plazo en un estado oculto es restringir las actualizaciones ocultas sobre cada iteración. Este enfoque evitará sobrescribir información importante a largo plazo.\nPuede encontrar la siguiente definición de GRU en internet:\nSe comienza calculando la puerta de actualización \\(z_t\\) para el peso de tiempo \\(t\\) usando la fórmula:\n\\[\n\\begin{eqnarray*}\nz_{t} &=& \\sigma(W^{z}x_t + U^{z}h_{t-1}) \\hspace{1cm} \\mbox{Puerta de actualización}\\\\[0.2cm]\n\\end{eqnarray*}\n\\]\nlo que sucede aquí es que cuando \\(x_t\\) se conecta a la unidad de red, se multiplica por su propio peso \\(W^{z}\\). Lo mismo ocurre con \\(h_{t-1}\\), que contiene la información de las unidades \\(t-1\\) anteriores y se múltiplica por su propio peso \\(U^{z}\\). Ambos resultados se suman y se aplica una función de activación sigmoidea \\((\\sigma)\\) para acotar el resultado entre 0 y 1.\n\nLa puerta de actualización ayuda al modelo a determinar cuánta información pasada (de pasos de tiempo anteriores) debe transmitirse al futuro. Esto es muy poderoso porque el modelo puede decidir copiar toda la la información del pasado y eliminar el riesgo de que desaparezca el problema de fuga del gradiente.\nLuego continuamos con Restablecer puerta:\nBásicamente, esta puerta se utiliza desde el modelo para decidir cuánta información pasada se debe olvidar. Para calcularlo utilizamos:\n\\[\nr_t = \\sigma(W^{r}x_t + U^{r}h_{t-1})\\hspace{1cm} \\mbox{Restablecer puerta}\n\\]\nEsta fórmula es la misma que la de la puerta de actualización. La diferencia viene en los pesos y el uso de la puerta, que veremos en un momento.\n\nComo antes, conectamos \\(h_{t-1} - \\mbox{linea azul}\\) y \\(x_{t} - \\mbox{linea violeta}\\), los multiplicamos con sus pesos correspondientes, sumamos los resultados y aplicamos la función sigmoidea.\nContenido de la memoria actual:\nveamos como afectarán exactamente las puertaas al resultado final. Primero, comenzamos con el uso de la puerta de reinicio. Introducimos un nuevo contenido de memoria que utilizará la puerta de reinicio para almacenar la información del pasado. Se calcula de la siguiente manera:\n\\[\nh_{t}^{\\prime} = tanh(Wx_{t} + r_{t}\\odot U h_{t-1})\n\\]\n\nMultiplique la entrada \\(x_t\\) con un peso \\(W\\) y \\(h_{t-1}\\) con un peso \\(U\\).\nCalcule el producto de Hadamard (por elementos) entre la puerta de reinicio \\(r_t\\) y \\(Uh_{t-1}\\). Eso determinará qué eliminar de los pasos de tiempo anterior. Digamos que tenemos un problema de análisis de sentimientos para determinar la opinión de una persona sobre un libro a partir de una reseña que escribió. El texto comienza con “Este es un libro de fantasía que ilustra…” y después de un par de párrafos termina con “No disfruté mucho el libro porque creo que captura demasiados detalles”. Para determinar el nivel general de satisfacción con el libro sólo necesitamos la última parte de la reseña. En ese caso, a medida que la red neuronal se acerque al final del texto, aprenderá a asignar un vector \\(r_t\\) cercano a 0, eliminando el pasado y centrándose solo en las últimas oraciones.\nResuma los resultados de los pasos 1 y 2.\nAplicar la función de activación no lineal tanh.\n\nPuedes ver claramente los pasos aquí:\n\nHacemos una multiplicación por elementos de \\(h_{t-1} - \\mbox{línea azul}\\) y \\(r_t - \\mbox{línea naranja}\\) y luego sumamos el resultado - linea rosa con la entrada \\(x_t -\\) línea morada. Finalmente, tanh se usa para producir \\(h_{t}^{\\prime}:\\) línea verde brillante.\nMemoria final en el paso de tiempo actual\nComo último paso, la red necesita calcular \\(h_{t}\\), el vector que contiene información para la unidad actual y la transmite a la red. Para hacer eso, se necesita la puerta de actualización. Determina qué recopilar el contenido de la memoria actual \\((h_t^{\\prime})\\) y qué de los pasos anteriores \\((h_{(t-1)})\\). Eso se hace de la siguiente manera:\n\\[\nh_t = z_t\\odot h_{t-1} + (1 - z_t)\\odot h_{t}^{\\prime}\n\\]\n\nAplique la multiplicación por elementos a la puerta de actualización \\(z_t\\) y \\(h_{(t-1)}\\).\nAplique la multiplicación por elementos a \\((1- z_t)\\) y \\(h_{t}^{\\prime}\\).\nSume los resultados de los pasos 1 y 2.\n\nPongamos el ejemplo de la reseña del equilibrio. En esta ocasión, la información más relevante se situa al inicio del texto. El modelo puede aprender a establecer el vector \\(z_t\\) cerca de 1 y conservar la mayor parte de la información anterior. Dado que \\(z_t\\) estará cerca de 1 en este paso de tiempo, \\((1-z_t)\\) estará cerca de 0, lo que ignorará gran parte del contenido actual (en este caso, la última parte de la reseña que explica la trama del libro), lo cual es irrelevante para nuestra predicción.\nAquí hay una ilustración que enfatiza la ecuación anterior:\n\nA continuación, puede ver cómo \\(z_t\\) (línea verde) para calcular \\(1 - z_t\\) que combinado con \\(h_{t}^{\\prime}\\) (línea verde brillante), produce un resultado en la línea roja oscura. \\(z_t\\) también se usa con \\(h_{t-1} - \\mbox{línea azul}\\) en una multiplicación de elementos. Finalmente, \\(h_{t}:\\) la línea azul es el resultado de la suma de las salidas correspondientes a las líneas rojas brillantes y oscuras.\nAhora puede ver cómo las GRU pueden almacenar y filtrar la información utilizando sus puertas de actualización y reinicio. Eso elimina el problema del gradiente de fuga, ya que el modelo no elimina la nueva entrada cada vez, sino que mantiene la información relevante y la pasa a los siguientes pasos de la red. Si se les entrena cuidadosamente, pueden desempeñarse extremadamente bien incluso en escenarios complejos.\nEl modelo de predicción GRU es muy similar al RNN. Veamos su desempeño utilizando la misma data que el casa RNN.\n\nimport torch.nn as nn\n\nrandom.seed(1)\ntorch.manual_seed(1)\n\n\nfeatures = 240\ntest_ts_len = 300\ngru_hidden_size = 24\nlearning_rate = 0.02\ntraining_epochs = 500\n\nclass GRU(nn.Module):\n\n    def __init__(self,\n                 hidden_size,\n                 in_size = 1,\n                 out_size = 1):\n        super(GRU, self).__init__()\n        self.gru = nn.GRU(\n            input_size = in_size,\n            hidden_size = hidden_size,\n            batch_first = True)\n        self.fc = nn.Linear(hidden_size, out_size)\n\n    def forward(self, x, h = None):\n        out, _ = self.gru(x, h)\n        last_hidden_states = out[:, -1]\n        out = self.fc(last_hidden_states)\n        return out, last_hidden_states\n\n# Inicializando el modelo GRU\nmodel = GRU(hidden_size = gru_hidden_size)\nmodel.train()\n\n# Entrenamiento\noptimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\nmse_loss = torch.nn.MSELoss()\n\nbest_model = None\nmin_val_loss = sys.maxsize\n\ntraining_loss = []\nvalidation_loss = []\n\n\nfor t in range(training_epochs):\n\n    prediction, _ = model(x_train)\n    loss = mse_loss(prediction, y_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    val_prediction, _ = model(x_val)\n    val_loss = mse_loss(val_prediction, y_val)\n\n    training_loss.append(loss.item())\n    validation_loss.append(val_loss.item())\n\n    if val_loss.item() &lt; min_val_loss:\n        best_model = copy.deepcopy(model)\n        min_val_loss = val_loss.item()\n\n    if t % 50 == 0:\n        print(f'epoch {t}: train - {round(loss.item(), 4)}, '\n              f'val: - {round(val_loss.item(), 4)}')\n\nbest_model.eval()\n_, h_list = best_model(x_val)\nh = (h_list[-1, :]).unsqueeze(-2)\n\npredicted = []\nfor test_seq in x_test.tolist():\n    x = torch.Tensor(data = [test_seq])\n    y, h = best_model(x, h.unsqueeze(-2))\n    unscaled = scaler.inverse_transform(np.array(y.item()).reshape(-1, 1))[0][0]\n    predicted.append(unscaled)\n\nepoch 0: train - 0.0626, val: - 0.0326\nepoch 50: train - 0.0017, val: - 0.0026\nepoch 100: train - 0.0012, val: - 0.0024\nepoch 150: train - 0.0012, val: - 0.0023\nepoch 200: train - 0.0011, val: - 0.0022\nepoch 250: train - 0.0011, val: - 0.0022\nepoch 300: train - 0.0011, val: - 0.0023\nepoch 350: train - 0.0011, val: - 0.0023\nepoch 400: train - 0.0011, val: - 0.0022\nepoch 450: train - 0.0011, val: - 0.0022\n\n\n\nreal = scaler.inverse_transform(y_test.tolist())\nplt.title(\"conjutno de datos prueba\")\nplt.plot(real, label = 'real')\nplt.plot(predicted, label = 'predicción')\nplt.legend()\nplt.show()\n\n\n\n\nVemos que el modelo GRU imita el comportamiento original de la serie temporal con bastante precisión.\n\nplt.title('Entrenamiento')\nplt.yscale('log')\nplt.plot(training_loss, label = 'Entrenamiengto')\nplt.plot(validation_loss, label = 'validación')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n\n\n\n\nLas pérdidas de entrenamiento y validación tienen descenso asintótico con un brecha natural constante entre ellas. Podemos concluir que el modelo realmente aprende el comportamiento de la serie temporal.\n\n\nLong short-term memory network (LSTM)\nLa red LSTM se ha desarrollado para superar el problema de fuga de gradiente en RNN al mejorar el flujo de gradiente de la red. Debe mencionarse que la arquitectura apareció mucho antes que la GRU. La arquitectura LSTM se desarrolló en 1997, y el GRU se propueso en 2014. El diseño GRU es más simple y más comprensible que LSTM. Es por eso que comenzamos nuestro estudio examinando primero GRU.\nComo su nombre lo índica, LSTM aborda los mismos problemas de memoria a corto y largo plazo que GRU. A nivel global, el flujo computacional del LSTM se ve de la siguiente manera:\n\nLSTM funciona sobre los principios similares que GRU pero tiene más variables. RNN y GRU solo pasan un estado oculto \\(h_t\\) a través de cada iteración. Pero LSTM pasa dos vectores:\n\n\\(h_t\\) estado oculto (memoria a corto plazo)\n\\(c_t\\) estado de celda (memoria a largo plazo)\n\nLas salidas de LSTM Cell se calculan a través de las fórmulas:\n\\[\n\\begin{eqnarray*}\ni_t &=& \\sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1} + b_{hi})\\\\[0.2cm]\nf_t &=& \\sigma(W_{ii}x_{t} + b_{if} + W_{hf}h_{t-1} + b_{hf})\\\\[0.2cm]\ng_t &=& tanh(W_{ig}x_t + b_{ig} + W_{hg}h_{t-1} + b_{hn})\\\\[0.2cm]\no_t &=& \\sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho})\\\\[0.2cm]\nc_t &=& f_t \\circ c_{t-1} + i_t\\circ g_t\\\\[0.2cm]\nh_t &=& o_t \\circ tanh(c_t)\n\\end{eqnarray*}\n\\]\ndonde:\n\n\\(\\sigma\\) es la función sigmoidea\n\\(\\circ\\) es el producto de Hadamard\n\nEn cuanto a las variables:\n\n\\(i_t~(puerta de entrada)\\) es la variable que se utiliza para actualizar el estado \\(c_t\\). El estado previamente oculto \\(h_t\\) y la secuencia \\(x_t\\) se dan como entradas a una función sigmoidea \\((\\sigma)\\). Si la salida está cerca de 1, entonces la información es más importante.\n\\(f_t ~ (puerta~de~olvido)\\) es la variable que decide que información debe olvidarse en el estado \\(c_t\\). El estado \\(h_t\\) de estado previamente oculto y la secuencia \\(x_t\\) se dan como entradas a una función sigmoidea. Si la salida \\(f_t\\) está cerca de cero, la información se puede olvidar, mientras que si la salida está cerca de 1, la información debe almacenarse o recordarse.\n\\(g_t\\) representa información importante potencialmente nueva para el estado \\(c_t\\).\n\\(c_t ~ (estado~celda)\\) es una suma de:\n\nestado de celda anterior \\(c_{t-1}\\) con información olvidada \\(f_t\\).\nnueva información de \\(g_t\\) seleccionada por \\(i_t\\)\n\n\\(o_t ~ (puerta~de~salida)\\) es la variable para actualizar el estado oculto \\(h_t\\).\n\\(h_t ~(estado~oculto)\\) es el siguiente estado oculto que se calcula eligiendo la información importante del estado de celda o celular \\(c_t\\).\n\nA continuación te muestro el gráfico computacional de la celda LSTM:\n\nLSTM tiene los siguientes parámetros, que se ajustan durante el entrenamiento:\n\n\\(W_{ii}, W_{hi}, W_{if}, W_{hf}, W_{ig}, W_{hg}, W_{io}, W_{ho}\\) estos son los pesos.\n\\(b_{ii}, b_{hi}, b_{if}, b_{hf}, b_{ig}, b_{hg}, b_{io}, b_{ho}\\) estos son sesgos.\n\nAhora examinemos la implementación de Pytorch del modelo de predicción LSTM:\n\nimport torch.nn as nn\n\nclass LSTM(nn.Module):\n\n    def __init__(self,\n                 hidden_size,\n                 in_size = 1,\n                 out_size = 1):\n        super(LSTM, self).__init__()\n        self.lstm = nn.LSTM(\n            input_size = in_size,\n            hidden_size = hidden_size,\n            batch_first = True)\n        self.fc = nn.Linear(hidden_size, out_size)\n\n    def forward(self, x, h = None):\n        out, h = self.lstm(x, h)\n        last_hidden_states = out[:, -1]\n        out = self.fc(last_hidden_states)\n        return out, h\n\nComo vemos, la implementación del modelo LSTM es bastante similar a las implementaciones de RNN y GRU.\nProbaremos el modelo LSTM con el siguiente conjunto de datos de la serie tiempo de consumo de energía por hora).\n\nimport pandas as pd\nimport torch\n\ndf = pd.read_csv('NI_hourly.csv')\nts = df['NI_MW'].astype(int).values.reshape(-1, 1)[-3000:]\n\nimport matplotlib.pyplot as plt\n\nplt.title('NI Hourly')\nplt.plot(ts[:500])\nplt.show()\n\n\n\n\nVeamos el modelo en acción:\n\nimport copy\nimport random\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom sklearn.preprocessing import MinMaxScaler\n\nrandom.seed(1)\ntorch.manual_seed(1)\n\n\nfeatures = 240\ntest_ts_len = 300\nlstm_hidden_size = 24\nlearning_rate = 0.02\ntraining_epochs = 100\n\n# Preparar el conjunto de datos para el entrenamiento \nscaler = MinMaxScaler()\nscaled_ts = scaler.fit_transform(ts)\nx_train, x_val, x_test, y_train, y_val, y_test =\\\n    get_training_datasets(scaled_ts, features, test_ts_len)\n\n# Inicializando el modelo \nmodel = LSTM(hidden_size = lstm_hidden_size)\nmodel.train()\n\n# Entrenamiento \noptimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\nmse_loss = torch.nn.MSELoss()\n\nbest_model = None\nmin_val_loss = sys.maxsize\n\ntraining_loss = []\nvalidation_loss = []\n\n\nfor t in range(training_epochs):\n\n    prediction, _ = model(x_train)\n    loss = mse_loss(prediction, y_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    val_prediction, _ = model(x_val)\n    val_loss = mse_loss(val_prediction, y_val)\n\n    training_loss.append(loss.item())\n    validation_loss.append(val_loss.item())\n\n    if val_loss.item() &lt; min_val_loss:\n        best_model = copy.deepcopy(model)\n        min_val_loss = val_loss.item()\n\n    if t % 10 == 0:\n        print(f'epoch {t}: train - {round(loss.item(), 4)}, '\n              f'val: - {round(val_loss.item(), 4)}')\n\nepoch 0: train - 0.0979, val: - 0.087\nepoch 10: train - 0.0253, val: - 0.0255\nepoch 20: train - 0.0131, val: - 0.0119\nepoch 30: train - 0.0056, val: - 0.0059\nepoch 40: train - 0.0032, val: - 0.0043\nepoch 50: train - 0.0026, val: - 0.0029\nepoch 60: train - 0.002, val: - 0.0025\nepoch 70: train - 0.0018, val: - 0.0023\nepoch 80: train - 0.0016, val: - 0.0021\nepoch 90: train - 0.0014, val: - 0.0019\n\n\nPara una evaluación del modelo LSTM, necesitamos pasar un estado celular y estado oculto.\n\nbest_model.eval()\nwith torch.no_grad():\n    _, h_list = best_model(x_val)\n\n    h = tuple([(h[-1, -1, :]).unsqueeze(-2).unsqueeze(-2)\n               for h in h_list])\n\n    predicted = []\n    for test_seq in x_test.tolist():\n        x = torch.Tensor(data = [test_seq])\n\n        y, h = best_model(x, h)\n        unscaled = scaler.inverse_transform(\n            np.array(y.item()).reshape(-1, 1))[0][0]\n        predicted.append(unscaled)\n        \nreal = scaler.inverse_transform(y_test.tolist())\nplt.title(\"Conjunto de prueba\")\nplt.plot(real, label = 'real')\nplt.plot(predicted, label = 'predicción')\nplt.legend()\nplt.show()\n\n\n\n\nLSTM captura muy bien el comportamiento de las series temporales para hacer predicciones precisas.\n\nplt.title('Entrenamiento')\nplt.yscale('log')\nplt.plot(training_loss, label = 'Entrenamiento')\nplt.plot(validation_loss, label = 'validación')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n\n\n\n\nMirando, concluimos que detuvimos el proceso de entrenamiento demasiado temprano. Obtenemos modelos más precisos si establecemos más epocas (epoch) para el entrenamiento.\n\n\nCONCLUSIONES\nPudimos ver que las redes neuronales recurrentes muestran excelentes resultados y son adecuadas para problemas de pronósticos de series de tiempo.\nLas Redes Neuronales Recurrentes son la técnica muy popular de aprendizaje profundo (Deep Learning) para el pronóstico de series de tiempo, ya que permiten producir predicciones confiables en series de tiempo en diversos problemas. El principal problema con RNN es que sufre el problema de fuga de gradiente cuando se aplica a secuencia largas, y no tiene una herramienta de memoria a largo plazo. Se desarrollaron LSTM y GRU para evitar el problema de gradiente de RNN con el uso de puertas que regulan el flujo de información e implementan el almacenamiento de memoria a largo plazo. El uso de LSTM y GRU ofrece resultados notables, pero LSTM y GRU no siempre funcionan mejor que RNN.\n\nRNN tiene un estado oculto que puede tratarse como una memoria interna de la secuencia de entrada.\nRNN vuelve a calcular el estado oculto después de procesar cada nuevo valor de entrada de forma recurrente.\nRNN sufre un problema de fuga de gradiente.\nRNN actualiza un estado oculto en cada iteración. Por tanto, no tiene memoria a largo plazo.\nGRU implementa la puerta de reinicio, que rechaza algunas actualizaciones en un estado oculto.\nLSTM pasa dos vectores a través de cada iteración: estado oculto y estado de celda.\n\n\n\nREFERENCIAS\n\nTime Series Forecasting Using Deep Learning - Ivan Gridin\nUnderstanding GRU Networks"
  },
  {
    "objectID": "posts/random_variables/index.html#fundamentos-previos-a-la-comprensión-de-redes-neuronales",
    "href": "posts/random_variables/index.html#fundamentos-previos-a-la-comprensión-de-redes-neuronales",
    "title": "Tipos de Arquitecturas de Redes Neuronales",
    "section": "Fundamentos previos a la comprensión de Redes Neuronales",
    "text": "Fundamentos previos a la comprensión de Redes Neuronales\n\nFunción de Activación\nUna función de activación es una función que se agrega a una red neuronal para ayudar a la red a aprender dependencias no lineales complejas. Una función de activación típica debe ser diferenciable y continua en todas partes. A continuación proporcionaremos algunos ejemplos de funciones de activación utilizando la biblioteca PyTorch.\n\nFunción ReLU\nReLU o la función ReLU realiza una operacion simple: \\(y = \\max (0, x)\\). Aquí te proporciono un ejemplo de uso de la función ReLU utilizando PyTorch.\n\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\nx = torch.linspace(-10, 10,steps=100)\n\nrelu = torch.nn.ReLU()\n\ny = relu(x)\nplt.title(\"ReLU\")\nplt.plot(x.tolist(), y.tolist())\nplt.show()\n\n\n\n\n\n\nFunción Sigmoidea\nEs una de las funciones de activación no lineal más comunes. La función sigmoidea se representa matemáticamente como:\n\\[\nsigmoid(x) = \\frac{1}{1 + e^x}\n\\]\nAl igual que ReLU, la función sigmoidea se puede construir simplemente usando PyTorch.\n\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\nx = torch.linspace(-10, 10,steps=100)\n\nsigmoid = torch.nn.Sigmoid()\n\ny = sigmoid(x)\nplt.title(\"Sigmoidea\")\nplt.plot(x.tolist(), y.tolist())\nplt.show()\n\n\n\n\n\n\nFunción Tanh\nLa función tangente hiperbólica es similar a la función sigmoidea, pero devuelve valores en el rango \\((-1,1)\\). El beneficio de Tanh sobre Sigmoid es que las entradas negativas se asignarán estrictamente a negativa, y las entradas positivas se asignarán estrictamente a positivas:\n\\[\ntanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n\\]\n\nimport torch\nimport matplotlib.pyplot as plt\n\nx=torch.linspace(-10,10, steps = 100)\ntanh = torch.nn.Tanh()\ny = tanh(x)\n\nplt.title('Tanh')\nplt.plot(x.tolist(),y.tolist())\nplt.show()\n\n\n\n\nLas funciones de activación no lineales, como la Sigmoid y Tanh, sufren de un gran problema computacional llamado problema de fuga de gradiente.\nLa fuga de gradiente hace que sea muy difícil entrenar y ajustar los parámetros de las capas iniciales en la red. Este problema empeora a medida que aumenta el número de capas en la red.\nLa fuga de gradiente es la causa principal que hace que las activaciones sigmoideas o Tanh no sean adecuadas para los modelos de Deep Learning (aprendizaje profundo). La función de activación ReLU no sufre de gradiente de desaparición porque la derivada siempre es 1 para entradas positivas. Así que siempre considere usar ReLU como la función de activación en los primeros borradores del diseño de su modelo.\n\nLa creación de una arquitectura de red neuronal que se adapte más a un problema en particular es un arte. Existe una dirección de estudio separada en el aprendizaje profundo llamado Búsqueda de arquitectura neural, que automatiza la ingeniería de arquitectura de red: https://lilianweng.github.io/lil-log/2020/08/06/neural-architecture-search.html. Pero incluso estos motores de búsqueda no pueden competir con las habilidades heurísticas humanas en el diseño todavía. Existen algunas técnicas que aumentan la probabilidad de mejorar el rendimiento de la red neuronal. Por supuesto, estas técnicas no garantizan la mejora en todos los casos. A veces incluso pueden empeorar el rendimiento de la red neuronal. Pero es probable que desarrolle una arquitectura de modelo robusta siguiendo estos enfoques.\n\n\n\nFunciones de Pérdida y Optimización\n\nFunciones de Pérdida\nLa función de pérdida calculará un error de red en cada iteración, mientras que la función de optimización determina “cómo y en qué dirección cambiar los parámetros de peso”.\nHay una cantidad diversa de funciones de pérdida, cada una de ellas está destinada a una tarea en particular. Para el análisis de series de tiempo, hay tres funciones de pérdida principales:\n\nPérdida absoluta (L1): La pérdida absoluta es la métrica más simple de la distancia entre dos vectores:\n\\[\nabsolute loss = \\frac{\\sum |y_{actual} - y_{predicción}|}{n}\n\\]\nEn PyTorch, la función de pérdida absoluta se implementa de la siguiente manera:\n\na = torch.tensor([1,2]).float()\nb = torch.tensor([1, 5]).float()\nabs_loss = torch.nn.L1Loss()\nabs_error = abs_loss(a,b)\nprint(f'abs: {abs_error.item()}')\n\nabs: 1.5\n\n\nError cuadrático medio (MSE) (L2): Es la función de pérdida más utilizada para los problemas de predicción de series de tiempo:\n\\[\nmean\\_squared\\_error =  \\frac{\\sum(y_{actual} - y_{predicted})^2}{n}\n\\]\nPérdida suave (L1): es algo intermedio entre las funciones de pérdida absoluta y MSE. La pérdida absoluto (L1) es menos sensible a los valores atípicos que MSE:\n\\[\nsmooth\\_loss(y^{\\prime},y) = \\frac{1}{n}\\sum z_i\n\\]\ndonde \\(y\\) es valor real, \\(y\\) se predice, \\(z_i\\) se define como:\n\\[ z =\n\\begin{equation}\n\\begin{matrix}\n  \\frac{0.5(y_{i}^{\\prime} - y_i)^2}{\\beta}, & |y_{i}^{\\prime} - y_i| &lt; \\beta\\\\  \n|y_{i}^{\\prime} - y_i| - 0.5\\beta, & otro\\_caso\n  \\end{matrix}\n\\end{equation}\n\\]\n\nLa función de pérdida de L1 suave tiene un parámetro \\(\\beta\\), es igual a 1 por defecto.\n\n\nOptimizador\nEl objetivo principal de un optimizador es cambiar los parámetros de pesos del modelo para minimizar la función de pérdida. La selección de un optimizador adecuado depende completamente de la arquitectura de la red neuronal y los datos sobre los que ocurre el entrenamiento.\n\nAdagrad: es un algoritmo de optimización basado en gradiente que adapta la tasa de aprendizaje a los parámetros. Realiza actualizaciones más pequeñas para los parámetros asociados con características frecuentes y actualizaciones más grandes para parámetros asociados con características raras.\nAdadelta es la versión avanzada del algoritmo de Adagrad. Adadelta busca minimizar su tasa de aprendizaje agresiva y monotónica que disminuye. En lugar de acumular todos los gradientes pasados.\nAdam es otro método de optimización que calcula las tasas de aprendizaje adaptativo para cada parámetro. Además de guardar un promedio exponencialmente en descomposición de gradientes cuadrados anteriores como Adadelta, Adam también mantiene un promedio exponencialmente de disminución de gradientes anteriores."
  },
  {
    "objectID": "posts/random_variables/index.html#conclusiones",
    "href": "posts/random_variables/index.html#conclusiones",
    "title": "Tipos de Arquitecturas de Redes Neuronales",
    "section": "CONCLUSIONES",
    "text": "CONCLUSIONES\nPudimos ver que las redes neuronales recurrentes muestran excelentes resultados y son adecuadas para problemas de pronósticos de series de tiempo.\nLas Redes Neuronales Recurrentes son la técnica muy popular de aprendizaje profundo (Deep Learning) para el pronóstico de series de tiempo, ya que permiten producir predicciones confiables en series de tiempo en diversos problemas. El principal problema con RNN es que sufre el problema de fuga de gradiente cuando se aplica a secuencia largas, y no tiene una herramienta de memoria a largo plazo. Se desarrollaron LSTM y GRU para evitar el problema de gradiente de RNN con el uso de puertas que regulan el flujo de información e implementan el almacenamiento de memoria a largo plazo. El uso de LSTM y GRU ofrece resultados notables, pero LSTM y GRU no siempre funcionan mejor que RNN.\n\nRNN tiene un estado oculto que puede tratarse como una memoria interna de la secuencia de entrada.\nRNN vuelve a calcular el estado oculto después de procesar cada nuevo valor de entrada de forma recurrente.\nRNN sufre un problema de fuga de gradiente.\nRNN actualiza un estado oculto en cada iteración. Por tanto, no tiene memoria a largo plazo.\nGRU implementa la puerta de reinicio, que rechaza algunas actualizaciones en un estado oculto.\nLSTM pasa dos vectores a través de cada iteración: estado oculto y estado de celda."
  }
]