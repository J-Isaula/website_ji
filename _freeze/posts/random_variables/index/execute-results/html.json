{
  "hash": "16cf6985959792e304148c0de4d249eb",
  "result": {
    "markdown": "---\ntitle: \"Tipos de Arquitecturas de Redes Neuronales\"\nsubtitle: \"\"\nauthor: \"Juan Isaula\"\ndate: \"2024-01-24\"\ncategories: [RNN, GRU, LSTM, PyTorch]\nimage: \"arq_rn.jpeg\"\neditor: \n  markdown: \n    wrap: 72\n---\n\nLas arquitecturas de redes neuronales se refieren a los diseños\nestructurales y organizativos de redes neuronales artificiales (RNA).\nEstas arquitecturas determinan cómo se organiza la red, incluida la\ncantidad de capas, la cantidad de neuronas en cada capa, las conexiones\nentre neuoronas y las funciones de activación utilizadas. Se forman\ndiferentes arquitecturas de redes neuronales alterando estos componentes\nestructurales para adaptarse a tareas o desafíos específicos. Si desea\nconocer los tipos de arquitectura de redes neuronales que debe conocer,\neste artículo es para usted. En este artículo, le explicaré los tipos de\narquitecturas de redes neuronales en `Machine Learning` y cuándo\nelegirlas.\n\n## Fundamentos previos a la comprensión de Redes Neuronales\n\n### Función de Activación\n\nUna función de activación es una función que se agrega a una red\nneuronal para ayudar a la red a aprender dependencias no lineales\ncomplejas. Una función de activación típica debe ser diferenciable y\ncontinua en todas partes. A continuación proporcionaremos algunos\nejemplos de funciones de activación utilizando la biblioteca\n[PyTorch](https://pytorch.org/).\n\n#### Función ReLU\n\n`ReLU` o la función ReLU realiza una operacion simple:\n$y = \\max (0, x)$. Aquí te proporciono un ejemplo de uso de la función\nReLU utilizando PyTorch.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\nx = torch.linspace(-10, 10,steps=100)\n\nrelu = torch.nn.ReLU()\n\ny = relu(x)\nplt.title(\"ReLU\")\nplt.plot(x.tolist(), y.tolist())\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=566 height=431}\n:::\n:::\n\n\n#### Función Sigmoidea\n\nEs una de las funciones de activación no lineal más comunes. La función\nsigmoidea se representa matemáticamente como:\n\n$$\nsigmoid(x) = \\frac{1}{1 + e^x} \n$$\n\nAl igual que `ReLU`, la función `sigmoidea` se puede construir\nsimplemente usando `PyTorch`.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\nx = torch.linspace(-10, 10,steps=100)\n\nsigmoid = torch.nn.Sigmoid()\n\ny = sigmoid(x)\nplt.title(\"Sigmoidea\")\nplt.plot(x.tolist(), y.tolist())\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=571 height=431}\n:::\n:::\n\n\n#### Función Tanh\n\nLa función tangente hiperbólica es similar a la función sigmoidea, pero\ndevuelve valores en el rango $(-1,1)$. El beneficio de `Tanh` sobre\n`Sigmoid` es que las entradas negativas se asignarán estrictamente a\nnegativa, y las entradas positivas se asignarán estrictamente a\npositivas:\n\n$$\ntanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n$$\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport torch\nimport matplotlib.pyplot as plt\n\nx=torch.linspace(-10,10, steps = 100)\ntanh = torch.nn.Tanh()\ny = tanh(x)\n\nplt.title('Tanh')\nplt.plot(x.tolist(),y.tolist())\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){width=590 height=431}\n:::\n:::\n\n\nLas funciones de activación no lineales, como la `Sigmoid` y `Tanh`,\nsufren de un gran problema computacional llamado problema de ***fuga de\ngradiente.***\n\nLa fuga de gradiente hace que sea muy difícil entrenar y ajustar los\nparámetros de las capas iniciales en la red. Este problema empeora a\nmedida que aumenta el número de capas en la red.\n\nLa fuga de gradiente es la causa principal que hace que las activaciones\nsigmoideas o Tanh no sean adecuadas para los modelos de Deep Learning\n(aprendizaje profundo). La función de activación `ReLU` no sufre de\ngradiente de desaparición porque la derivada siempre es 1 para entradas\npositivas. Así que siempre considere usar ReLU como la función de\nactivación en los primeros borradores del diseño de su modelo.\\\n\\\nLa creación de una arquitectura de red neuronal que se adapte más a un\nproblema en particular es un arte. Existe una dirección de estudio\nseparada en el aprendizaje profundo llamado\n*`Búsqueda de arquitectura neural`*, que automatiza la ingeniería de\narquitectura de red:\n<https://lilianweng.github.io/lil-log/2020/08/06/neural-architecture-search.html.>\nPero incluso estos motores de búsqueda no pueden competir con las\nhabilidades heurísticas humanas en el diseño todavía. Existen algunas\ntécnicas que aumentan la probabilidad de mejorar el rendimiento de la\nred neuronal. Por supuesto, estas técnicas no garantizan la mejora en\ntodos los casos. A veces incluso pueden empeorar el rendimiento de la\nred neuronal. Pero es probable que desarrolle una arquitectura de modelo\nrobusta siguiendo estos enfoques.\n\n### Funciones de Pérdida y Optimización\n\n#### Funciones de Pérdida\n\nLa función de pérdida calculará un error de red en cada iteración,\nmientras que la función de optimización determina *\"cómo y en qué\ndirección cambiar los parámetros de peso\".*\n\nHay una cantidad diversa de funciones de pérdida, cada una de ellas está\ndestinada a una tarea en particular. Para el análisis de series de\ntiempo, hay tres funciones de pérdida principales:\n\n-   ***Pérdida absoluta (L1):*** La pérdida absoluta es la métrica más\n    simple de la distancia entre dos vectores:\n\n    $$\n    absolute loss = \\frac{\\sum |y_{actual} - y_{predicción}|}{n}\n    $$\n\n    En `PyTorch`, la función de pérdida absoluta se implementa de la\n    siguiente manera:\n\n\n    ::: {.cell execution_count=4}\n    ``` {.python .cell-code}\n    a = torch.tensor([1,2]).float()\n    b = torch.tensor([1, 5]).float()\n    abs_loss = torch.nn.L1Loss()\n    abs_error = abs_loss(a,b)\n    print(f'abs: {abs_error.item()}')\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    abs: 1.5\n    ```\n    :::\n    :::\n    \n    \n-   ***Error cuadrático medio (MSE)*** ***(L2):*** Es la función de\n    pérdida más utilizada para los problemas de predicción de series de\n    tiempo:\n\n    $$\n    mean\\_squared\\_error =  \\frac{\\sum(y_{actual} - y_{predicted})^2}{n}\n    $$\n\n-   ***Pérdida suave (L1):*** es algo intermedio entre las funciones de\n    pérdida absoluta y MSE. La pérdida absoluto (L1) es menos sensible a\n    los valores atípicos que MSE:\n\n    $$\n    smooth\\_loss(y^{\\prime},y) = \\frac{1}{n}\\sum z_i \n    $$\n\n    donde $y$ es valor real, $y$ se predice, $z_i$ se define como:\n\n    $$ z = \n    \\begin{equation} \n     \\begin{matrix}\n      \\frac{0.5(y_{i}^{\\prime} - y_i)^2}{\\beta}, & |y_{i}^{\\prime} - y_i| < \\beta\\\\  \n    |y_{i}^{\\prime} - y_i| - 0.5\\beta, & otro\\_caso\n      \\end{matrix}\n    \\end{equation}\n    $$\n\nLa función de pérdida de L1 suave tiene un parámetro $\\beta$, es igual a\n1 por defecto.\n\n#### Optimizador\n\nEl objetivo principal de un optimizador es cambiar los parámetros de\npesos del modelo para minimizar la función de pérdida. La selección de\nun optimizador adecuado depende completamente de la arquitectura de la\nred neuronal y los datos sobre los que ocurre el entrenamiento.\n\n-   `Adagrad:` es un algoritmo de optimización basado en gradiente que\n    adapta la tasa de aprendizaje a los parámetros. Realiza\n    actualizaciones más pequeñas para los parámetros asociados con\n    características frecuentes y actualizaciones más grandes para\n    parámetros asociados con características raras.\n\n-   `Adadelta` es la versión avanzada del algoritmo de Adagrad. Adadelta\n    busca minimizar su tasa de aprendizaje agresiva y monotónica que\n    disminuye. En lugar de acumular todos los gradientes pasados.\n\n-   `Adam` es otro método de optimización que calcula las tasas de\n    aprendizaje adaptativo para cada parámetro. Además de guardar un\n    promedio exponencialmente en descomposición de gradientes cuadrados\n    anteriores como Adadelta, Adam también mantiene un promedio\n    exponencialmente de disminución de gradientes anteriores.\n\n## Tipos de Redes Neuronales\n\nComenzaremos explorando algunas de las arquitecturas de redes neuronales\nmás eficientes para el pronóstico de series de tiempo. Nos centraremos\nen la implementación de redes neuronales recurrentes (RNN), unidad\nrecurrentes cerradas (GRU), redes de memoria a largo plazo (LSTM).\nComprender los principios básicos de las RNN será una buena base para su\naplicación directa y dominar otras arquitecturas similares. Trataremos\nde cubrir la lógica y el núcleo de cada arquitectura, su aplicación\npráctica y pros y contras.\n\nDiscutiremos los siguientes temas:\n\n-   Recurrent neural network (RNN)\n\n-   Gated recurrent unit network (GRU)\n\n-   Long short-term memory network (LSTM)\n\n### Recurrent Neural Network (RNN)\n\nRNN tiene un concepto de un estado oculto. Un estado oculto puede\ntratarse como memoria interna. El estado oculto no intenta recordar\ntodos los valores pasados de la secuencia sino solo su efecto. Debido a\nla memoria interna, las RNN pueden recordar cosas importantes sobre su\nentrada, lo que les permite ser muy preciosos para predecir valores\nfuturos.\n\nEstudiemos la teoría de RNN de una manera más formal. En RNN, la\nsecuencia de entrada se representa a traves de un bucle. Cuando toma una\ndecisión, considera la entrada actual y también lo que ha aprendido de\nlas entradas que recibio anteriormente. Veamos el gráfico computacional\nde RNN para comprender esta lógica:\n\n![Gráfico Computacional de RNN](Figure%204.3.png)\n\ndonde,\n\n-   $x_1, x_2, . . . , x_n$ son la secuencia de entrada.\n\n-   $h_i$ es el estado oculto. $h_i$ es un vector de longitud $h$.\n\n-   `RNN Cell` representa la capa de red neuronal que calcula la\n    siguiente función:\n    $h_t = \\tanh(W_{ih}x_t + b_{ih} + W_{hh}h_{(t-1)} + b_{hh})$\n\nPodemos ver a detalle la RNN Cell:\n\n![Gráfico computacional de RNN Cell](Figure%204.4.png)\n\nLa RNN Cell combina información sobre el valor actual de la secuencia\n$x_i$ y el estado previamente oculto $h_{i-1}$. La célula RNN devuelve\nun estado oculto actualizado $h_i$ después de aplicar la función de\nactivación.\n\nLa RNN tiene los siguientes parámetros, que se ajustan durante el\nentrenamiento:\n\n-   $W_{ih}$ pesos ocultos de entrada\n\n-   $b_{ih}$ sesgos oculto de entrada\n\n-   $W_{hh}$ pesos ocultos - ocultos\n\n-   $B_{hh}$ sesgos oculto - oculto\n\nNota: Un error común ocurre cuando los subíndices en los parámetros RNN\n$(W_{ih}, b_{ih}, W_{hh}, b_{hh})$ se interpretan como una dimensión de\níndice o tensor. No, son solo la abreviatura de entrada-oculto $(h_í)$ y\noculto-oculto $(h)$. El mismo principio aplica a los parámetros de otros\nmodelos: `GRU` y `LSTM`.\n\nEn ocasiones, los cientificos de datos utilizan la siguiente\nrepresentación de las RNN:\n\n![Visualización alternativa de RNN](Figure%204.5.png)\n\nEl gráfico que se muestra puede dar lugar a algunos malentendidos, y\nestoy tratando de evitar esto. Pero si este tipo de gráfico se adapta a\ntu intuición, entonces úsalo sin ninguna duda.\\\n\nAhora estamos listos para examinar una implementación de RNN utilizando\n`PyTorch`.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nimport torch.nn as nn\n\nclass RNN(nn.Module):\n\n    def __init__(self,\n                 hidden_size,\n                 in_size = 1,\n                 out_size = 1):\n        super(RNN, self).__init__()\n        self.rnn = nn.RNN(\n            input_size = in_size,\n            hidden_size = hidden_size,\n            batch_first = True)\n        self.fc = nn.Linear(hidden_size, out_size)\n\n    def forward(self, x, h = None):\n        out, _ = self.rnn(x, h)\n        last_hidden_states = out[:, -1]\n        out = self.fc(last_hidden_states)\n        return out, last_hidden_states\n```\n:::\n\n\nNote que nuestro modelo devuelve dos salidas: predicción y estado\noculto. Es crucial reutilizar los estados ocultos durante la evaluación\nRNN. Utilizaremos conjuntos de datos de consumo de energía por hora (\n<https://www.kaggle.com/robikscube/Hourly-energy-Consumed>) para la\nimplementación de RNN.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nimport pandas as pd\nimport torch\n\ndf = pd.read_csv('AEP_hourly.csv')\nts = df['AEP_MW'].astype(int).values.reshape(-1, 1)[-3000:]\n\nimport matplotlib.pyplot as plt\n\nplt.title('AEP Hourly')\nplt.plot(ts[:500])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=592 height=431}\n:::\n:::\n\n\nPodemos ver en que esta es una serie de tiempo realmente complicada.\nTiene varios factores de estacionalidad con picos apenas predecibles.\n\nA continuación, voy a mostrarte como se desempeña RNN en la serie de\ntiempo AEP Hourly:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nimport copy\nimport random\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom sklearn.preprocessing import MinMaxScaler\n\nrandom.seed(1)\ntorch.manual_seed(1)\n\n# Parametros globales\n\n\nfeatures = 240\n# Longitud del conjunto de datos de prueba\ntest_ts_len = 300\n# tamaño del estado oculto\nrnn_hidden_size = 24\n# tasa de aprendizaje de optimizador\nlearning_rate = 0.02\n\ntraining_epochs = 500\n\ndef sliding_window(ts, features):\n    X = []\n    Y = []\n\n    for i in range(features + 1, len(ts) + 1):\n        X.append(ts[i - (features + 1):i - 1])\n        Y.append([ts[i - 1]])\n\n    return X, Y\n\ndef get_training_datasets(ts, features, test_len):\n    X, Y = sliding_window(ts, features)\n\n    X_train, Y_train, X_test, Y_test = X[0:-test_len],\\\n                                       Y[0:-test_len],\\\n                                       X[-test_len:],\\\n                                       Y[-test_len:]\n\n    train_len = round(len(ts) * 0.7)\n\n    X_train, X_val, Y_train, Y_val = X_train[0:train_len],\\\n                                     X_train[train_len:],\\\n                                     Y_train[0:train_len],\\\n                                     Y_train[train_len:]\n\n    x_train = torch.tensor(data = X_train).float()\n    y_train = torch.tensor(data = Y_train).float()\n\n    x_val = torch.tensor(data = X_val).float()\n    y_val = torch.tensor(data = Y_val).float()\n\n    x_test = torch.tensor(data = X_test).float()\n    y_test = torch.tensor(data = Y_test).float()\n\n    return x_train, x_val, x_test,\\\n           y_train.squeeze(1), y_val.squeeze(1), y_test.squeeze(1)\n           \n\n# Preparando datos para entrenamiento\nscaler = MinMaxScaler()\nscaled_ts = scaler.fit_transform(ts)\nx_train, x_val, x_test, y_train, y_val, y_test =\\\n    get_training_datasets(scaled_ts, features, test_ts_len)\n    \n\n# Inicialización del modelo \nmodel = RNN(hidden_size = rnn_hidden_size)\nmodel.train()\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\juani\\AppData\\Local\\Temp\\ipykernel_15172\\1156180628.py:50: UserWarning:\n\nCreating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\nRNN(\n  (rnn): RNN(1, 24, batch_first=True)\n  (fc): Linear(in_features=24, out_features=1, bias=True)\n)\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Entrenamiento\noptimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\nmse_loss = torch.nn.MSELoss()\n\nbest_model = None\nmin_val_loss = sys.maxsize\n\ntraining_loss = []\nvalidation_loss = []\n\nfor t in range(training_epochs):\n\n    prediction, _ = model(x_train)\n    loss = mse_loss(prediction, y_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    val_prediction, _ = model(x_val)\n    val_loss = mse_loss(val_prediction, y_val)\n\n    training_loss.append(loss.item())\n    validation_loss.append(val_loss.item())\n\n    if val_loss.item() < min_val_loss:\n        best_model = copy.deepcopy(model)\n        min_val_loss = val_loss.item()\n\n    if t % 50 == 0:\n        print(f'epoch {t}: train - {round(loss.item(), 4)}, '\n              f'val: - {round(val_loss.item(), 4)}')\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nepoch 0: train - 0.377, val: - 0.0866\nepoch 50: train - 0.0061, val: - 0.0133\nepoch 100: train - 0.0021, val: - 0.0044\nepoch 150: train - 0.0018, val: - 0.0034\nepoch 200: train - 0.0015, val: - 0.003\nepoch 250: train - 0.0014, val: - 0.0027\nepoch 300: train - 0.0013, val: - 0.0026\nepoch 350: train - 0.0012, val: - 0.0025\nepoch 400: train - 0.0012, val: - 0.0024\nepoch 450: train - 0.0012, val: - 0.0024\n```\n:::\n:::\n\n\nY aquí llegamos al punto más difícil. Debe pasar el estado oculto al\nmodelo RNN cuando lo evalua. La forma más sencilla de calentar el estado\noculto es ejecutar el modelo en los datos de validación una vez y pasar\nun estado oculto cálido a través de cada iteración y por último\nevaluamos el modelo que construimos en el conjunto de datos de prueba.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nbest_model.eval()\n_, h_list = best_model(x_val)\n\nh = (h_list[-1, :]).unsqueeze(-2)\n\n\npredicted = []\nfor test_seq in x_test.tolist():\n    x = torch.Tensor(data = [test_seq])\n \n    y, h = best_model(x, h.unsqueeze(-2))\n    unscaled = scaler.inverse_transform(np.array(y.item()).reshape(-1, 1))[0][0]\n    predicted.append(unscaled)\n\nreal = scaler.inverse_transform(y_test.tolist())\nplt.title(\"conjutno de datos prueba\")\nplt.plot(real, label = 'real')\nplt.plot(predicted, label = 'predicción')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-1.png){width=592 height=431}\n:::\n:::\n\n\nRNN muestra un gran rendimiento en el conjunto de datos de prueba. El\nmodelo que hemos entrenado predice picos estacionales con mucha\nprecisión.\n\nY finalmente, examinamos el proceso de entrenamiento en sí.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nplt.title('Entrenamiento')\nplt.yscale('log')\nplt.plot(training_loss, label = 'Entrenamiento')\nplt.plot(validation_loss, label = 'validación')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-11-output-1.png){width=599 height=449}\n:::\n:::\n\n\nEl proceso del entrenamiento es suave sin picos agudos e impredecibles.\n\nAhora, podemos establecer con confianza la promesa y la efectividad de\nla aplicación de RNN a los problemas de pronósticos de la serie\ntemporal.\n\nA pesar de todas las ventajas de RNN, tiene desventajas significativas:\n\n-   Debido a la complejidad computacional, sufren problemas de gradiente\n    de fuga. El proceso de entrenamiento se vuelve demasiado lento. El\n    problema del gradient e de fuga es un problema común a todas las\n    RNN.\n\n-   El estado oculto se actualiza en cada iteración, lo que dificulta el\n    almacenamiento de información a largo plazo en RNN. Las\n    arquitecturas `GRU` y `LSTM` resuelven este problema. Tienen\n    enfoques similares sobre cómo almacenar información a largo plazo.\n\n### Gated recurrent unit network (GRU)\n\nLa GRU es es una versión avanzada de la RNN clásica. El propósito\nprincipal de GRU es almacenar información a largo plazo. En breve\nexploraremos como GRU logra esto.\n\nLa forma más fácil de almacenar información a largo plazo en un estado\noculto es restringir las actualizaciones ocultas sobre cada iteración.\nEste enfoque evitará sobrescribir información importante a largo plazo.\n\nPuede encontrar la siguiente definición de GRU en internet:\n\nSe comienza calculando la puerta de actualización $z_t$ para el peso de\ntiempo $t$ usando la fórmula:\n\n$$\n\\begin{eqnarray*}\nz_{t} &=& \\sigma(W^{z}x_t + U^{z}h_{t-1}) \\hspace{1cm} \\mbox{Puerta de actualización}\\\\[0.2cm]\n\\end{eqnarray*}\n$$\n\nlo que sucede aquí es que cuando $x_t$ se conecta a la unidad de red, se\nmultiplica por su propio peso $W^{z}$. Lo mismo ocurre con $h_{t-1}$,\nque contiene la información de las unidades $t-1$ anteriores y se\nmúltiplica por su propio peso $U^{z}$. Ambos resultados se suman y se\naplica una función de activación sigmoidea $(\\sigma)$ para acotar el\nresultado entre 0 y 1.\n\n![](fig_gru_1.png)\n\nLa puerta de actualización ayuda al modelo a determinar cuánta\ninformación pasada (de pasos de tiempo anteriores) debe transmitirse al\nfuturo. Esto es muy poderoso porque el modelo puede decidir copiar toda\nla la información del pasado y eliminar el riesgo de que desaparezca el\nproblema de fuga del gradiente.\n\nLuego continuamos con Restablecer puerta:\n\nBásicamente, esta puerta se utiliza desde el modelo para decidir cuánta\ninformación pasada se debe olvidar. Para calcularlo utilizamos:\n\n$$\nr_t = \\sigma(W^{r}x_t + U^{r}h_{t-1})\\hspace{1cm} \\mbox{Restablecer puerta}\n$$\n\nEsta fórmula es la misma que la de la puerta de actualización. La\ndiferencia viene en los pesos y el uso de la puerta, que veremos en un\nmomento.\n\n![](fig_2_gru.png)\n\nComo antes, conectamos $h_{t-1} - \\mbox{linea azul}$ y\n$x_{t} - \\mbox{linea violeta}$, los multiplicamos con sus pesos\ncorrespondientes, sumamos los resultados y aplicamos la función\nsigmoidea.\n\n***Contenido de la memoria actual:***\n\nveamos como afectarán exactamente las puertaas al resultado final.\nPrimero, comenzamos con el uso de la puerta de reinicio. Introducimos un\nnuevo contenido de memoria que utilizará la puerta de reinicio para\nalmacenar la información del pasado. Se calcula de la siguiente manera:\n\n$$\nh_{t}^{\\prime} = tanh(Wx_{t} + r_{t}\\odot U h_{t-1})\n$$\n\n1.  Multiplique la entrada $x_t$ con un peso $W$ y $h_{t-1}$ con un peso\n    $U$.\n\n2.  Calcule el producto de Hadamard (por elementos) entre la puerta de\n    reinicio $r_t$ y $Uh_{t-1}$. Eso determinará qué eliminar de los\n    pasos de tiempo anterior. Digamos que tenemos un problema de\n    análisis de sentimientos para determinar la opinión de una persona\n    sobre un libro a partir de una reseña que escribió. El texto\n    comienza con *\"Este es un libro de fantasía que ilustra...\"* y\n    después de un par de párrafos termina con *\"No disfruté mucho el\n    libro porque creo que captura demasiados detalles\". Para determinar\n    el nivel general de satisfacción con el libro sólo necesitamos la\n    última parte de la reseña. En ese caso, a medida que la red neuronal\n    se acerque al final del texto, aprenderá a asignar un vector* $r_t$\n    cercano a 0, eliminando el pasado y centrándose solo en las últimas\n    oraciones.\n\n3.  Resuma los resultados de los pasos 1 y 2.\n\n4.  Aplicar la función de activación no lineal tanh.\n\nPuedes ver claramente los pasos aquí:\n\n![](fig_3_gru.png)\n\nHacemos una multiplicación por elementos de\n$h_{t-1} - \\mbox{línea azul}$ y $r_t - \\mbox{línea naranja}$ y luego\nsumamos el resultado - linea rosa con la entrada $x_t -$ línea morada.\nFinalmente, tanh se usa para producir $h_{t}^{\\prime}:$ línea verde\nbrillante.\n\n***Memoria final en el paso de tiempo actual***\n\nComo último paso, la red necesita calcular $h_{t}$, el vector que\ncontiene información para la unidad actual y la transmite a la red. Para\nhacer eso, se necesita la puerta de actualización. Determina qué\nrecopilar el contenido de la memoria actual $(h_t^{\\prime})$ y qué de\nlos pasos anteriores $(h_{(t-1)})$. Eso se hace de la siguiente manera:\n\n$$\nh_t = z_t\\odot h_{t-1} + (1 - z_t)\\odot h_{t}^{\\prime}\n$$\n\n1.  Aplique la multiplicación por elementos a la puerta de actualización\n    $z_t$ y $h_{(t-1)}$.\n\n2.  Aplique la multiplicación por elementos a $(1- z_t)$ y\n    $h_{t}^{\\prime}$.\n\n3.  Sume los resultados de los pasos 1 y 2.\n\nPongamos el ejemplo de la reseña del equilibrio. En esta ocasión, la\ninformación más relevante se situa al inicio del texto. El modelo puede\naprender a establecer el vector $z_t$ cerca de 1 y conservar la mayor\nparte de la información anterior. Dado que $z_t$ estará cerca de 1 en\neste paso de tiempo, $(1-z_t)$ estará cerca de 0, lo que ignorará gran\nparte del contenido actual (en este caso, la última parte de la reseña\nque explica la trama del libro), lo cual es irrelevante para nuestra\npredicción.\n\nAquí hay una ilustración que enfatiza la ecuación anterior:\n\n![](fig_4_gru.png)\n\nA continuación, puede ver cómo $z_t$ (línea verde) para calcular\n$1 - z_t$ que combinado con $h_{t}^{\\prime}$ (línea verde brillante),\nproduce un resultado en la línea roja oscura. $z_t$ también se usa con\n$h_{t-1} - \\mbox{línea azul}$ en una multiplicación de elementos.\nFinalmente, $h_{t}:$ la línea azul es el resultado de la suma de las\nsalidas correspondientes a las líneas rojas brillantes y oscuras.\n\nAhora puede ver cómo las GRU pueden almacenar y filtrar la información\nutilizando sus puertas de actualización y reinicio. Eso elimina el\nproblema del gradiente de fuga, ya que el modelo no elimina la nueva\nentrada cada vez, sino que mantiene la información relevante y la pasa a\nlos siguientes pasos de la red. ***Si se les entrena cuidadosamente,\npueden desempeñarse extremadamente bien incluso en escenarios\ncomplejos.***\n\nEl modelo de predicción `GRU` es muy similar al `RNN`. Veamos su\ndesempeño utilizando la misma data que el casa `RNN`.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nimport torch.nn as nn\n\nrandom.seed(1)\ntorch.manual_seed(1)\n\n\nfeatures = 240\ntest_ts_len = 300\ngru_hidden_size = 24\nlearning_rate = 0.02\ntraining_epochs = 500\n\nclass GRU(nn.Module):\n\n    def __init__(self,\n                 hidden_size,\n                 in_size = 1,\n                 out_size = 1):\n        super(GRU, self).__init__()\n        self.gru = nn.GRU(\n            input_size = in_size,\n            hidden_size = hidden_size,\n            batch_first = True)\n        self.fc = nn.Linear(hidden_size, out_size)\n\n    def forward(self, x, h = None):\n        out, _ = self.gru(x, h)\n        last_hidden_states = out[:, -1]\n        out = self.fc(last_hidden_states)\n        return out, last_hidden_states\n\n# Inicializando el modelo GRU\nmodel = GRU(hidden_size = gru_hidden_size)\nmodel.train()\n\n# Entrenamiento\noptimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\nmse_loss = torch.nn.MSELoss()\n\nbest_model = None\nmin_val_loss = sys.maxsize\n\ntraining_loss = []\nvalidation_loss = []\n\n\nfor t in range(training_epochs):\n\n    prediction, _ = model(x_train)\n    loss = mse_loss(prediction, y_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    val_prediction, _ = model(x_val)\n    val_loss = mse_loss(val_prediction, y_val)\n\n    training_loss.append(loss.item())\n    validation_loss.append(val_loss.item())\n\n    if val_loss.item() < min_val_loss:\n        best_model = copy.deepcopy(model)\n        min_val_loss = val_loss.item()\n\n    if t % 50 == 0:\n        print(f'epoch {t}: train - {round(loss.item(), 4)}, '\n              f'val: - {round(val_loss.item(), 4)}')\n\nbest_model.eval()\n_, h_list = best_model(x_val)\nh = (h_list[-1, :]).unsqueeze(-2)\n\npredicted = []\nfor test_seq in x_test.tolist():\n    x = torch.Tensor(data = [test_seq])\n    y, h = best_model(x, h.unsqueeze(-2))\n    unscaled = scaler.inverse_transform(np.array(y.item()).reshape(-1, 1))[0][0]\n    predicted.append(unscaled)\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nepoch 0: train - 0.0626, val: - 0.0326\nepoch 50: train - 0.0017, val: - 0.0026\nepoch 100: train - 0.0012, val: - 0.0024\nepoch 150: train - 0.0012, val: - 0.0023\nepoch 200: train - 0.0011, val: - 0.0022\nepoch 250: train - 0.0011, val: - 0.0022\nepoch 300: train - 0.0011, val: - 0.0023\nepoch 350: train - 0.0011, val: - 0.0023\nepoch 400: train - 0.0011, val: - 0.0022\nepoch 450: train - 0.0011, val: - 0.0022\n```\n:::\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nreal = scaler.inverse_transform(y_test.tolist())\nplt.title(\"conjutno de datos prueba\")\nplt.plot(real, label = 'real')\nplt.plot(predicted, label = 'predicción')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-1.png){width=592 height=431}\n:::\n:::\n\n\nVemos que el modelo `GRU` imita el comportamiento original de la serie\ntemporal con bastante precisión.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nplt.title('Entrenamiento')\nplt.yscale('log')\nplt.plot(training_loss, label = 'Entrenamiengto')\nplt.plot(validation_loss, label = 'validación')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-14-output-1.png){width=599 height=449}\n:::\n:::\n\n\nLas pérdidas de entrenamiento y validación tienen descenso asintótico\ncon un brecha natural constante entre ellas. Podemos concluir que el\nmodelo realmente aprende el comportamiento de la serie temporal.\n\n### Long short-term memory network (LSTM)\n\nLa red `LSTM` se ha desarrollado para superar el problema de fuga de\ngradiente en `RNN` al mejorar el flujo de gradiente de la red. Debe\nmencionarse que la arquitectura apareció mucho antes que la GRU. La\narquitectura LSTM se desarrolló en 1997, y el GRU se propueso en 2014.\nEl diseño GRU es más simple y más comprensible que LSTM. Es por eso que\ncomenzamos nuestro estudio examinando primero GRU.\n\nComo su nombre lo índica, LSTM aborda los mismos problemas de memoria a\ncorto y largo plazo que GRU. A nivel global, el flujo computacional del\nLSTM se ve de la siguiente manera:\n\n![](Figure%204.16.png)\n\nLSTM funciona sobre los principios similares que GRU pero tiene más\nvariables. RNN y GRU solo pasan un estado oculto $h_t$ a través de cada\niteración. Pero LSTM pasa dos vectores:\n\n-   $h_t$ estado oculto (memoria a corto plazo)\n\n-   $c_t$ estado de celda (memoria a largo plazo)\n\nLas salidas de `LSTM Cell` se calculan a través de las fórmulas:\n\n$$\n\\begin{eqnarray*}\ni_t &=& \\sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1} + b_{hi})\\\\[0.2cm]\nf_t &=& \\sigma(W_{ii}x_{t} + b_{if} + W_{hf}h_{t-1} + b_{hf})\\\\[0.2cm]\ng_t &=& tanh(W_{ig}x_t + b_{ig} + W_{hg}h_{t-1} + b_{hn})\\\\[0.2cm]\no_t &=& \\sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho})\\\\[0.2cm]\nc_t &=& f_t \\circ c_{t-1} + i_t\\circ g_t\\\\[0.2cm]\nh_t &=& o_t \\circ tanh(c_t)\n\\end{eqnarray*}\n$$\n\ndonde:\n\n-   $\\sigma$ es la función sigmoidea\n\n-   $\\circ$ es el producto de Hadamard\n\nEn cuanto a las variables:\n\n-   $i_t~(puerta de entrada)$ es la variable que se utiliza para\n    actualizar el estado $c_t$. El estado previamente oculto $h_t$ y la\n    secuencia $x_t$ se dan como entradas a una función sigmoidea\n    $(\\sigma)$. Si la salida está cerca de 1, entonces la información es\n    más importante.\n\n-   $f_t ~ (puerta~de~olvido)$ es la variable que decide que información\n    debe olvidarse en el estado $c_t$. El estado $h_t$ de estado\n    previamente oculto y la secuencia $x_t$ se dan como entradas a una\n    función sigmoidea. Si la salida $f_t$ está cerca de cero, la\n    información se puede olvidar, mientras que si la salida está cerca\n    de 1, la información debe almacenarse o recordarse.\n\n-   $g_t$ representa información importante potencialmente nueva para el\n    estado $c_t$.\n\n-   $c_t ~ (estado~celda)$ es una suma de:\n\n    -   estado de celda anterior $c_{t-1}$ con información olvidada\n        $f_t$.\n\n    -   nueva información de $g_t$ seleccionada por $i_t$\n\n-   $o_t ~ (puerta~de~salida)$ es la variable para actualizar el estado\n    oculto $h_t$.\n\n-   $h_t ~(estado~oculto)$ es el siguiente estado oculto que se calcula\n    eligiendo la información importante del estado de celda o celular\n    $c_t$.\n\nA continuación te muestro el gráfico computacional de la celda LSTM:\n\n![](Figure%204.17%20.png)\n\nLSTM tiene los siguientes parámetros, que se ajustan durante el\nentrenamiento:\n\n-   $W_{ii}, W_{hi}, W_{if}, W_{hf}, W_{ig}, W_{hg}, W_{io}, W_{ho}$\n    estos son los pesos.\n\n-   $b_{ii}, b_{hi}, b_{if}, b_{hf}, b_{ig}, b_{hg}, b_{io}, b_{ho}$\n    estos son sesgos.\n\nAhora examinemos la implementación de Pytorch del modelo de predicción\nLSTM:\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nimport torch.nn as nn\n\nclass LSTM(nn.Module):\n\n    def __init__(self,\n                 hidden_size,\n                 in_size = 1,\n                 out_size = 1):\n        super(LSTM, self).__init__()\n        self.lstm = nn.LSTM(\n            input_size = in_size,\n            hidden_size = hidden_size,\n            batch_first = True)\n        self.fc = nn.Linear(hidden_size, out_size)\n\n    def forward(self, x, h = None):\n        out, h = self.lstm(x, h)\n        last_hidden_states = out[:, -1]\n        out = self.fc(last_hidden_states)\n        return out, h\n```\n:::\n\n\nComo vemos, la implementación del modelo `LSTM` es bastante similar a\nlas implementaciones de `RNN` y `GRU`.\n\nProbaremos el modelo LSTM con el siguiente conjunto de datos de la serie\ntiempo de consumo de energía por hora).\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nimport pandas as pd\nimport torch\n\ndf = pd.read_csv('NI_hourly.csv')\nts = df['NI_MW'].astype(int).values.reshape(-1, 1)[-3000:]\n\nimport matplotlib.pyplot as plt\n\nplt.title('NI Hourly')\nplt.plot(ts[:500])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-16-output-1.png){width=592 height=431}\n:::\n:::\n\n\nVeamos el modelo en acción:\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nimport copy\nimport random\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom sklearn.preprocessing import MinMaxScaler\n\nrandom.seed(1)\ntorch.manual_seed(1)\n\n\nfeatures = 240\ntest_ts_len = 300\nlstm_hidden_size = 24\nlearning_rate = 0.02\ntraining_epochs = 100\n\n# Preparar el conjunto de datos para el entrenamiento \nscaler = MinMaxScaler()\nscaled_ts = scaler.fit_transform(ts)\nx_train, x_val, x_test, y_train, y_val, y_test =\\\n    get_training_datasets(scaled_ts, features, test_ts_len)\n\n# Inicializando el modelo \nmodel = LSTM(hidden_size = lstm_hidden_size)\nmodel.train()\n\n# Entrenamiento \noptimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\nmse_loss = torch.nn.MSELoss()\n\nbest_model = None\nmin_val_loss = sys.maxsize\n\ntraining_loss = []\nvalidation_loss = []\n\n\nfor t in range(training_epochs):\n\n    prediction, _ = model(x_train)\n    loss = mse_loss(prediction, y_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    val_prediction, _ = model(x_val)\n    val_loss = mse_loss(val_prediction, y_val)\n\n    training_loss.append(loss.item())\n    validation_loss.append(val_loss.item())\n\n    if val_loss.item() < min_val_loss:\n        best_model = copy.deepcopy(model)\n        min_val_loss = val_loss.item()\n\n    if t % 10 == 0:\n        print(f'epoch {t}: train - {round(loss.item(), 4)}, '\n              f'val: - {round(val_loss.item(), 4)}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nepoch 0: train - 0.0979, val: - 0.087\nepoch 10: train - 0.0253, val: - 0.0255\nepoch 20: train - 0.0131, val: - 0.0119\nepoch 30: train - 0.0056, val: - 0.0059\nepoch 40: train - 0.0032, val: - 0.0043\nepoch 50: train - 0.0026, val: - 0.0029\nepoch 60: train - 0.002, val: - 0.0025\nepoch 70: train - 0.0018, val: - 0.0023\nepoch 80: train - 0.0016, val: - 0.0021\nepoch 90: train - 0.0014, val: - 0.0019\n```\n:::\n:::\n\n\nPara una evaluación del modelo LSTM, necesitamos pasar un estado celular\ny estado oculto.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nbest_model.eval()\nwith torch.no_grad():\n    _, h_list = best_model(x_val)\n\n    h = tuple([(h[-1, -1, :]).unsqueeze(-2).unsqueeze(-2)\n               for h in h_list])\n\n    predicted = []\n    for test_seq in x_test.tolist():\n        x = torch.Tensor(data = [test_seq])\n\n        y, h = best_model(x, h)\n        unscaled = scaler.inverse_transform(\n            np.array(y.item()).reshape(-1, 1))[0][0]\n        predicted.append(unscaled)\n        \nreal = scaler.inverse_transform(y_test.tolist())\nplt.title(\"Conjunto de prueba\")\nplt.plot(real, label = 'real')\nplt.plot(predicted, label = 'predicción')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-1.png){width=592 height=431}\n:::\n:::\n\n\nLSTM captura muy bien el comportamiento de las series temporales para\nhacer predicciones precisas.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nplt.title('Entrenamiento')\nplt.yscale('log')\nplt.plot(training_loss, label = 'Entrenamiento')\nplt.plot(validation_loss, label = 'validación')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-1.png){width=599 height=449}\n:::\n:::\n\n\nMirando, concluimos que detuvimos el proceso de entrenamiento demasiado\ntemprano. Obtenemos modelos más precisos si establecemos más epocas\n(epoch) para el entrenamiento.\n\n### CONCLUSIONES\n\nPudimos ver que las redes neuronales recurrentes muestran excelentes\nresultados y son adecuadas para problemas de pronósticos de series de\ntiempo.\n\nLas Redes Neuronales Recurrentes son la técnica muy popular de\naprendizaje profundo (Deep Learning) para el pronóstico de series de\ntiempo, ya que permiten producir predicciones confiables en series de\ntiempo en diversos problemas. El principal problema con RNN es que sufre\nel problema de fuga de gradiente cuando se aplica a secuencia largas, y\nno tiene una herramienta de memoria a largo plazo. Se desarrollaron LSTM\ny GRU para evitar el problema de gradiente de RNN con el uso de puertas\nque regulan el flujo de información e implementan el almacenamiento de\nmemoria a largo plazo. El uso de LSTM y GRU ofrece resultados notables,\npero LSTM y GRU no siempre funcionan mejor que RNN.\n\n-   `RNN` tiene un estado oculto que puede tratarse como una memoria\n    interna de la secuencia de entrada.\n\n-   `RNN` vuelve a calcular el estado oculto después de procesar cada\n    nuevo valor de entrada de forma recurrente.\n\n-   `RNN` sufre un problema de fuga de gradiente.\n\n-   `RNN` actualiza un estado oculto en cada iteración. Por tanto, no\n    tiene memoria a largo plazo.\n\n-   `GRU` implementa la puerta de reinicio, que rechaza algunas\n    actualizaciones en un estado oculto.\n\n-   `LSTM` pasa dos vectores a través de cada iteración: *estado oculto*\n    y *estado de celda.*\n\n### REFERENCIAS\n\n-   Time Series Forecasting Using Deep Learning - Ivan Gridin\n\n-   [Understanding GRU\n    Networks](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be)\n\n### \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}